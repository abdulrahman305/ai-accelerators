{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ad9c4103-876a-4bcc-8210-2242544d48b9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Synthetic data capability\n",
    "\n",
    "## Summary\n",
    "\n",
    "The use case provided in this notebook creates synthetic training data sets for use in DataRobot models.\n",
    "\n",
    "This notebook outlines how to create a synthetic training data set in a csv file, with name, address, phone number, company, account number, and credit score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements\n",
    "\n",
    "The `datarobot` package will required an API token and an endpoint to interact with the Datarobot offering. See https://docs.datarobot.com/en/docs/api/api-quickstart/index.html#configure-api-authentication for the available methods and pick the one relevant to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are packages used in this accelerator\n",
    "# The below format is used in the Datarobot notebooks to install packages. If running this in a DR notebook, uncomment the below entries\n",
    "\n",
    "# !pip install datarobot\n",
    "# !pip install faker\n",
    "# !pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "\n",
    "import datarobot as dr\n",
    "from datarobot import Dataset as ds\n",
    "from faker import Faker\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a csv file with 10000 rows consisting of these columns:\n",
    "# fake first name\n",
    "# fake last name\n",
    "# fake address\n",
    "# phone number\n",
    "# company\n",
    "# fake account number\n",
    "# credit score (random number between 300-850)\n",
    "# good loan candidate (T/F)\n",
    "\n",
    "Faker.seed(0)\n",
    "fake = Faker()\n",
    "fake.set_arguments(\"credit_score\", {\"min_value\": 300, \"max_value\": 850})\n",
    "people_csv = fake.csv(\n",
    "    header=(\n",
    "        \"Name\",\n",
    "        \"Address\",\n",
    "        \"Phone_Number\",\n",
    "        \"Company\",\n",
    "        \"Account_Number\",\n",
    "        \"Credit_Score\",\n",
    "        \"Good_Loan_Candidate\",\n",
    "    ),\n",
    "    data_columns=(\n",
    "        \"{{name}}\",\n",
    "        \"{{address}}\",\n",
    "        \"{{phone_number}}\",\n",
    "        \"{{company}}\",\n",
    "        \"{{bban}}\",\n",
    "        \"{{pyint:credit_score}}\",\n",
    "        \"{{boolean}}\",\n",
    "    ),\n",
    "    num_rows=10000,\n",
    "    include_row_ids=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Frame for Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use StringIO to create a file-like object for pandas to read from\n",
    "csv_file = StringIO(people_csv)\n",
    "\n",
    "# Read the CSV into a DataFrame\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Now 'df' is your DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CSV into AI Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write synthetic data csv to a file on disk\n",
    "with open(\"people.csv\", \"w\") as file:\n",
    "    file.write(people_csv)\n",
    "\n",
    "# push that to datarobot\n",
    "# https://datarobot-public-api-client.readthedocs-hosted.com/en/latest-release/autodoc/api_reference.html#datasets\n",
    "\n",
    "people_dataset = ds.upload(\"people.csv\")\n",
    "\n",
    "# get the dataset id\n",
    "people_dataset_id = people_dataset.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load synthetic data into AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = dr.Project.create_from_dataset(people_dataset_id, project_name=\"Good_Loan_Candidate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiate autopilot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.analyze_and_model(target=\"Good_Loan_Candidate\", mode=dr.AUTOPILOT_MODE.FULL_AUTO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve top performing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for the autopilot testing and top model identification to finish\n",
    "project.wait_for_autopilot()\n",
    "\n",
    "model = project.get_top_model()\n",
    "\n",
    "print(\"\"\"The top performing model is {model}\"\"\".format(model=str(model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy chosen model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the prediction server\n",
    "prediction_server = dr.PredictionServer.list()[0]\n",
    "\n",
    "# Create a deployment\n",
    "deployment = dr.Deployment.create_from_learning_model(\n",
    "    model.id,\n",
    "    label=\"Synthetic data test\",\n",
    "    description=\"Model trained on synthetic dataset with names, addresses, credit scores, etc.\",\n",
    "    default_prediction_server_id=prediction_server.id,\n",
    ")\n",
    "\n",
    "print(deployment.id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": true,
  "vscode": {
   "interpreter": {
    "hash": "397704579725e15f5c7cb49fe5f0341eb7531c82d19f2c29d197e8b64ab5776b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

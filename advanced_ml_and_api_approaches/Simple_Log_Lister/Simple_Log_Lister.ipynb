{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Event Log Viewer\n",
    "\n",
    "This note book provides a user with a method of changing the output of User Activity Monitor to allow the user to drop an entire column of output or change the contents of that column in a way to preserve the anonymity of the column but maintain consistency for reporting.\n",
    "\n",
    "For the full list of columns, please refer to: \n",
    "https://docs.datarobot.com/en/docs/api/reference/public-api/analytics.html#get-apiv2eventlogs\n",
    "\n",
    "## Required Permissions\n",
    "\n",
    "The user that executes this notebook, must have the following permissions:\n",
    "\n",
    "- `ADMIN_API_ACCESS`\n",
    "- `CAN_ACCESS_USER_ACTIVITY`\n",
    "\n",
    "## NOTE 1:\n",
    "\n",
    "This notebook assumes usage from a local laptop or similar, using a `.env` file with the following format:\n",
    "\n",
    "```bash\n",
    "# Where to connect\n",
    "DATAROBOT_ENDPOINT = 'https://datarobot.example.com'\n",
    "\n",
    "# A valid API key from a user with the permissions above\n",
    "DATAROBOT_API_TOKEN = ''\n",
    "```\n",
    "\n",
    "If you wish to use the the DataRobot notebook functionality, be sure to set the following environment variables:\n",
    "\n",
    "- DATAROBOT_ENDPOINT\n",
    "- DATAROBOT_API_TOKEN\n",
    "\n",
    "And comment where shown in the notebook\n",
    "\n",
    "## NOTE 2:\n",
    "The block below uses pip3 to install the required python packages.\n",
    "Be sure to update this command to what is appropreate for your notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python package import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install --upgrade pip\n",
    "!pip3 install dotenv\n",
    "!pip3 install datarobot\n",
    "!pip3 install faker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "from datetime import timedelta\n",
    "import json\n",
    "import os\n",
    "from random import randint\n",
    "import urllib.parse\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "import datarobot as dr\n",
    "\n",
    "########################################################\n",
    "# Comment these 2 lines when used in DataRobot notebooks\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from faker import Faker\n",
    "import pandas as pd\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "########################################################\n",
    "\n",
    "# Provide the URL protocol, address (IP or FQDN)\n",
    "# Example: https://datarobot.example.com or http://10.1.2.3\n",
    "DATAROBOT_ENDPOINT = os.environ[\"DATAROBOT_ENDPOINT\"]\n",
    "\n",
    "# Provide an API key from a user with the ADMIN_API_ACCESS permission from this cluster\n",
    "DATAROBOT_API_TOKEN = os.environ[\"DATAROBOT_API_TOKEN\"]\n",
    "\n",
    "# These values are mostly constant\n",
    "# Create the shared DataRobot client\n",
    "my_client = dr.Client(\n",
    "    token=\"%s\" % (DATAROBOT_API_TOKEN),\n",
    "    endpoint=\"%s/api/v2\" % (DATAROBOT_ENDPOINT),\n",
    "    ssl_verify=True if (urlparse(DATAROBOT_ENDPOINT)).scheme == \"https\" else False,\n",
    ")\n",
    "\n",
    "########################################################\n",
    "# Define the download function\n",
    "\n",
    "\n",
    "def findEventData(_client, location, parameters):\n",
    "    \"\"\"\n",
    "    Uses the DR Client to get the data from the event logs\n",
    "    \"\"\"\n",
    "    my_replies = []\n",
    "    reply_set = json.loads(\n",
    "        _client.get(\"%s?%s\" % (location, urllib.parse.urlencode(parameters))).text\n",
    "    )\n",
    "\n",
    "    while \"next\" in reply_set and reply_set[\"next\"] != None:\n",
    "        for reply in reply_set[\"data\"]:\n",
    "            my_replies.append(reply)\n",
    "\n",
    "        my_next = urlparse(reply_set[\"next\"])\n",
    "        reply_set = json.loads(_client.get(\"%s?%s\" % (location, my_next.query)).text)\n",
    "\n",
    "    # Add the last set of items, depending on where it lives\n",
    "    for reply in reply_set[\"data\"]:\n",
    "        my_replies.append(reply)\n",
    "\n",
    "    # print(\"getEventData %s item count:> %s\" % ( location, len(my_replies)))\n",
    "    return my_replies\n",
    "\n",
    "\n",
    "########################################################\n",
    "# Verbose settings statement\n",
    "print(\"# -----------------------------------------\")\n",
    "print(\"DataRobot client version: %s\" % dr.__version__)\n",
    "print(\"Pandas version: %s\" % pd.__version__)\n",
    "print(\"# -----------------------------------------\")\n",
    "print(\"DATAROBOT_ENDPOINT: %s\" % DATAROBOT_ENDPOINT)\n",
    "print(\"DATAROBOT_API_TOKEN length: %s\" % len(DATAROBOT_API_TOKEN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Everything and drop an entire column\n",
    "\n",
    "If the query needs to be customized, see here for details: https://docs.datarobot.com/en/docs/api/reference/public-api/analytics.html#get-apiv2eventlogs\n",
    "\n",
    "A complete example of the UAM query is below\n",
    "\n",
    "```python\n",
    "my_params = {\n",
    "    'projectId': '<The project to select log records for>',\n",
    "    'userId': '<The user to select log records for>',\n",
    "    'orgId': '<The organization to select log records for>',\n",
    "    'event' : '<The event type of records>',\n",
    "    'minTimestamp': '<The lower bound for timestamps. E.g. 2016-12-13T11:12:13.141516Z>',\n",
    "    'maxTimestamp': 'The upper bound for timestamps. E.g. 2024-01-26T16:10:42.234516Z',\n",
    "    'offset': '<This many results will be skipped. Defaults to 0>'\n",
    "    'order': '<The order of the results. Defaults to descending>'\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Example below show for the last 30 days\n",
    "end_date = dt.utcnow()\n",
    "start_date = end_date - timedelta(days=30)\n",
    "\n",
    "my_params = {\"minTimestamp\": start_date, \"maxTimestamp\": end_date}\n",
    "\n",
    "# # This is where you can update the Event Log search params\n",
    "# # For now, we are extracting the default events\n",
    "# my_params = {}\n",
    "\n",
    "print(\"Loading data from: %s/eventLogs\" % my_client.endpoint)\n",
    "print(\"params: %s\" % my_params)\n",
    "\n",
    "EVENTS = findEventData(my_client, \"eventLogs\", my_params)\n",
    "print(\"Currnet log entries: %s\" % len(EVENTS))\n",
    "\n",
    "MASTER_EVENTS_DF = pd.json_normalize(EVENTS)\n",
    "\n",
    "# Puts the scrollbar next to the DataFrame\n",
    "display(\n",
    "    HTML(\n",
    "        \"<div style='height: 600px; overflow: auto; width: fit-content'>\"\n",
    "        + MASTER_EVENTS_DF.style.to_html()\n",
    "        + \"</div>\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Drop an entire column:\n",
    "REDUCED_DF = MASTER_EVENTS_DF\n",
    "REDUCED_DF.drop(\n",
    "    columns=[\"username\"], inplace=True\n",
    ")  # dropped because unique for every row\n",
    "\n",
    "# Puts the scrollbar next to the DataFrame\n",
    "display(\n",
    "    HTML(\n",
    "        \"<div style='height: 600px; overflow: auto; width: fit-content'>\"\n",
    "        + REDUCED_DF.style.to_html()\n",
    "        + \"</div>\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download a subset and consistently change a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHANGED_DF = pd.json_normalize(EVENTS)\n",
    "print(\"Got Data: %s\" % len(CHANGED_DF.index))\n",
    "\n",
    "# seed the random generator to produce the same results\n",
    "faker = Faker()\n",
    "Faker.seed()\n",
    "\n",
    "# In this case we are replacing the username with the new\n",
    "dict_names = {name: faker.name() for name in CHANGED_DF[\"username\"].unique()}\n",
    "\n",
    "# Handy debug statement\n",
    "print(\"DEBUG dict_names: %s\" % json.dumps(dict_names, indent=4))\n",
    "\n",
    "CHANGED_DF[\"username\"] = CHANGED_DF[\"username\"].map(dict_names)\n",
    "\n",
    "# Puts the scrollbar next to the DataFrame\n",
    "display(\n",
    "    HTML(\n",
    "        \"<div style='height: 600px; overflow: auto; width: fit-content'>\"\n",
    "        + CHANGED_DF.style.to_html()\n",
    "        + \"</div>\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the file\n",
    "CHANGED_DF.to_csv(\"./my_outputfile.csv\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copyright 2024 DataRobot Inc\n",
    "\n",
    "**All Rights Reserved.**\n",
    "\n",
    "This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, express or implied."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

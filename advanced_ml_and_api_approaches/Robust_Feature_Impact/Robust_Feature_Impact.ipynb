{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ad9c4103-876a-4bcc-8210-2242544d48b9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Selecting robust features by permutation importance cross multiple seeds\n",
    "- Author: senkin.zhan@datarobot.com\n",
    "- demo data for regression or binary classfication: https://s3.amazonaws.com/datarobot_public_datasets/ai_accelerators/500_Lending_Club_Loans.csv\n",
    "- demo data for regression or multiple classfication: \n",
    "https://s3.amazonaws.com/datarobot_public_datasets/ai_accelerators/multiclass_lending_club.csv\n",
    "\n",
    "## Summary\n",
    "\n",
    "Machine learning models have biases using small data, and some industries such as health care and manufaturing lack labled data. In light of this, a good approach is to select robust features to build models.\n",
    "\n",
    "This accelerator introduces an approach to select robust features, use multiple seeds for cross validation, add dummy features to compute the median permutation importance, and then select the most robust dummy features.\n",
    "\n",
    "This notebook outlines how to:\n",
    "\n",
    "1. Connect to DataRobot\n",
    "2. Create multiple projects by multiple seeds and adding dummy features\n",
    "3. Create blend models of top-performing models\n",
    "4. Retrieve modeling permutation importance from the top-performing blend models\n",
    "5. Remove features whose permutation importance are lower than dummy features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### Install and import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas numpy datarobot boto3 plotly dask awswrangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "import zipfile\n",
    "\n",
    "import awswrangler as wr  # For aws s3 bucket read\n",
    "import boto3  # For aws credentials\n",
    "from dask import compute, delayed  # For parallelization\n",
    "import datarobot as dr\n",
    "from datarobot.models.dataset import Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bind variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1: Run this notebook at Local or DataRobot Notebooks\n",
    "ENV = \"local\"  # (\"local\" or \"dr_notebooks\")\n",
    "\n",
    "# 2: DataRobot API Token and end point\n",
    "TOKEN = \"<INSERT YOUR DataRobot API Token>\"  #  # can skip if use DataRobot Notebooks\n",
    "END_POINT = \"https://app.datarobot.com/api/v2\"\n",
    "AI_CATALOG_DATA_ID = \"<INSERT YOUR AI CATALOG DATASET ID>\"\n",
    "AWS_KEY = \"<INSERT YOUR AWS ACCESS KEY>\"\n",
    "AWS_SECRET = \"<INSERT YOUR AWS SECRET>\"\n",
    "AWS_S3_INPUT_PATH = \"<INSERT YOUR AWS S3 INPUT PATH>\"\n",
    "AWS_S3_OUTPUT_PATH = \"<INSERT YOUR AWS S3 OUTPUT PATH>\"\n",
    "\n",
    "# 3: Input and Output Path(file should be csv with UTF-8 encoding)\n",
    "input_folder = \"./input/\"\n",
    "output_folder = \"./output/\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "os.makedirs(input_folder, exist_ok=True)\n",
    "file_name = \"500_Lending_Club_Loans.csv\"  # input file name\n",
    "input_file = input_folder + file_name\n",
    "\n",
    "data_source = (\n",
    "    \"local\"  # (\"local\" or \"ai_catalog\" or \"aws_s3\", dr_notebooks can not use local)\n",
    ")\n",
    "data_output = [\"ai_catalog\", \"aws_s3\"]  # (\"ai_catalog\" or \"aws_s3\", multiple selects)\n",
    "\n",
    "# 4: Target, if multiclass, use 0,1,2... as target\n",
    "target = \"is_bad\"\n",
    "\n",
    "# 5: Regression task or not\n",
    "regression = False\n",
    "\n",
    "# 6: If regression choose 1, if binaryclass choose 2, if multiclass the number of class\n",
    "class_num = 2\n",
    "\n",
    "# 7: Cross Validation folds, 10 is recommended\n",
    "cv = 10\n",
    "\n",
    "# 8: Run how many times with random seed, 10 is recommended\n",
    "iteration = 10\n",
    "# max iteration is 10\n",
    "if iteration > 10:\n",
    "    iteration = 10\n",
    "\n",
    "# 9: Choose metric to measure best performance like \"AUC\" \"MAE\" \"R Squared\", if use default choose 0\n",
    "metrics = \"LogLoss\"\n",
    "\n",
    "# 10: Choose feature importance aggregation method like \"median\" \"min\", median is recommended\n",
    "how = \"median\"\n",
    "\n",
    "# 11: Keep series id column, if have multiple ids [\"ID1\",\"ID2\"], if none []\n",
    "keep_column = [\"ID\"]\n",
    "\n",
    "# 12: Use relative value or absolute values of feature impact. Absolute value is recommended\n",
    "impact_abs = True\n",
    "\n",
    "# 13: If enable partial dependency plot of top 5 features 。If True the running time become longer\n",
    "pdp = True\n",
    "\n",
    "# 14: If use groupkfold input group column [\"Group_ID\"], if not input False\n",
    "group_col = False\n",
    "\n",
    "# 15: If add error features(dummy features)。If true will add 3 0~100 random numeric features(error_1, error_2, error_3)\n",
    "error_feature = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to DataRobot\n",
    "\n",
    "You can read more about different options for [connecting to DataRobot from the client](https://docs.datarobot.com/en/docs/api/api-quickstart/api-qs.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __init_datarobot_env(end_point, token, env):\n",
    "    if env == \"local\":\n",
    "        c = dr.Client(\n",
    "            endpoint=end_point,\n",
    "            token=token,\n",
    "            connect_timeout=60,\n",
    "        )\n",
    "    else:\n",
    "        c = dr.Client()\n",
    "    print(\"DataRobot API Version:\", dr.__version__)\n",
    "    print(\"Endpoint:\", c.endpoint)\n",
    "    print(\"Connection:\", c.verify)\n",
    "\n",
    "\n",
    "__init_datarobot_env(END_POINT, TOKEN, ENV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __read_inputs(input_path, ext, error_feature, target, keep_column, group_col):\n",
    "    # check extension and deal with。If input Excel, should install xlrd by pip.\n",
    "    def read_file_autohandle(input_path, ext):\n",
    "        if ext == \".csv\":\n",
    "            result = pd.read_csv(input_path, encoding=\"utf-8-sig\")\n",
    "            found_csv = False\n",
    "            return result, found_csv\n",
    "        elif ext == \".zip\":\n",
    "            with zipfile.ZipFile(input_path) as existing_zip:\n",
    "                existing_zip.extractall(zip_folder)\n",
    "\n",
    "            def check_files(zip_folder):\n",
    "                tmp_folder = \"\"\n",
    "                result = \"\"\n",
    "                found_csv = False\n",
    "                for f in os.listdir(zip_folder):\n",
    "                    file, ext2 = os.path.splitext(f)\n",
    "                    if ext2 == \".csv\":\n",
    "                        result = pd.read_csv(\n",
    "                            zip_folder + \"/\" + file + \".csv\", encoding=\"utf-8-sig\"\n",
    "                        )\n",
    "                        found_csv = zip_folder\n",
    "                        break\n",
    "                    if (ext2 == \"\") and (file != \".DS_Store\"):\n",
    "                        print(file)\n",
    "                        tmp_folder = zip_folder + \"/\" + file + \"/\"\n",
    "                    else:\n",
    "                        continue\n",
    "                return result, found_csv, tmp_folder\n",
    "\n",
    "            # check zip folder\n",
    "            result, found_csv, tmp_folder = check_files(zip_folder)\n",
    "            if found_csv == False:\n",
    "                result, found_csv, tmp_folder = check_files(tmp_folder)\n",
    "                if found_csv == False:\n",
    "                    result, found_csv, tmp_folder = check_files(tmp_folder)\n",
    "            return result, found_csv\n",
    "\n",
    "        else:\n",
    "            print(\"Please input csv file.\")\n",
    "\n",
    "    df_x, found_csv = read_file_autohandle(input_path, ext)\n",
    "\n",
    "    # if use error_feature,generate random numeric features.\n",
    "    if error_feature == True:\n",
    "        # setup numpy seed\n",
    "        np.random.seed(seed=1)\n",
    "        df_x[\"error_1\"] = np.random.randn(len(df_x))\n",
    "        df_x[\"error_2\"] = np.random.randn(len(df_x))\n",
    "        df_x[\"error_3\"] = np.random.randn(len(df_x))\n",
    "\n",
    "    # create dataframe with different keep_column and group_column conditions\n",
    "    df_y = df_x[target]\n",
    "    df_id = pd.DataFrame()\n",
    "    if len(keep_column) != 0:\n",
    "        df_id = pd.DataFrame(df_x[keep_column])\n",
    "        df_x.drop(columns=keep_column, inplace=True)\n",
    "        if group_col != False:\n",
    "            df_id[group_col] = df_x[group_col]\n",
    "    if len(keep_column) == 0:\n",
    "        if group_col != False:\n",
    "            df_id = df_x[group_col]\n",
    "\n",
    "    # features naming should be same as datarobot's special symbols\n",
    "    for col in df_x.columns:\n",
    "        df_x.rename(\n",
    "            columns={\n",
    "                col: col.replace(\"{\", \"_\")\n",
    "                .replace(\"-\", \"_\")\n",
    "                .replace(\"$\", \"_\")\n",
    "                .replace(\".\", \"_\")\n",
    "                .replace(\"}\", \"_\")\n",
    "                .replace(\"\\n\", \"_\")\n",
    "                .replace('\"', \"_\")\n",
    "            },\n",
    "            inplace=True,\n",
    "        )\n",
    "\n",
    "    # if use zip,found the file inside zip then create new csv file\n",
    "    if ext == \".zip\":\n",
    "        for f in os.listdir(found_csv):\n",
    "            _, ext2 = os.path.splitext(f)\n",
    "            if ext2 == \".csv\":\n",
    "                df_x.to_csv(found_csv + f, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "        # create new zip file using the new csv file\n",
    "        with zipfile.ZipFile(\n",
    "            zip_folder[:-1] + \".zip\", \"w\", compression=zipfile.ZIP_STORED\n",
    "        ) as new_zip:\n",
    "            for folder, subfolders, files in os.walk(zip_folder):\n",
    "                new_zip.write(folder)\n",
    "                for file in files:\n",
    "                    new_zip.write(os.path.join(folder, file))\n",
    "\n",
    "    return (df_id, df_x, df_y)\n",
    "\n",
    "\n",
    "# define zip folder if use zip file\n",
    "f, _ = os.path.splitext(input_folder + file_name)\n",
    "zip_folder = str(dt.date.today()) + \"_temp_{0}/\".format(f)\n",
    "\n",
    "# get input file extension\n",
    "_, ext = os.path.splitext(input_folder + file_name)\n",
    "\n",
    "# save input csv to input folder\n",
    "if data_source == \"local\":\n",
    "    print(\"Put the csv file to \" + input_folder)\n",
    "if data_source == \"ai_catalog\":\n",
    "    dataset_id = AI_CATALOG_DATA_ID  # ai_catalog id, eg. \"64a2520bf822342ecfb8fcc\"\n",
    "    dataset = Dataset.get(dataset_id)\n",
    "    dataset.get_as_dataframe().to_csv(input_file, index=False)  # save to input folder\n",
    "if data_source == \"aws_s3\":\n",
    "    my_session = boto3.Session(\n",
    "        aws_access_key_id=AWS_KEY, aws_secret_access_key=AWS_SECRET\n",
    "    )  # aws access_key and secret_access_key\n",
    "    dataset = wr.s3.read_csv(\n",
    "        path=AWS_S3_INPUT_PATH,\n",
    "        dataset=True,\n",
    "        boto3_session=my_session,\n",
    "        encoding=\"ISO-8859-1\",\n",
    "    )  # path is bucket path like 's3://senkin-demo/'\n",
    "    dataset.to_csv(input_file, index=False)  # save to input folder\n",
    "\n",
    "df_id, df_x, df_y = __read_inputs(\n",
    "    input_file, ext, error_feature, target, keep_column, group_col\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create multiple projects cross multiple seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "def __run_autopilot(\n",
    "    i, target, zip_folder, input_file, ext, df_x, group_col, regression, cv\n",
    "):\n",
    "    # if use zip file,load new zip file or else load df_x\n",
    "    if ext == \".zip\":\n",
    "        project = dr.Project.create(\n",
    "            zip_folder[:-1] + \".zip\",\n",
    "            project_name=str(dt.date.today()) + \"_\" + input_file + \"_Seed\" + str(i),\n",
    "        )\n",
    "    else:\n",
    "        project = dr.Project.create(\n",
    "            df_x,\n",
    "            project_name=str(dt.date.today()) + \"_\" + input_file + \"_Seed\" + str(i),\n",
    "        )\n",
    "\n",
    "    ao = dr.AdvancedOptions(seed=i)\n",
    "    if group_col != False:\n",
    "        pm = dr.GroupCV(holdout_pct=0, partition_key_cols=[group_col], reps=cv, seed=i)\n",
    "    elif regression == False:\n",
    "        if class_num == 2:\n",
    "            pm = dr.StratifiedCV(holdout_pct=0, reps=cv, seed=i)\n",
    "        else:\n",
    "            pm = dr.RandomCV(holdout_pct=0, reps=cv, seed=i)\n",
    "    elif regression == True:\n",
    "        pm = dr.RandomCV(holdout_pct=0, reps=cv, seed=i)\n",
    "    try:\n",
    "        if class_num <= 2:\n",
    "            project.analyze_and_model(\n",
    "                worker_count=-1,\n",
    "                target=target,\n",
    "                mode=\"quick\",\n",
    "                partitioning_method=pm,\n",
    "                advanced_options=ao,\n",
    "                max_wait=10000,\n",
    "            )\n",
    "        else:\n",
    "            project.analyze_and_model(\n",
    "                worker_count=-1,\n",
    "                target=target,\n",
    "                mode=\"quick\",\n",
    "                partitioning_method=pm,\n",
    "                advanced_options=ao,\n",
    "                target_type=\"Multiclass\",\n",
    "                max_wait=10000,\n",
    "            )\n",
    "        print(\"The new project has ID for seed {} is\".format(i), project.id)\n",
    "\n",
    "    except:\n",
    "        print(\"The seed {} has occured error\".format(i))\n",
    "\n",
    "    return project\n",
    "\n",
    "\n",
    "delayed_dr_projects = []\n",
    "\n",
    "for seed in range(1, iteration + 1):\n",
    "    temp = delayed(__run_autopilot)(\n",
    "        seed, target, zip_folder, input_file, ext, df_x, group_col, regression, cv\n",
    "    )\n",
    "    delayed_dr_projects.append(temp)\n",
    "\n",
    "projects = compute(delayed_dr_projects)[0]\n",
    "project_id_list = []\n",
    "for p in projects:\n",
    "    project_id_list.append(p.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wait for autopilot completed and run cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "def __get_model_scores(project):\n",
    "    return pd.DataFrame(\n",
    "        [\n",
    "            [\n",
    "                model.metrics[project.metric][\"crossValidation\"],\n",
    "                model.metrics[project.metric][\"validation\"],\n",
    "                model.model_type,\n",
    "                model.id,\n",
    "                model.sample_pct,\n",
    "                model.model_category,\n",
    "                model,\n",
    "                model.blueprint_id,\n",
    "            ]\n",
    "            for model in project.get_model_records(with_metric=project.metric)\n",
    "        ],\n",
    "        columns=[\n",
    "            \"cv\",\n",
    "            \"v\",\n",
    "            \"type\",\n",
    "            \"model_id\",\n",
    "            \"sample_pct\",\n",
    "            \"category\",\n",
    "            \"model\",\n",
    "            \"blueprint_id\",\n",
    "        ],\n",
    "    ).sort_values([\"cv\", \"v\"], na_position=\"last\")\n",
    "\n",
    "\n",
    "def __run_cross_validation(projects, i):\n",
    "    try:\n",
    "        project = dr.Project.get(project_id=projects[i - 1].id)\n",
    "        project.wait_for_autopilot(check_interval=60.0, timeout=800000, verbosity=1)\n",
    "        print(\"Autopilot of the project for seed \" + str(i + 1) + \" is completed\")\n",
    "        print(\"Confirming CV status....\")\n",
    "        jobs_list = project.get_all_jobs()\n",
    "        for job in jobs_list:\n",
    "            job.wait_for_completion(max_wait=60000)\n",
    "\n",
    "        df_model = __get_model_scores(project)\n",
    "\n",
    "        # if can build 100% sample size model,run cross validation first\n",
    "        if max(df_model[\"sample_pct\"]) == 100:\n",
    "            df_model = df_model[\n",
    "                df_model[\"sample_pct\"] == sorted(list(set(df_model[\"sample_pct\"])))[-2]\n",
    "            ]\n",
    "            df_model = df_model[df_model[\"category\"] == \"model\"]\n",
    "            for model in df_model[df_model[\"cv\"].isnull()][\"model\"]:\n",
    "                print(\"Seed\" + str(i) + \" \" + model.model_type + \" started CV\")\n",
    "                model.cross_validate()\n",
    "        else:\n",
    "            print(\"Seed \" + str(i) + \" looks error occured. Ignored\")\n",
    "    except:\n",
    "        print(\"Seed {} has occured error\".format(i))\n",
    "\n",
    "\n",
    "delayed_dr_projects = []\n",
    "\n",
    "for seed in range(1, iteration + 1):\n",
    "    temp = delayed(__run_cross_validation)(projects, seed)\n",
    "    delayed_dr_projects.append(temp)\n",
    "\n",
    "compute(delayed_dr_projects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wait for cross validation completed and create blend model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "def __wait_for_cv(projects, iteration):\n",
    "    for i in range(1, iteration + 1):\n",
    "        try:\n",
    "            project = dr.Project.get(project_id=projects[i - 1].id)\n",
    "            jobs_list = project.get_all_jobs()\n",
    "            for job in jobs_list:\n",
    "                job.wait_for_completion(max_wait=60000)\n",
    "            print(\"completed CV of in seed\" + str(i))\n",
    "        except:\n",
    "            print(\"Seed {} has occured error\".format(i))\n",
    "\n",
    "\n",
    "def __get_blender_detail(project):\n",
    "    return pd.DataFrame(\n",
    "        [\n",
    "            [\n",
    "                model.model_type,\n",
    "                model.id,\n",
    "                model.sample_pct,\n",
    "                model.model_category,\n",
    "                model,\n",
    "                model.blender_method,\n",
    "                model.model_ids,\n",
    "            ]\n",
    "            for model in project.get_blenders()\n",
    "        ],\n",
    "        columns=[\n",
    "            \"type\",\n",
    "            \"model_id\",\n",
    "            \"sample_pct\",\n",
    "            \"category\",\n",
    "            \"model\",\n",
    "            \"blueprint_method\",\n",
    "            \"model_ids\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "\n",
    "def __create_blender(projects, i):\n",
    "    def _sort_leader_board(project):\n",
    "        df_model = __get_model_scores(project)\n",
    "        df_model = df_model[df_model[\"category\"] == \"model\"]\n",
    "        df_model = df_model[\n",
    "            df_model[\"sample_pct\"] == sorted(list(set(df_model[\"sample_pct\"])))[-2]\n",
    "        ]\n",
    "        parent_models = [model.id for model in df_model[\"model\"]]\n",
    "        return parent_models\n",
    "\n",
    "    def _run_blender(project, parent_models):\n",
    "        blender_method = [\"GLM\", \"ENET\", \"AVG\", \"MED\"]\n",
    "        df_blender = __get_blender_detail(project)\n",
    "        for j in range(3, 7):\n",
    "            if len(parent_models) < j:\n",
    "                continue\n",
    "            for b in blender_method:\n",
    "                if project.check_blendable(parent_models[:j], b).supported == True:\n",
    "                    df_tmp_blenders = df_blender[df_blender.blueprint_method == b]\n",
    "                    check = [\n",
    "                        set(df_tmp_blenders.model_ids.iloc[x]) == set(parent_models[:j])\n",
    "                        for x in range(0, len(df_tmp_blenders))\n",
    "                    ]\n",
    "                    if any(check) != True:\n",
    "                        project.blend(parent_models[:j], b)\n",
    "                        print(\n",
    "                            b\n",
    "                            + \" blender \"\n",
    "                            + str(j)\n",
    "                            + \" models for project \"\n",
    "                            + str(i + 1)\n",
    "                            + \" started\"\n",
    "                        )\n",
    "                    else:\n",
    "                        print(\n",
    "                            b\n",
    "                            + \" blender \"\n",
    "                            + str(j)\n",
    "                            + \" models for project \"\n",
    "                            + str(i + 1)\n",
    "                            + \" was created already\"\n",
    "                        )\n",
    "                else:\n",
    "                    print(b + \" was not supported\")\n",
    "\n",
    "    try:\n",
    "        project = dr.Project.get(project_id=projects[i - 1].id)\n",
    "        parent_models = _sort_leader_board(project)\n",
    "        _run_blender(project, parent_models)\n",
    "        print(\"started creating all blenders for project \" + str(i))\n",
    "    except:\n",
    "        print(\"Seed {} has occured error\".format(i))\n",
    "\n",
    "\n",
    "__wait_for_cv(projects, iteration)\n",
    "delayed_dr_projects = []\n",
    "\n",
    "for seed in range(1, iteration + 1):\n",
    "    temp = delayed(__create_blender)(projects, seed)\n",
    "    delayed_dr_projects.append(temp)\n",
    "\n",
    "compute(delayed_dr_projects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wait for blend compeleted and retrieve permutation importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "def __get_impact(projects, i, impact_abs):\n",
    "    feature_impact = {}\n",
    "    try:\n",
    "        project = dr.Project.get(project_id=projects[i - 1].id)\n",
    "        jobs_list = project.get_all_jobs()\n",
    "        print(\"Waiting blenders finished in seed\" + str(i))\n",
    "        for job in jobs_list:\n",
    "            job.wait_for_completion(max_wait=60000)\n",
    "        print(\"Completed seed\" + str(i))\n",
    "        df_model = __get_model_scores(project)\n",
    "        df_model = df_model[df_model[\"category\"] == \"blend\"]\n",
    "\n",
    "        model = dr.Model.get(projects[i - 1].id, df_model.iloc[0, 3])\n",
    "        print(\"Request and get feature impact for seed\" + str(i))\n",
    "        feature_impact[i] = model.get_or_request_feature_impact(max_wait=60000)\n",
    "\n",
    "        df_tmp2 = pd.DataFrame(\n",
    "            feature_impact[i],\n",
    "            columns=[\n",
    "                \"redundantWith\",\n",
    "                \"featureName\",\n",
    "                \"impactNormalized\",\n",
    "                \"impactUnnormalized\",\n",
    "            ],\n",
    "        )\n",
    "        if impact_abs == False:\n",
    "            df_tmp2 = pd.DataFrame(df_tmp2[[\"featureName\", \"impactNormalized\"]])\n",
    "            df_tmp2 = df_tmp2.rename(columns={\"impactNormalized\": \"Seed_\" + str(i)})\n",
    "        else:\n",
    "            df_tmp2 = pd.DataFrame(df_tmp2[[\"featureName\", \"impactUnnormalized\"]])\n",
    "            df_tmp2 = df_tmp2.rename(columns={\"impactUnnormalized\": \"Seed_\" + str(i)})\n",
    "        fn_list = list(df_tmp2[\"featureName\"])\n",
    "        df_tmp2 = df_tmp2.T\n",
    "        df_tmp2.columns = fn_list\n",
    "        df_tmp2 = df_tmp2.drop(df_tmp2.index[0])\n",
    "    except:\n",
    "        print(\"Seed {} has occured error\".format(i))\n",
    "\n",
    "    return df_tmp2\n",
    "\n",
    "\n",
    "delayed_dr_projects = []\n",
    "\n",
    "for seed in range(1, iteration + 1):\n",
    "    temp = delayed(__get_impact)(projects, seed, impact_abs)\n",
    "    delayed_dr_projects.append(temp)\n",
    "\n",
    "df_tmp = compute(delayed_dr_projects)[0]\n",
    "df_tmp = pd.concat(df_tmp)\n",
    "\n",
    "df_tmp = df_tmp.fillna(0)\n",
    "df_stat = pd.DataFrame()\n",
    "df_stat[\"max\"] = df_tmp.max()\n",
    "df_stat[\"median\"] = df_tmp.median()\n",
    "df_stat[\"min\"] = df_tmp.min()\n",
    "df_output = pd.concat([df_tmp, df_stat.T])\n",
    "if how == \"min\":\n",
    "    df_output = df_output.T.sort_values(by=[\"min\", \"median\", \"max\"], ascending=False)\n",
    "else:\n",
    "    df_output = df_output.T.sort_values(by=[\"median\", \"max\"], ascending=False)\n",
    "df_output = df_output.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Create Log file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __create_log(\n",
    "    project_id_list, iteration, metrics, input_file, target, regression, cv, group_col\n",
    "):\n",
    "    model_lists, model_name, metric_name, cross_val_score, model_id, sample_pct = (\n",
    "        {},\n",
    "        [],\n",
    "        [],\n",
    "        [],\n",
    "        [],\n",
    "        [],\n",
    "    )\n",
    "    print(\"Preparting export files...\")\n",
    "    # create Log file\n",
    "    for i in range(0, iteration):\n",
    "        try:\n",
    "            project = dr.Project.get(project_id=project_id_list[i])\n",
    "            df_model = __get_model_scores(project)\n",
    "            df_model = df_model[df_model[\"category\"] == \"blend\"]\n",
    "            model = dr.Model.get(project_id_list[i], df_model.iloc[0, 3])\n",
    "            model_name.append(model.model_type)\n",
    "            if metrics == 0:\n",
    "                met = project.metric\n",
    "                metric_name.append(met)\n",
    "                cross_val_score.append(model.metrics[met][\"crossValidation\"])\n",
    "            if metrics != 0:\n",
    "                metric_name.append(metrics)\n",
    "                cross_val_score.append(model.metrics[metrics][\"crossValidation\"])\n",
    "\n",
    "            model_id.append(model.id)\n",
    "            sample_pct.append(model.sample_pct)\n",
    "            df_model = __get_model_scores(project)\n",
    "            df_model = df_model[df_model[\"category\"] == \"model\"]\n",
    "            df_model = df_model[\n",
    "                df_model[\"sample_pct\"] == sorted(list(set(df_model[\"sample_pct\"])))[-2]\n",
    "            ]\n",
    "            model_lists[i] = df_model.iloc[:, 2]\n",
    "        except:\n",
    "            print(\"Seed {} has occured error\".format(i))\n",
    "\n",
    "    # create DataFrame from log file\n",
    "    df_log = pd.DataFrame(\n",
    "        project_id_list,\n",
    "        columns=[\"project_id\"],\n",
    "        index=[\"Seed_\" + str(i) for i in range(1, iteration + 1)],\n",
    "    )\n",
    "    df_log[\"model_name\"] = model_name\n",
    "    df_log[\"metric_name\"] = metric_name\n",
    "    df_log[\"CV_score\"] = cross_val_score\n",
    "    df_log[\"model_id\"] = model_id\n",
    "    df_log[\"sample_pct\"] = sample_pct\n",
    "    df_log[\"input_file\"] = input_file\n",
    "    df_log[\"target\"] = target\n",
    "    df_log[\"regression\"] = regression\n",
    "    df_log[\"cv_number\"] = cv\n",
    "    df_log[\"group_cv\"] = group_col\n",
    "    model_rank = []\n",
    "    for i in range(0, iteration):\n",
    "        model_rank_temp = []\n",
    "        for j in range(0, 5):\n",
    "            if project_id_list[i] == \"error\":\n",
    "                model_rank_temp.append(\"error\")\n",
    "            else:\n",
    "                model_tmp = model_lists[i].reset_index()[\"type\"][j]\n",
    "                model_rank_temp.append(model_tmp)\n",
    "        model_rank.append(model_rank_temp)\n",
    "    df_tmp = pd.DataFrame(\n",
    "        model_rank,\n",
    "        index=[\"Seed_\" + str(i) for i in range(1, iteration + 1)],\n",
    "        columns=[\"Model_rank_\" + str(i) for i in range(1, 6)],\n",
    "    )\n",
    "    df_log = pd.concat([df_log, df_tmp], axis=1)\n",
    "    return df_log\n",
    "\n",
    "\n",
    "df_log = __create_log(\n",
    "    project_id_list, iteration, metrics, input_file, target, regression, cv, group_col\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_associations_df(df_output, project_id_list, output_folder):\n",
    "    project = dr.Project.get(project_id=[x for x in project_id_list if x != \"error\"][0])\n",
    "    association_data = project.get_associations(\n",
    "        assoc_type=\"association\", metric=\"mutualInfo\"\n",
    "    )\n",
    "    df = pd.DataFrame(association_data[\"strengths\"])\n",
    "    df = df[~(df[\"feature1\"] == df[\"feature2\"])]\n",
    "\n",
    "    df_med = df_output.T[\"median\"].reset_index()\n",
    "    df = pd.merge(df, df_med, left_on=\"feature1\", right_on=\"index\")\n",
    "    df.drop(columns=\"index\", inplace=True)\n",
    "    df.rename(\n",
    "        columns={\"median\": \"feature1_median_imp\", \"statistic\": \"mutual_information\"},\n",
    "        inplace=True,\n",
    "    )\n",
    "    df = pd.merge(df, df_med, left_on=\"feature2\", right_on=\"index\")\n",
    "    df.drop(columns=\"index\", inplace=True)\n",
    "    df.rename(columns={\"median\": \"feature2_median_imp\"}, inplace=True)\n",
    "\n",
    "    df_min = df_output.T[\"min\"].reset_index()\n",
    "    df = pd.merge(df, df_min, left_on=\"feature1\", right_on=\"index\")\n",
    "    df.drop(columns=\"index\", inplace=True)\n",
    "    df.rename(columns={\"min\": \"feature1_min_imp\"}, inplace=True)\n",
    "    df = pd.merge(df, df_min, left_on=\"feature2\", right_on=\"index\")\n",
    "    df.drop(columns=\"index\", inplace=True)\n",
    "    df.rename(columns={\"min\": \"feature2_min_imp\"}, inplace=True)\n",
    "    df = df[\n",
    "        [\n",
    "            \"feature1\",\n",
    "            \"feature1_median_imp\",\n",
    "            \"feature1_min_imp\",\n",
    "            \"feature2\",\n",
    "            \"feature2_median_imp\",\n",
    "            \"feature2_min_imp\",\n",
    "            \"mutual_information\",\n",
    "        ]\n",
    "    ]\n",
    "    df = df.sort_values(\"mutual_information\", ascending=False)\n",
    "    df = df.reset_index()\n",
    "    df.drop(columns=\"index\", inplace=True)\n",
    "\n",
    "    def order_change(x):\n",
    "        if x.feature1_median_imp < x.feature2_median_imp:\n",
    "            x.featureX = x.feature1\n",
    "            x.feature1 = x.feature2\n",
    "            x.feature2 = x.featureX\n",
    "            x.featureX_median_imp = x.feature1_median_imp\n",
    "            x.feature1_median_imp = x.feature2_median_imp\n",
    "            x.feature2_median_imp = x.featureX_median_imp\n",
    "            x.featureX_min_imp = x.feature1_min_imp\n",
    "            x.feature1_min_imp = x.feature2_min_imp\n",
    "            x.feature2_min_imp = x.featureX_min_imp\n",
    "        return x\n",
    "\n",
    "    df = df.apply(lambda x: order_change(x), axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "## Check features relevance. Output the relevance values of feature impacts cross all seeds among the top 50 most useful features\n",
    "## Display the larger median impact cross the seeds on the feature1 column.\n",
    "\n",
    "\n",
    "df_association = get_associations_df(df_output, project_id_list, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_association"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting permutation importance and feature effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def __get_effects(project_id_list, iteration, topx):\n",
    "    feature_effects = {}\n",
    "    for i in range(0, iteration):\n",
    "        try:\n",
    "            project = dr.Project.get(project_id=project_id_list[i])\n",
    "            df_model = __get_model_scores(project)\n",
    "            df_model = df_model[df_model[\"category\"] == \"blend\"].reset_index(drop=True)\n",
    "            model = dr.Model.get(project_id_list[i], df_model.iloc[0, 3])\n",
    "            model.get_feature_effect_metadata()\n",
    "            if class_num <= 2:\n",
    "                model.request_feature_effect()\n",
    "            else:\n",
    "                model.request_feature_effects_multiclass(top_n_features=topx)\n",
    "        except:\n",
    "            print(\"Seed {} has occured error\".format(i))\n",
    "\n",
    "    for i in range(0, iteration):\n",
    "        try:\n",
    "            project = dr.Project.get(project_id=project_id_list[i])\n",
    "            jobs_list = project.get_all_jobs()\n",
    "            print(\"Waiting feature effect seed \" + str(i + 1))\n",
    "            for job in jobs_list:\n",
    "                job.wait_for_completion(max_wait=60000)\n",
    "            df_model = __get_model_scores(project)\n",
    "            df_model = df_model[df_model[\"category\"] == \"blend\"].reset_index(drop=True)\n",
    "            model = dr.Model.get(project_id_list[i], df_model.iloc[0, 3])\n",
    "            if class_num <= 2:\n",
    "                feature_effects[i] = model.get_feature_effect(\"validation\")\n",
    "            else:\n",
    "                feature_effects[i] = model.get_feature_effects_multiclass(\"validation\")\n",
    "        except:\n",
    "            print(\"Seed {} has occured error\".format(i))\n",
    "\n",
    "    return feature_effects\n",
    "\n",
    "\n",
    "# show top x features effects\n",
    "if pdp:\n",
    "    topx = 100\n",
    "    feature_effects = __get_effects(project_id_list, iteration, topx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __create_graph(df_output2, output_folder, how, topx, exp=True):\n",
    "    os.makedirs(output_folder + \"graph/\", exist_ok=True)\n",
    "    df_graph = df_output2.T.copy()\n",
    "    if how == \"min\":\n",
    "        df_graph = df_graph.sort_values(by=[\"min\", \"median\", \"max\"], ascending=True)\n",
    "        df_graph = df_graph.tail(topx)\n",
    "    else:\n",
    "        df_graph = df_graph.sort_values(by=[\"median\", \"max\"], ascending=True)\n",
    "        df_graph = df_graph.tail(topx)\n",
    "\n",
    "    # create histogram\n",
    "    x = df_graph[\"median\"].values\n",
    "    y = df_graph.index.values\n",
    "    fig = go.Figure(\n",
    "        data=go.Bar(\n",
    "            x=x,\n",
    "            y=y,\n",
    "            orientation=\"h\",\n",
    "            error_x=dict(\n",
    "                type=\"data\",\n",
    "                symmetric=False,\n",
    "                array=df_graph[\"max\"] - df_graph[\"median\"],\n",
    "                arrayminus=df_graph[\"median\"] - df_graph[\"min\"],\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "    fig.update_yaxes(type=\"category\", dtick=1)\n",
    "    fig.update_layout(\n",
    "        height=800,\n",
    "        width=800,\n",
    "        title=\"Feature impact among seeds - Bar plot\",\n",
    "        xaxis_title=\"Feature impact\",\n",
    "        yaxis_title=\"Feature\",\n",
    "    )\n",
    "    fig.show()\n",
    "    if exp == True:\n",
    "        plotly.offline.plot(\n",
    "            fig,\n",
    "            filename=output_folder + \"graph/\" + str(how) + \"_bar.html\",\n",
    "            auto_open=False,\n",
    "        )\n",
    "\n",
    "    # create Box\n",
    "    if how == \"min\":\n",
    "        df_graph = df_graph.sort_values(by=[\"min\", \"median\", \"max\"], ascending=False)\n",
    "    else:\n",
    "        df_graph = df_graph.sort_values(by=[\"median\", \"max\"], ascending=False)\n",
    "    df_graph = df_graph.T\n",
    "    df_graph.drop([\"max\", \"median\", \"min\"], inplace=True, axis=0)\n",
    "    df_graph = df_graph.reset_index()\n",
    "\n",
    "    fig = go.Figure()\n",
    "    for col in df_graph.columns[1:]:\n",
    "        fig.add_trace(\n",
    "            go.Box(y=df_graph[col], name=col)\n",
    "        )  # ,hovertext=df_graph[\"index\"]))\n",
    "    fig.update_xaxes(type=\"category\", dtick=1)\n",
    "    fig.update_traces(boxpoints=\"all\", jitter=0.5)\n",
    "    fig.update_layout(\n",
    "        height=800,\n",
    "        width=800,\n",
    "        title=\"Feature impact among seeds - Box plot\",\n",
    "        yaxis_title=\"Feature impact\",\n",
    "    )\n",
    "    fig.show()\n",
    "    if exp == True:\n",
    "        plotly.offline.plot(\n",
    "            fig,\n",
    "            filename=output_folder + \"graph/\" + str(how) + \"_box.html\",\n",
    "            auto_open=False,\n",
    "        )\n",
    "\n",
    "    # create Violine\n",
    "    fig = go.Figure()\n",
    "    for col in df_graph.columns[1:]:\n",
    "        fig.add_trace(\n",
    "            go.Violin(y=df_graph[col], name=col)\n",
    "        )  # , hovertext=df_graph[\"index\"]))\n",
    "    fig.update_xaxes(type=\"category\", dtick=1)\n",
    "    fig.update_traces(points=\"all\", jitter=0.5, box_visible=True)\n",
    "    fig.update_layout(\n",
    "        height=800,\n",
    "        width=800,\n",
    "        title=\"Feature impact among seeds - Violine plot\",\n",
    "        yaxis_title=\"Feature impact\",\n",
    "    )\n",
    "    fig.show()\n",
    "    if exp == True:\n",
    "        plotly.offline.plot(\n",
    "            fig,\n",
    "            filename=output_folder + \"graph/\" + str(how) + \"_violine.html\",\n",
    "            auto_open=False,\n",
    "        )\n",
    "        print(\"All files are exported\")\n",
    "\n",
    "\n",
    "# show top x features permutation importance\n",
    "topx = 100\n",
    "__create_graph(df_output, output_folder, how, topx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pdp(feature_effects, i):\n",
    "    df = pd.DataFrame()\n",
    "    fe = feature_effects[i]\n",
    "    for r in range(len(fe)):\n",
    "        row = str(fe[r])\n",
    "        row = (\n",
    "            row.replace(\"class=\", \"'class':\")\n",
    "            .replace(\"feature_name=\", \"'feature_name':'\")\n",
    "            .replace(\", feature_type=\", \"', 'feature_type':'\")\n",
    "            .replace(\", feature_impact_score=\", \"', 'feature_impact_score':\")\n",
    "            .replace(\"weight_label=\", \"'weight_label':\")\n",
    "            .replace(\"partial_dependence=\", \"'partial_dependence':\")\n",
    "            .replace(\"predicted_vs_actual=\", \"'predicted_vs_actual':\")\n",
    "            .replace(\"FeatureEffectsMulticlass(\", \"{\")\n",
    "            .replace(\"}]})\", \"}]}}\")\n",
    "            .replace(\"False\", \"0\")\n",
    "            .replace(\"True\", \"1\")\n",
    "            .replace(\"'\", '\"')\n",
    "            .replace(\"None\", '\"None\"')\n",
    "        )\n",
    "\n",
    "        row = json.loads(row)\n",
    "        row = pd.json_normalize(row).reset_index(drop=True)\n",
    "        df = pd.concat([df, row])\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def __create_effect_plot(\n",
    "    df_output2, output_folder, feature_effects, iteration, topx, project_id_list, df_x\n",
    "):\n",
    "    max_dependence = 0\n",
    "    min_dependence = 100\n",
    "    os.makedirs(output_folder + \"pdp/\", exist_ok=True)\n",
    "\n",
    "    if class_num <= 2:\n",
    "        file_num = 1\n",
    "    else:\n",
    "        file_num = class_num\n",
    "\n",
    "    for class_no in range(file_num):\n",
    "        for x in df_output2.columns[:topx]:\n",
    "            effect = pd.DataFrame()\n",
    "            for i in range(0, iteration):\n",
    "                if project_id_list[i] == \"error\":\n",
    "                    continue\n",
    "                if class_num <= 2:\n",
    "                    df_feature_effects = pd.json_normalize(feature_effects[i])\n",
    "                    df_feature_effects[\"class\"] = 0\n",
    "                else:\n",
    "                    df_feature_effects = extract_pdp(feature_effects, i)\n",
    "                df = df_feature_effects[df_feature_effects[\"class\"] == class_no]\n",
    "                df_x_class = df_x[df_x[\"class\"] == class_no]\n",
    "                if x in list(df[\"feature_name\"]):\n",
    "                    z = pd.DataFrame()\n",
    "                    z = list(df[df[\"feature_name\"] == x][\"partial_dependence.data\"])\n",
    "\n",
    "                    def flatten_2d(data):\n",
    "                        for block in data:\n",
    "                            for elem in block:\n",
    "                                yield elem\n",
    "\n",
    "                    z = list(flatten_2d(z))\n",
    "                    z = pd.DataFrame(z)\n",
    "                    effect[[\"label\", \"seed\" + str(i + 1)]] = z[[\"label\", \"dependence\"]]\n",
    "                    if max_dependence < z[\"dependence\"].max():\n",
    "                        max_dependence = z[\"dependence\"].max()\n",
    "                    if min_dependence > z[\"dependence\"].min():\n",
    "                        min_dependence = z[\"dependence\"].min()\n",
    "                    if list(df[df[\"feature_name\"] == x][\"feature_type\"]) == [\"numeric\"]:\n",
    "                        effect[\"label\"] = effect[\"label\"].astype(\"float\")\n",
    "                    else:\n",
    "\n",
    "                        def order(effect, df_x_class, x):\n",
    "                            l_order = list(df_x_class[x].value_counts().index)\n",
    "                            j = 0\n",
    "                            l_order_dic = {}\n",
    "                            for x in l_order:\n",
    "                                l_order_dic[x] = j\n",
    "                                j += 1\n",
    "                            effect[\"order\"] = effect[\"label\"].map(l_order_dic)\n",
    "                            effect[\"order\"] = effect[\"order\"].fillna(j)\n",
    "                            effect = effect.sort_values(\"order\")\n",
    "                            effect.drop(columns=\"order\", inplace=True)\n",
    "                            return effect\n",
    "\n",
    "                        effect = order(effect, df_x_class, x)\n",
    "\n",
    "            if x in list(df[\"feature_name\"]):\n",
    "                effect[\"mean\"] = effect.iloc[:, 1:].mean(axis=1)\n",
    "                effect.to_csv(\n",
    "                    output_folder + \"pdp/\" + x + \"_class\" + str(class_no) + \"_pdp.csv\",\n",
    "                    index=False,\n",
    "                    encoding=\"utf-8-sig\",\n",
    "                )\n",
    "\n",
    "    for x in df_output2.columns[:topx]:\n",
    "        if x in list(df[\"feature_name\"]):\n",
    "            for class_no in range(file_num):\n",
    "                df_x_class = df_x[df_x[\"class\"] == class_no]\n",
    "                effect = pd.read_csv(\n",
    "                    output_folder + \"pdp/\" + x + \"_class\" + str(class_no) + \"_pdp.csv\",\n",
    "                    encoding=\"utf-8-sig\",\n",
    "                )\n",
    "                if effect[\"label\"].nunique() != 1:\n",
    "                    effect.dropna(inplace=True)\n",
    "                    fig = go.Figure()\n",
    "                    if list(df[df[\"feature_name\"] == x][\"feature_type\"]) == [\"numeric\"]:\n",
    "                        for y in effect.columns[1:]:\n",
    "                            if y == effect.columns[-1]:\n",
    "                                fig.add_trace(\n",
    "                                    go.Scatter(\n",
    "                                        x=effect[\"label\"],\n",
    "                                        y=effect[y],\n",
    "                                        mode=\"lines\",\n",
    "                                        line=dict(width=5),\n",
    "                                        name=y,\n",
    "                                    )\n",
    "                                )\n",
    "                            else:\n",
    "                                fig.add_trace(\n",
    "                                    go.Scatter(\n",
    "                                        x=effect[\"label\"],\n",
    "                                        y=effect[y],\n",
    "                                        mode=\"lines\",\n",
    "                                        line=dict(width=2, dash=\"dash\"),\n",
    "                                        name=y,\n",
    "                                    )\n",
    "                                )\n",
    "\n",
    "                    else:\n",
    "                        effect.sort_values(by=\"label\", inplace=True)\n",
    "                        effect = pd.concat([effect, effect.iloc[0, :]]).iloc[1:, :]\n",
    "                        for y in effect.columns[1:]:\n",
    "                            if y == effect.columns[-1]:\n",
    "                                fig.add_trace(\n",
    "                                    go.Scatter(\n",
    "                                        x=effect[\"label\"],\n",
    "                                        y=effect[y],\n",
    "                                        mode=\"markers\",\n",
    "                                        marker=dict(size=10),\n",
    "                                        name=y,\n",
    "                                    )\n",
    "                                )\n",
    "                            else:\n",
    "                                fig.add_trace(\n",
    "                                    go.Scatter(\n",
    "                                        x=effect[\"label\"],\n",
    "                                        y=effect[y],\n",
    "                                        mode=\"markers\",\n",
    "                                        marker=dict(size=5),\n",
    "                                        name=y,\n",
    "                                    )\n",
    "                                )\n",
    "                    fig.update_layout(\n",
    "                        title=\"Partial dependence plot for \"\n",
    "                        + x\n",
    "                        + \"_class\"\n",
    "                        + str(class_no),\n",
    "                        xaxis_title=x,\n",
    "                        yaxis_title=\"Feature effect for \",\n",
    "                    )\n",
    "                    plotly.offline.plot(\n",
    "                        fig,\n",
    "                        filename=output_folder\n",
    "                        + \"pdp/\"\n",
    "                        + x\n",
    "                        + \"_class\"\n",
    "                        + str(class_no)\n",
    "                        + \"_pdp.html\",\n",
    "                        auto_open=False,\n",
    "                    )\n",
    "                    fig.show()\n",
    "\n",
    "                    if (\n",
    "                        list(df[df[\"feature_name\"] == x][\"feature_type\"]) == [\"numeric\"]\n",
    "                        and df_x_class[x].dtype.kind in \"iufc\"\n",
    "                    ):\n",
    "                        fig = go.Figure()\n",
    "                        fig.add_trace(\n",
    "                            go.Histogram(\n",
    "                                x=df_x_class[\n",
    "                                    (df_x_class[x] >= effect.label.min())\n",
    "                                    & (df_x_class[x] <= effect.label.max())\n",
    "                                ][x]\n",
    "                            )\n",
    "                        )\n",
    "                    else:\n",
    "                        fig = go.Figure()\n",
    "                        # df_x_class.sort_values(by=x, inplace=True)\n",
    "                        fig.add_trace(go.Histogram(x=df_x_class.sort_values(x)[x]))\n",
    "                    fig.update_layout(\n",
    "                        title=\"Original distribution of \"\n",
    "                        + x\n",
    "                        + \"_class\"\n",
    "                        + str(class_no),\n",
    "                        xaxis_title=x,\n",
    "                        yaxis_title=\"Count\",\n",
    "                    )\n",
    "                    plotly.offline.plot(\n",
    "                        fig,\n",
    "                        filename=output_folder\n",
    "                        + \"pdp/\"\n",
    "                        + x\n",
    "                        + \"_class\"\n",
    "                        + str(class_no)\n",
    "                        + \"_hist.html\",\n",
    "                        auto_open=False,\n",
    "                    )\n",
    "                    fig.show()\n",
    "\n",
    "\n",
    "# show top x features effects\n",
    "topx = 5\n",
    "if pdp:\n",
    "    if class_num > 2:\n",
    "        df_x[\"class\"] = df_x[target]\n",
    "    else:\n",
    "        df_x[\"class\"] = 0\n",
    "    __create_effect_plot(\n",
    "        df_output,\n",
    "        output_folder,\n",
    "        feature_effects,\n",
    "        iteration,\n",
    "        topx,\n",
    "        project_id_list,\n",
    "        df_x,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort and output the the top impact features based on the topX "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_new_data(\n",
    "    df_output2,\n",
    "    name,\n",
    "    df_id,\n",
    "    df_x,\n",
    "    df_y,\n",
    "    error_feature,\n",
    "    keep_column,\n",
    "    output_folder,\n",
    "    file_name,\n",
    "):\n",
    "    # output new data\n",
    "    lis = list(df_output2.columns)\n",
    "    drops = set(df_x.columns) - set(lis)\n",
    "    df_x2 = df_x.drop(columns=list(drops))\n",
    "\n",
    "    # drop error features from TopX\n",
    "    if error_feature == True:\n",
    "        df_x2 = df_x2[\n",
    "            [c for c in df_x2.columns if c not in [\"error_1\", \"error_2\", \"error_3\"]]\n",
    "        ]\n",
    "\n",
    "    if (len(keep_column) != 0) or (group_col != False):\n",
    "        df_topx = pd.concat([df_id, df_x2, df_y], axis=1)\n",
    "    else:\n",
    "        df_topx = pd.concat([df_x2, df_y], axis=1)\n",
    "    print(\"{} columns will be exported\".format(len(df_x2.columns)))\n",
    "    print(df_x2.columns)\n",
    "    return df_topx\n",
    "\n",
    "\n",
    "def change_topX(\n",
    "    top,\n",
    "    how,\n",
    "    output_folder,\n",
    "    input_file,\n",
    "    df_output,\n",
    "    remove_list,\n",
    "    keep_list,\n",
    "    df_id,\n",
    "    df_x,\n",
    "    df_y,\n",
    "    error_feature,\n",
    "    keep_column,\n",
    "    file_name,\n",
    "):\n",
    "    # load output file\n",
    "    name, ext = os.path.splitext(input_file)\n",
    "    name = re.split(\"_[0-9]+columns\", name)[0]\n",
    "    if how == \"min\":\n",
    "        df_output = df_output.sort_values(\n",
    "            by=[\"min\", \"median\", \"max\"], ascending=False, axis=1\n",
    "        )\n",
    "    else:\n",
    "        df_output = df_output.sort_values(by=[\"median\", \"max\"], ascending=False, axis=1)\n",
    "\n",
    "    # remove feautes which are in remove_list\n",
    "    if len(remove_list) != 0:\n",
    "        df_output = df_output[[c for c in df_output.columns if c not in remove_list]]\n",
    "\n",
    "    # if top>0, sort within TopX features\n",
    "    if top > 0:\n",
    "        sort_col = list(df_output.columns[: int(top)])\n",
    "        # add columns in keep list\n",
    "        if len(keep_list) != 0:\n",
    "            for col in keep_list:\n",
    "                sort_col.append(col)\n",
    "        df_output2 = df_output[list(set(sort_col))]\n",
    "        df_topx = export_new_data(\n",
    "            df_output2,\n",
    "            name,\n",
    "            df_id,\n",
    "            df_x,\n",
    "            df_y,\n",
    "            error_feature,\n",
    "            keep_column,\n",
    "            output_folder,\n",
    "            file_name,\n",
    "        )\n",
    "\n",
    "    # If top is -4,remove features lower than the lowest error_X(error_1,error_2,error_3).\n",
    "    elif top == -4:\n",
    "        if error_feature:\n",
    "            error_1_place = list(df_output.columns).index(\"error_1\")\n",
    "            error_2_place = list(df_output.columns).index(\"error_2\")\n",
    "            error_3_place = list(df_output.columns).index(\"error_3\")\n",
    "            worst_error_rank = max(error_1_place, error_2_place, error_3_place)\n",
    "            sort_col = list(df_output.columns[: int(worst_error_rank) + 1])\n",
    "            # add columns in keep list\n",
    "            if len(keep_list) != 0:\n",
    "                for col in keep_list:\n",
    "                    sort_col.append(col)\n",
    "            df_output2 = df_output[list(set(sort_col))]\n",
    "            df_topx = export_new_data(\n",
    "                df_output2,\n",
    "                name,\n",
    "                df_id,\n",
    "                df_x,\n",
    "                df_y,\n",
    "                error_feature,\n",
    "                keep_column,\n",
    "                output_folder,\n",
    "                file_name,\n",
    "            )\n",
    "        else:\n",
    "            df_topx = pd.DataFrame()\n",
    "            assert False, \"Please enable error_features\"\n",
    "\n",
    "    # If top is in [-1,-2,-3],remove features lower than [error_1,error_2,error_3]\n",
    "    elif top in [-1, -2, -3]:\n",
    "        if error_feature:\n",
    "            error_x_place = list(df_output.columns).index(\"error_{}\".format(abs(top)))\n",
    "            sort_col = list(df_output.columns[: int(error_x_place) + 1])\n",
    "            # add columns in keep list\n",
    "            if len(keep_list) != 0:\n",
    "                for col in keep_list:\n",
    "                    sort_col.append(col)\n",
    "            df_output2 = df_output[list(set(sort_col))]\n",
    "            df_topx = export_new_data(\n",
    "                df_output2,\n",
    "                name,\n",
    "                df_id,\n",
    "                df_x,\n",
    "                df_y,\n",
    "                error_feature,\n",
    "                keep_column,\n",
    "                output_folder,\n",
    "                file_name,\n",
    "            )\n",
    "        else:\n",
    "            df_topx = pd.DataFrame()\n",
    "            assert False, \"Please enable error_features\"\n",
    "\n",
    "    # if top=0,no output\n",
    "    elif top == 0:\n",
    "        df_topx = pd.DataFrame()\n",
    "\n",
    "    else:\n",
    "        df_topx = pd.DataFrame()\n",
    "        assert False, \"Please enter a valid value\"\n",
    "\n",
    "    return df_topx\n",
    "\n",
    "\n",
    "# top parameter controls the top feature impact list\n",
    "# if 0,show all the featuers\n",
    "# if enable error_feature,will remove features with some conditions below\n",
    "# if -4,remove features lower than the lowest error_X(error_1,error_2,error_3)\n",
    "# if -3,remove features lower than error_3\n",
    "# if -2,remove features lower than error_2\n",
    "# if -1,remove features lower than error_1\n",
    "top = -4\n",
    "# feature impact ranked by median or others, median is recommended\n",
    "how = \"median\"\n",
    "# Input features name if want to remove which are in the top list or keep null\n",
    "remove_list = []\n",
    "# Input features name if want to keep which are not in the top list or keep null\n",
    "keep_list = []\n",
    "\n",
    "df_topx = change_topX(\n",
    "    top,\n",
    "    how,\n",
    "    output_folder,\n",
    "    input_file,\n",
    "    df_output,\n",
    "    remove_list,\n",
    "    keep_list,\n",
    "    df_id,\n",
    "    df_x,\n",
    "    df_y,\n",
    "    error_feature,\n",
    "    keep_column,\n",
    "    file_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_output.to_csv(output_folder + \"seeds_check.csv\", index=True, encoding=\"utf-8-sig\")\n",
    "df_log.to_csv(output_folder + \"log_file.csv\", index=True, encoding=\"utf-8-sig\")\n",
    "df_association.to_csv(\n",
    "    output_folder + \"association.csv\", index=False, encoding=\"utf-8-sig\"\n",
    ")\n",
    "df_topx.to_csv(\n",
    "    output_folder + \"robust_feature_\" + file_name, index=False, encoding=\"utf-8-sig\"\n",
    ")\n",
    "print(\"save to local output folder finished!\")\n",
    "\n",
    "for d in data_output:\n",
    "    if d == \"ai_catalog\":\n",
    "        dr.Dataset.upload(output_folder + \"seeds_check.csv\")\n",
    "        dr.Dataset.upload(output_folder + \"log_file.csv\")\n",
    "        dr.Dataset.upload(output_folder + \"association.csv\")\n",
    "        dr.Dataset.upload(output_folder + \"robust_feature_\" + file_name)\n",
    "        print(\"save to ai_catalog finished!\")\n",
    "    if d == \"aws_s3\":\n",
    "        my_session = boto3.Session(\n",
    "            aws_access_key_id=AWS_KEY, aws_secret_access_key=AWS_SECRET\n",
    "        )  # aws access_key and secret_access_key\n",
    "        wr.s3.upload(\n",
    "            local_file=output_folder + \"seeds_check.csv\",\n",
    "            path=AWS_S3_OUTPUT_PATH + \"seeds_check.csv\",\n",
    "            boto3_session=my_session,\n",
    "        )\n",
    "        wr.s3.upload(\n",
    "            local_file=output_folder + \"log_file.csv\",\n",
    "            path=AWS_S3_OUTPUT_PATH + \"log_file.csv\",\n",
    "            boto3_session=my_session,\n",
    "        )\n",
    "        wr.s3.upload(\n",
    "            local_file=output_folder + \"association.csv\",\n",
    "            path=AWS_S3_OUTPUT_PATH + \"association.csv\",\n",
    "            boto3_session=my_session,\n",
    "        )\n",
    "        wr.s3.upload(\n",
    "            local_file=output_folder + \"robust_feature_\" + file_name,\n",
    "            path=AWS_S3_OUTPUT_PATH + \"robust_feature_\" + file_name,\n",
    "            boto3_session=my_session,\n",
    "        )\n",
    "        print(\"save to aws_s3 finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": true,
  "vscode": {
   "interpreter": {
    "hash": "397704579725e15f5c7cb49fe5f0341eb7531c82d19f2c29d197e8b64ab5776b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b751667-41c1-4037-bbf7-af594dc142b7",
   "metadata": {
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": null,
     "hide_code": false,
     "hide_results": false,
     "language": "markdown"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    }
   },
   "source": [
    "# LLM multimodal PDF RAG\n",
    "\n",
    "- **Author**: senkin.zhan@datarobot.com\n",
    "- **Demo data**: https://s3.us-east-1.amazonaws.com/datarobot_public_datasets/ai_accelerators/pdf_demo.zip\n",
    "\n",
    "## Summary\n",
    "\n",
    "Since open-source PDF OCR tools often make mistakes, you can use an LLM instead. This AI accelerator introduces an approach to use an LLM as an OCR tool to extract all the text, table, and graph data from a PDF, then build a RAG and a Playround chat on DataRobot.\n",
    "\n",
    "This notebook outlines how to:\n",
    "\n",
    "1. Split a PDF to multiple images; one per page.\n",
    "2. Extract all the text, table, and graph data from image using an LLM, then save them as markdown files. \n",
    "3. Build a vector database with the markdown files.\n",
    "4. Build a Playground chat and test prompt.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c80b5a-4319-44f3-9d40-deb0d8e7a723",
   "metadata": {
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": null,
     "hide_code": false,
     "hide_results": false,
     "language": "markdown"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    }
   },
   "source": [
    "## Setup\n",
    "\n",
    "### Install and import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "666c08ab1acd9b92f3f9e93b",
   "metadata": {
    "chart_settings": null,
    "collapsed": false,
    "custom_llm_metric_settings": null,
    "custom_metric_settings": null,
    "dataframe_view_options": null,
    "datarobot": {
     "disable_run": false,
     "execution_time_millis": 2047,
     "hide_code": false,
     "hide_results": false,
     "language": "python"
    },
    "disable_run": false,
    "hide_code": false,
    "hide_results": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "!pip install google-genai pdf2image pymupdf openai anthropic -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "666c08ab1acd9b92f3f9e93c",
   "metadata": {
    "chart_settings": null,
    "collapsed": false,
    "custom_llm_metric_settings": null,
    "custom_metric_settings": null,
    "dataframe_view_options": null,
    "datarobot": {
     "disable_run": false,
     "execution_time_millis": 2558,
     "hide_code": false,
     "hide_results": false,
     "language": "python"
    },
    "disable_run": false,
    "hide_code": false,
    "hide_results": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import glob\n",
    "from io import BytesIO\n",
    "import os\n",
    "import time\n",
    "import zipfile\n",
    "\n",
    "from PIL import Image\n",
    "import anthropic\n",
    "import datarobot as dr\n",
    "from datarobot.enums import (\n",
    "    PromptType,\n",
    "    VectorDatabaseChunkingMethod,\n",
    "    VectorDatabaseEmbeddingModel,\n",
    ")\n",
    "from datarobot.models.dataset import Dataset\n",
    "from datarobot.models.genai.chat import Chat\n",
    "from datarobot.models.genai.chat_prompt import ChatPrompt\n",
    "from datarobot.models.genai.comparison_chat import ComparisonChat\n",
    "from datarobot.models.genai.comparison_prompt import ComparisonPrompt\n",
    "from datarobot.models.genai.custom_model_llm_validation import CustomModelLLMValidation\n",
    "from datarobot.models.genai.llm import LLMDefinition\n",
    "from datarobot.models.genai.llm_blueprint import LLMBlueprint, VectorDatabaseSettings\n",
    "from datarobot.models.genai.playground import Playground\n",
    "from datarobot.models.genai.vector_database import (\n",
    "    ChunkingParameters,\n",
    "    CustomModelVectorDatabaseValidation,\n",
    "    VectorDatabase,\n",
    ")\n",
    "import fitz\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "import numpy as np\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8394061-fdaf-4bce-ab72-2d5023ce6e7c",
   "metadata": {
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": null,
     "hide_code": false,
     "hide_results": false,
     "language": "markdown"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    }
   },
   "source": [
    "### Bind variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "666c08ab1acd9b92f3f9e941",
   "metadata": {
    "chart_settings": null,
    "collapsed": false,
    "custom_llm_metric_settings": null,
    "custom_metric_settings": null,
    "dataframe_view_options": null,
    "datarobot": {
     "disable_run": false,
     "execution_time_millis": 564,
     "hide_code": false,
     "hide_results": false,
     "language": "python"
    },
    "disable_run": false,
    "hide_code": false,
    "hide_results": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Datarobot client\n",
    "dr.Client()\n",
    "\n",
    "# Download demo data to current directory\n",
    "zip_path = \"pdf_demo.zip\"\n",
    "\n",
    "# Create a folder to save pdf uncompressed from zip file\n",
    "pdf_path = \"pdf\"\n",
    "os.makedirs(pdf_path, exist_ok=True)\n",
    "with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "    zip_ref.extractall(pdf_path)\n",
    "\n",
    "# Create a folder to save images converted from PDF\n",
    "image_path = \"image\"\n",
    "os.makedirs(image_path, exist_ok=True)\n",
    "\n",
    "# Create a folder to save markdown files extracted from images\n",
    "markdown_path = \"markdown\"\n",
    "os.makedirs(markdown_path, exist_ok=True)\n",
    "\n",
    "# Generate a .zip file to create a vector database\n",
    "vectordb_zip_path = \"vectordb.zip\"\n",
    "\n",
    "# Image size 1000 is recommended\n",
    "image_size = 1000\n",
    "\n",
    "# Chunk parameters\n",
    "chunking_method = VectorDatabaseChunkingMethod.RECURSIVE\n",
    "chunk_size = 384\n",
    "chunk_overlap_percentage = 50\n",
    "separators = [\"\\n\\n\"]\n",
    "\n",
    "# Playground parameters\n",
    "playground_name = \"multimodal_rag\"\n",
    "chat_name = \"gpt4o\"\n",
    "\n",
    "# Chat parameters\n",
    "max_completion_length = 256\n",
    "temperature = 0.4\n",
    "top_p = 0.9\n",
    "max_documents_retrieved_per_prompt = 5\n",
    "max_tokens = 384\n",
    "\n",
    "# For previous chat prompts (history) to be included in each subsequent prompt, PromptType.ONE_TIME_PROMPT is an alternative if you don't wish\n",
    "prompting_strategy = PromptType.CHAT_HISTORY_AWARE\n",
    "\n",
    "# Max retry for creating vector database and playground\n",
    "max_retry = 5\n",
    "\n",
    "# Use jp or en version to test demo\n",
    "lang = \"jp\"\n",
    "\n",
    "if lang == \"jp\":\n",
    "    # pdf_path\n",
    "    pdf_path = pdf_path + \"/jp\"\n",
    "\n",
    "    # prompt example\n",
    "    prompt = \"\"\"\n",
    "        **役割設定**:\n",
    "        あなたは画像からの文字認識、表の解析、および図表構造の抽出に精通したエキスパートです。\n",
    "\n",
    "        **タスクの目的**:\n",
    "        提供された画像から以下の情報を抽出し、Markdown形式で出力してください:\n",
    "        1.**すべての文字情報**: 画像中に含まれる文章や段落、見出しなどを可能な限り元の構成で再現してください。\n",
    "        2.**表（テーブル）**: 画像に表が含まれる場合、Markdownの表記法（| 区切り）を使って復元してください。\n",
    "        3.**図表（チャート）**: グラフやチャートが含まれる場合、テキストやリスト、あるいは擬似コードなどでデータと構造をできるだけ詳しく再現してください（軸のラベル、データ点、凡例など）。\n",
    "\n",
    "　　　　　**重要**:\n",
    "　　　　　- 元の画像に含まれていない情報は絶対に付け加えないでください。余計な情報や事実にない内容の追加は避けてください。\n",
    "     　　- 丁寧な挨拶や了解の返事（例：「はい、承知いたしました」など）を出力に含めないでください。\n",
    "\n",
    "        **出力要件**:\n",
    "        - Markdown形式で出力すること。\n",
    "        - 元の情報を可能な限り正確に保持すること。\n",
    "        - 認識できない、または不確定な部分は「不明」や「未確定」などと明示すること。\n",
    "        - 文章部分は段落や箇条書きなど、わかりやすい形式で整理すること。\n",
    "        - 表はMarkdownのテーブル記法を使用すること。\n",
    "        - 図表については、テキストやリスト、または簡易的な擬似コードで構造を説明するなど、できるだけ細かく記述すること。\n",
    "        - 全体の出力は見やすく、段階的に整理してください。\n",
    "        \"\"\"\n",
    "\n",
    "    # System prompt for chat\n",
    "    system_prompt = \"\"\"\n",
    "        質問に対して、可能な限り短く、答えてください。余計な、丁寧な言葉遣いや冗長な説明をやめてください。\n",
    "        \"\"\"\n",
    "\n",
    "    # SUP_SIMCSE_JA_BASE is recommend for japanese vectordatabase\n",
    "    embedding_model = VectorDatabaseEmbeddingModel.SUP_SIMCSE_JA_BASE\n",
    "\n",
    "else:\n",
    "    # pdf_path\n",
    "    pdf_path = pdf_path + \"/en\"\n",
    "\n",
    "    # Prompt example\n",
    "    prompt = \"\"\" \n",
    "        **Role Setting**:  \n",
    "        You are an expert in image text recognition, table parsing, and chart structure extraction.\n",
    "\n",
    "        **Task Objective**:  \n",
    "        Please extract the following information from the image I provide, and return the results in **Markdown** format:\n",
    "        1. **All Text**: Preserve the original paragraphs, headings, or logical order as much as possible.  \n",
    "        2. **Tables**: If the image contains tables, please reconstruct them using **Markdown table syntax** (using `|` as separators).  \n",
    "        3. **Charts (graphs)**: If there are charts or data visualizations, try to reconstruct their structure and data. You can describe charts in text, lists, or pseudo-code (e.g., axis labels, data points, legend).\n",
    "\n",
    "        **Important**:  \n",
    "        - **Do not include any content that is not present in the original image.** Avoid adding or fabricating extra information.\n",
    "        - **Do not output polite acknowledgments or confirmations** (e.g., “Yes, I understand.”).\n",
    "\n",
    "        **Output Requirements**:  \n",
    "        - The output must be in Markdown format.  \n",
    "        - Retain the integrity and accuracy of the original information.  \n",
    "        - If there is any text or data that is **uncertain or unrecognizable**, mark it clearly as “[Uncertain]” or “[Unrecognized]”.  \n",
    "        - For text, organize it into paragraphs or bullet points.  \n",
    "        - For tables, use standard Markdown table syntax.  \n",
    "        - For charts, describe them in text/list form or simple pseudo-code.  \n",
    "        - Keep the structure clear and organized.\n",
    "        \"\"\"\n",
    "\n",
    "    # System prompt for chat\n",
    "    system_prompt = \"\"\"\n",
    "        Answer the question as briefly as possible. Avoid unnecessary polite language and redundant explanations.\n",
    "        \"\"\"\n",
    "\n",
    "    # JINA_EMBEDDING_T_EN_V1  is recommend for english vectordatabase\n",
    "    embedding_model = VectorDatabaseEmbeddingModel.JINA_EMBEDDING_T_EN_V1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff24b68-7184-4b66-957e-bee5895ca0d2",
   "metadata": {
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": null,
     "hide_code": false,
     "hide_results": false,
     "language": "markdown"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    }
   },
   "source": [
    "### Convert the PDF into images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b253ff8f-91da-4b09-9a77-d87bbcee02c8",
   "metadata": {
    "collapsed": false,
    "datarobot": {
     "disable_run": false,
     "execution_time_millis": 57421,
     "hide_code": false,
     "hide_results": false,
     "language": "python"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pdf/jp/ドラえもん.pdf\n",
      "pdf/jp/ポケットモンスター.pdf\n"
     ]
    }
   ],
   "source": [
    "def convert_pdf_to_image(pdf_path, image_path):\n",
    "    pdf_list = sorted(glob.glob(pdf_path + \"/*.pdf\"))\n",
    "    for p in pdf_list:\n",
    "        print(p)\n",
    "        pdf_name = p.split(\".\")[0].split(\"/\")[-1]\n",
    "        doc = fitz.open(p)\n",
    "        for i in range(len(doc)):\n",
    "            page = doc[i]\n",
    "            pix = page.get_pixmap(dpi=300)  # Adjust DPI for quality\n",
    "            pix.save(f\"{image_path}/{pdf_name}_{i+1}.jpeg\")  # Save as PNG\n",
    "\n",
    "\n",
    "convert_pdf_to_image(pdf_path, image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d14b012-2875-47c3-99ec-e84014f971c3",
   "metadata": {
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": null,
     "hide_code": false,
     "hide_results": false,
     "language": "markdown"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    }
   },
   "source": [
    "### Check the LLM OCR processing of one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b68bda94-7662-440a-8b45-102b367dcd52",
   "metadata": {
    "collapsed": false,
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": 2167,
     "hide_code": false,
     "hide_results": false,
     "language": "python"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'```markdown\\n# ドラえもん\\n出典: フリー百科事典『ウィキペディア (Wikipedia)』\\n\\n藤子不二雄（連載） > 藤子・F・不二雄（著作） > ドラえもん\\n\\n『ドラえもん』は、藤子・F・不二雄[注釈 1]による日本のSF児童ギャグ漫画である。1969年から主に児童向け雑誌で「藤子不二雄」名義で連載が開始[1][2]された。開始当初から藤本弘単独作品。1989年以降は「藤子・F・不二雄」名義となった。日本では国民的な知名度があり、海外でも東アジアや東南アジアを中心に高い人気を誇る[4]。2012年9月には藤子・F・不二雄大全集『ドラえもん』全20巻が完結し、藤本によって描かれた1300以上のドラえもん漫画作品のほぼ全話が単行本に収録された。\\n\\n## 作品の概要\\n22世紀の未来からやってきたネコ型ロボット・ドラえもんと、勉強もスポーツも苦手な小学生・野比のび太が繰り広げる日常生活を描いた作品である。基本的には一話完結型の連載漫画だが、連続ストーリー型となって日常を離れた冒険をする「大長編」シリーズもある。話完結の基本的なプロットは、ドラえもんがポケットから出す多種多様なひみつ道具（現代の技術では再現も実現も不可能な機能を持つ）でのび太（或いは他の場合もある）の身にふりかかる災難を解決しようとするが、道具を不適切に使った結果、しっぺ返しを受けるといったものが多い。\\n\\n## あらすじ\\nのび太がふだんのんびりと過ごしていると、突然、どこからともなく彼の未来を告げる声が聞こえ、机の引き出しからドラえもんと、のび太の孫の孫のセワシが現れた。セワシ曰く、のび太は社会に出た後も...\\n\\n---\\n\\n![ドラえもんの主要キャラクターの像 (高岡おとぎの森公園内「ドラえもんの空き地」より)]()\\n\\n## テーブル\\n| ジャンル | 児童漫画、少年漫画、SF漫画、ギャグ漫画 |\\n| --- | --- |\\n| 形式 | 漫画 |\\n| 作者 | 藤子・F・不二雄[注釈 1] |\\n| 出版社 | 小学館 |\\n| その他の出版社 | 中央公論社（FFランド） |\\n| 掲載誌 | 小学館の学習雑誌、コロコロコミック、てれびくん 他 |\\n| レーベル | てんとう虫コミックス 他 |\\n| 発表期間 | 1969年 - 1997年 |\\n| 巻数 | 全45巻[注釈 2]  （てんとう虫コミックスの短編集の巻数） |\\n| 話数 | 全1345話以上 |\\n| その他 | 各話のタイトルは、単行本 (てんとう虫コミックス 各巻を参照)。レーベル・巻数の詳細は単行本各巻を参照。大長編版は『大長編ドラえもん』を参照。|\\n\\n## テレビアニメ\\n```\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def llm_generate_content(llm, model, api_key, api_version, endpoint, prompt, img_path):\n",
    "    if llm == \"google\":\n",
    "        image = Image.open(img_path)\n",
    "        client = genai.Client(api_key=api_key)\n",
    "        response = client.models.generate_content(model=model, contents=[prompt, image])\n",
    "        res = response.text\n",
    "\n",
    "    if llm == \"anthropic\":\n",
    "        with open(img_path, \"rb\") as f:\n",
    "            bytes = f.read()\n",
    "            image = base64.standard_b64encode(bytes).decode(\"utf-8\")\n",
    "        client = anthropic.Anthropic(api_key=api_key)\n",
    "        response = client.messages.create(\n",
    "            max_tokens=4096,\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"image\",\n",
    "                            \"source\": {\"type\": \"base64\", \"media_type\": \"image/jpeg\", \"data\": image},\n",
    "                        },\n",
    "                        {\"type\": \"text\", \"text\": prompt},\n",
    "                    ],\n",
    "                }\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        res = response.content[0].text\n",
    "\n",
    "    if llm == \"openai\":\n",
    "        with Image.open(img_path) as img:\n",
    "            buffered = BytesIO()\n",
    "            img.save(buffered, format=\"JPEG\")\n",
    "            image = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "        client = OpenAI(api_key=api_key)\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": prompt},\n",
    "                        {\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image}\"},\n",
    "                        },\n",
    "                    ],\n",
    "                }\n",
    "            ],\n",
    "            max_tokens=4096,\n",
    "        )\n",
    "\n",
    "        res = response.choices[0].message.content\n",
    "\n",
    "    if llm == \"azure\":\n",
    "        openai.api_type = llm\n",
    "        openai.azure_endpoint = endpoint\n",
    "        openai.api_version = api_version\n",
    "        openai.api_key = api_key\n",
    "        with Image.open(img_path) as img:\n",
    "            buffered = BytesIO()\n",
    "            img.save(buffered, format=\"JPEG\")\n",
    "            image = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "        response = openai.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": prompt},\n",
    "                        {\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image}\"},\n",
    "                        },\n",
    "                    ],\n",
    "                }\n",
    "            ],\n",
    "            max_tokens=4096,\n",
    "        )\n",
    "\n",
    "        res = response.choices[0].message.content\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "# select llm service provider from (google | azure | openai | anthropic), (gemini-2.0-flash | claude-3-7-sonnet-20250219 | gpt-4o) are recommended for image ocr task\n",
    "\n",
    "## google gemini-2.0-flash\n",
    "# llm = 'google'\n",
    "# model = 'gemini-2.0-flash'\n",
    "# api_key = 'your-api-key'\n",
    "# api_version = '' # keep empty\n",
    "# endpoint = ''  # keep empty\n",
    "\n",
    "## anthropic claude 3.7\n",
    "# llm = 'anthropic'\n",
    "# model = \"claude-3-7-sonnet-20250219\"\n",
    "# api_key = 'your-api-key'\n",
    "# api_version = '' # keep empty\n",
    "# endpoint = ''  # keep empty\n",
    "\n",
    "## openai gpt-4o\n",
    "# llm = 'openai'\n",
    "# model = 'gpt-4o'\n",
    "# api_key = 'your-api-key'\n",
    "# api_version = '' # keep empty\n",
    "# endpoint = ''  # keep empty\n",
    "\n",
    "\n",
    "## azure gpt-4o\n",
    "llm = \"azure\"\n",
    "model = \"gpt-4o\"\n",
    "api_key = \"your-api-key\"\n",
    "api_version = \"2024-10-21\"  # Use the correct version for your deployment\n",
    "endpoint = \"https://your-organization.openai.azure.com/\"  # Use the correct azure endpoint for your deployment\n",
    "\n",
    "img_path = sorted(glob.glob(image_path + \"/*.jpeg\"))[0]\n",
    "llm_generate_content(llm, model, api_key, api_version, endpoint, prompt, img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2349a8e-1119-4771-a586-ca1866e62054",
   "metadata": {
    "datarobot": {
     "disable_run": false,
     "execution_time_millis": null,
     "hide_code": false,
     "hide_results": false,
     "language": "markdown"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    }
   },
   "source": [
    "### Extract markdown text from all of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9b10c95-7dd3-486b-bde4-79f564c2a0aa",
   "metadata": {
    "collapsed": false,
    "datarobot": {
     "disable_run": false,
     "execution_time_millis": 738061,
     "hide_code": false,
     "hide_results": false,
     "language": "python"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing  image/ドラえもん_1.jpeg ......\n",
      "processing  image/ドラえもん_10.jpeg ......\n",
      "processing  image/ドラえもん_11.jpeg ......\n",
      "processing  image/ドラえもん_12.jpeg ......\n",
      "processing  image/ドラえもん_13.jpeg ......\n",
      "processing  image/ドラえもん_14.jpeg ......\n",
      "processing  image/ドラえもん_15.jpeg ......\n",
      "processing  image/ドラえもん_16.jpeg ......\n",
      "processing  image/ドラえもん_17.jpeg ......\n",
      "processing  image/ドラえもん_18.jpeg ......\n",
      "processing  image/ドラえもん_19.jpeg ......\n",
      "processing  image/ドラえもん_2.jpeg ......\n",
      "processing  image/ドラえもん_20.jpeg ......\n",
      "processing  image/ドラえもん_21.jpeg ......\n",
      "processing  image/ドラえもん_22.jpeg ......\n",
      "processing  image/ドラえもん_23.jpeg ......\n",
      "processing  image/ドラえもん_24.jpeg ......\n",
      "processing  image/ドラえもん_25.jpeg ......\n",
      "processing  image/ドラえもん_26.jpeg ......\n",
      "processing  image/ドラえもん_27.jpeg ......\n",
      "processing  image/ドラえもん_28.jpeg ......\n",
      "processing  image/ドラえもん_29.jpeg ......\n",
      "processing  image/ドラえもん_3.jpeg ......\n",
      "processing  image/ドラえもん_30.jpeg ......\n",
      "processing  image/ドラえもん_31.jpeg ......\n",
      "processing  image/ドラえもん_32.jpeg ......\n",
      "processing  image/ドラえもん_33.jpeg ......\n",
      "processing  image/ドラえもん_34.jpeg ......\n",
      "processing  image/ドラえもん_35.jpeg ......\n",
      "processing  image/ドラえもん_36.jpeg ......\n",
      "processing  image/ドラえもん_4.jpeg ......\n",
      "processing  image/ドラえもん_5.jpeg ......\n",
      "processing  image/ドラえもん_6.jpeg ......\n",
      "processing  image/ドラえもん_7.jpeg ......\n",
      "processing  image/ドラえもん_8.jpeg ......\n",
      "processing  image/ドラえもん_9.jpeg ......\n",
      "processing  image/ポケットモンスター_1.jpeg ......\n",
      "processing  image/ポケットモンスター_10.jpeg ......\n",
      "processing  image/ポケットモンスター_11.jpeg ......\n",
      "processing  image/ポケットモンスター_12.jpeg ......\n",
      "processing  image/ポケットモンスター_13.jpeg ......\n",
      "processing  image/ポケットモンスター_14.jpeg ......\n",
      "processing  image/ポケットモンスター_15.jpeg ......\n",
      "processing  image/ポケットモンスター_16.jpeg ......\n",
      "processing  image/ポケットモンスター_17.jpeg ......\n",
      "processing  image/ポケットモンスター_18.jpeg ......\n",
      "processing  image/ポケットモンスター_19.jpeg ......\n",
      "processing  image/ポケットモンスター_2.jpeg ......\n",
      "processing  image/ポケットモンスター_20.jpeg ......\n",
      "processing  image/ポケットモンスター_21.jpeg ......\n",
      "processing  image/ポケットモンスター_22.jpeg ......\n",
      "processing  image/ポケットモンスター_23.jpeg ......\n",
      "processing  image/ポケットモンスター_24.jpeg ......\n",
      "processing  image/ポケットモンスター_25.jpeg ......\n",
      "processing  image/ポケットモンスター_26.jpeg ......\n",
      "processing  image/ポケットモンスター_27.jpeg ......\n",
      "processing  image/ポケットモンスター_28.jpeg ......\n",
      "processing  image/ポケットモンスター_29.jpeg ......\n",
      "processing  image/ポケットモンスター_3.jpeg ......\n",
      "processing  image/ポケットモンスター_30.jpeg ......\n",
      "processing  image/ポケットモンスター_31.jpeg ......\n",
      "processing  image/ポケットモンスター_32.jpeg ......\n",
      "processing  image/ポケットモンスター_4.jpeg ......\n",
      "processing  image/ポケットモンスター_5.jpeg ......\n",
      "processing  image/ポケットモンスター_6.jpeg ......\n",
      "processing  image/ポケットモンスター_7.jpeg ......\n",
      "processing  image/ポケットモンスター_8.jpeg ......\n",
      "processing  image/ポケットモンスター_9.jpeg ......\n",
      "CPU times: user 15.6 s, sys: 3.61 s, total: 19.2 s\n",
      "Wall time: 12min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "def extract_markdown_from_image(\n",
    "    image_path, markdown_path, vectordb_zip_path, llm, model, api_key, api_version, endpoint, prompt\n",
    "):\n",
    "    images = sorted(glob.glob(image_path + \"/*.jpeg\"))\n",
    "    df = pd.DataFrame()\n",
    "    for m in images:\n",
    "        print(\"processing \", m, \"......\")\n",
    "        text_page = llm_generate_content(llm, model, api_key, api_version, endpoint, prompt, m)\n",
    "        tmp = pd.DataFrame({\"text_page\": [text_page]})\n",
    "        tmp[\"source\"] = m\n",
    "        tmp[\"page\"] = tmp[\"source\"].apply(lambda x: x.split(\".\")[0].split(\"_\")[-1]).astype(int)\n",
    "        tmp[\"pdf\"] = tmp[\"source\"].apply(lambda x: x.split(\"/\")[-1].split(\"_\")[0])\n",
    "        df = pd.concat([df, tmp])\n",
    "\n",
    "    df = df.sort_values([\"pdf\", \"page\"]).reset_index(drop=True)\n",
    "    df_source = df.groupby([\"pdf\"])[\"text_page\"].agg(list).reset_index()\n",
    "    df_source[\"text\"] = df_source[\"text_page\"].apply(lambda x: \"\\n\\n\".join(x))\n",
    "    df_source = df_source.drop([\"text_page\"], axis=1).reset_index(drop=True)\n",
    "\n",
    "    for i in range(len(df_source)):\n",
    "        filename = df_source.iloc[i][\"pdf\"]\n",
    "        text = df_source.iloc[i][\"text\"]\n",
    "        with open(markdown_path + \"/\" + filename + \".md\", \"w\", encoding=\"utf-8_sig\") as text_file:\n",
    "            text_file.write(text)\n",
    "\n",
    "    with zipfile.ZipFile(vectordb_zip_path, \"w\", zipfile.ZIP_DEFLATED) as zipf:\n",
    "        for root, dirs, files in os.walk(markdown_path):\n",
    "            for file in files:\n",
    "                filepath = os.path.join(root, file)\n",
    "                arcname = os.path.relpath(filepath, start=markdown_path)\n",
    "                zipf.write(filepath, arcname)\n",
    "\n",
    "\n",
    "extract_markdown_from_image(\n",
    "    image_path, markdown_path, vectordb_zip_path, llm, model, api_key, api_version, endpoint, prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e52eec7-187e-4255-a4ad-4e92e6bfe967",
   "metadata": {
    "datarobot": {
     "disable_run": false,
     "hide_code": false,
     "hide_results": false,
     "language": "markdown"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    }
   },
   "source": [
    "### Build a Use Case and vector database with the extracted markdown files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a566985e-83b8-4251-bd30-f1fc3c6651f4",
   "metadata": {
    "collapsed": false,
    "datarobot": {
     "disable_run": false,
     "execution_time_millis": 321548,
     "hide_code": false,
     "hide_results": false,
     "language": "python"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 649 ms, sys: 7.74 ms, total: 656 ms\n",
      "Wall time: 5min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def create_vectordb(file):\n",
    "    use_case = dr.UseCase.create(file.split(\".\")[0])\n",
    "    dataset = dr.Dataset.create_from_file(file)\n",
    "    use_case.add(entity=dataset)\n",
    "\n",
    "    chunking_parameters = ChunkingParameters(\n",
    "        embedding_model=embedding_model,\n",
    "        chunking_method=chunking_method,\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap_percentage=chunk_overlap_percentage,\n",
    "        separators=separators,\n",
    "    )\n",
    "    vdb = VectorDatabase.create(dataset.id, chunking_parameters, use_case)\n",
    "\n",
    "    for n in range(max_retry):\n",
    "        time.sleep(60)\n",
    "        try:\n",
    "            vdb = VectorDatabase.get(vdb.id)\n",
    "            assert vdb.execution_status == \"COMPLETED\"\n",
    "        except:\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return use_case, vdb\n",
    "\n",
    "\n",
    "use_case, vdb = create_vectordb(vectordb_zip_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f26df1-18e3-4f31-b0c2-d67c439842e0",
   "metadata": {
    "datarobot": {
     "disable_run": false,
     "hide_code": false,
     "hide_results": false,
     "language": "markdown"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    }
   },
   "source": [
    "### Build an LLM playground "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f77d29b2-5ba9-4e20-be2c-8bc0501ee5de",
   "metadata": {
    "datarobot": {
     "execution_time_millis": 1616
    }
   },
   "outputs": [],
   "source": [
    "playground = Playground.create(name=playground_name, use_case=use_case)\n",
    "llms = LLMDefinition.list(use_case=use_case, as_dict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f018be2-aca3-4dac-adf6-bf5f27d3fc9e",
   "metadata": {
    "datarobot": {
     "execution_time_millis": 5
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LLMDefinition(id=azure-openai-gpt-3.5-turbo, name=Azure OpenAI GPT-3.5 Turbo),\n",
       " LLMDefinition(id=azure-openai-gpt-3.5-turbo-16k, name=Azure OpenAI GPT-3.5 Turbo 16k),\n",
       " LLMDefinition(id=azure-openai-gpt-4, name=Azure OpenAI GPT-4),\n",
       " LLMDefinition(id=azure-openai-gpt-4-32k, name=Azure OpenAI GPT-4 32k),\n",
       " LLMDefinition(id=azure-openai-gpt-4-turbo, name=Azure OpenAI GPT-4 Turbo),\n",
       " LLMDefinition(id=azure-openai-gpt-4-o, name=Azure OpenAI GPT-4o),\n",
       " LLMDefinition(id=azure-openai-gpt-4-o-mini, name=Azure OpenAI GPT-4o Mini),\n",
       " LLMDefinition(id=amazon-titan, name=Amazon Titan),\n",
       " LLMDefinition(id=anthropic-claude-2, name=Anthropic Claude 2.1),\n",
       " LLMDefinition(id=anthropic-claude-3-haiku, name=Anthropic Claude 3 Haiku),\n",
       " LLMDefinition(id=anthropic-claude-3-sonnet, name=Anthropic Claude 3 Sonnet),\n",
       " LLMDefinition(id=anthropic-claude-3-opus, name=Anthropic Claude 3 Opus),\n",
       " LLMDefinition(id=google-bison, name=Google Bison),\n",
       " LLMDefinition(id=google-gemini-1.5-flash, name=Google Gemini 1.5 Flash),\n",
       " LLMDefinition(id=google-gemini-1.5-pro, name=Google Gemini 1.5 Pro)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17a74e69-619e-467d-be5b-2074b6176655",
   "metadata": {
    "datarobot": {
     "execution_time_millis": 5
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMDefinition(id=azure-openai-gpt-4-o-mini, name=Azure OpenAI GPT-4o Mini)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use azure-openai-gpt-4-o-mini as chat llm\n",
    "gpt = llms[6]\n",
    "gpt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf1fbec-b310-4a9c-8a30-6519d9c2615d",
   "metadata": {
    "datarobot": {
     "disable_run": false,
     "hide_code": false,
     "hide_results": false,
     "language": "markdown"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    }
   },
   "source": [
    "### Build an LLM blueprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c012772-f125-4d83-9bfa-c4bf99d40d99",
   "metadata": {
    "datarobot": {
     "execution_time_millis": 1049
    }
   },
   "outputs": [],
   "source": [
    "llm_settings = {\n",
    "    \"system_prompt\": (system_prompt),\n",
    "    \"max_completion_length\": max_completion_length,\n",
    "    \"temperature\": temperature,\n",
    "    \"top_p\": top_p,\n",
    "}\n",
    "\n",
    "prompting_strategy = prompting_strategy\n",
    "\n",
    "vector_database_settings = VectorDatabaseSettings(\n",
    "    max_documents_retrieved_per_prompt=max_documents_retrieved_per_prompt,\n",
    "    max_tokens=max_tokens,\n",
    ")\n",
    "\n",
    "llm_blueprint = LLMBlueprint.create(\n",
    "    playground=playground,\n",
    "    name=\"GPT\",\n",
    "    llm=gpt,\n",
    "    prompt_type=prompting_strategy,\n",
    "    llm_settings=llm_settings,\n",
    "    vector_database=vdb,\n",
    "    vector_database_settings=vector_database_settings,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82ea87d-06a3-4bd0-9f98-e1199dee3e7b",
   "metadata": {
    "datarobot": {
     "disable_run": false,
     "hide_code": false,
     "hide_results": false,
     "language": "markdown"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    }
   },
   "source": [
    "## Build a chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec001cd5-659c-4b9c-a24d-7a54fedd6738",
   "metadata": {
    "datarobot": {
     "execution_time_millis": 720
    }
   },
   "outputs": [],
   "source": [
    "chat = Chat.create(name=chat_name, llm_blueprint=llm_blueprint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fde576-b8b1-44c7-9b47-df8693e40731",
   "metadata": {
    "datarobot": {
     "disable_run": false,
     "hide_code": false,
     "hide_results": false,
     "language": "markdown"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    }
   },
   "source": [
    "## Test the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "507beb27-d79e-4a52-b1d7-afca07e718c6",
   "metadata": {
    "datarobot": {
     "execution_time_millis": 7112
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1973年です。\n"
     ]
    }
   ],
   "source": [
    "prompt = ChatPrompt.create(\n",
    "    chat=chat,\n",
    "    text=\"ドラえもん最初テレビ放送はいつですか？\",\n",
    "    wait_for_completion=True,\n",
    ")\n",
    "print(prompt.result_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f9aa92aa-4891-47a1-982d-bff43de9b3d6",
   "metadata": {
    "datarobot": {
     "execution_time_millis": 12066
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4億8000万本以上です。\n"
     ]
    }
   ],
   "source": [
    "prompt = ChatPrompt.create(\n",
    "    chat=chat,\n",
    "    text=\"2024年3月末時点ポケモン関連ゲーム累計出荷数は？\",\n",
    "    wait_for_completion=True,\n",
    ")\n",
    "print(prompt.result_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

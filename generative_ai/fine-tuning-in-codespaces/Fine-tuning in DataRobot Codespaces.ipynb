{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b86f1113",
   "metadata": {
    "collapsed": false,
    "datarobot": {
     "disable_run": false,
     "hide_code": false,
     "hide_results": false,
     "language": "markdown"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "scrolled": "auto"
   },
   "source": [
    "# Fine-tuning and deploying Llama 3.2 1B in DataRobot\n",
    "\n",
    "Author: Tim Whittaker\n",
    "\n",
    "Date created: 2/5/2025\n",
    "\n",
    "Integrations: Huggingface, Weights and Biases\n",
    "\n",
    "This accelerator illustrates an end-to-end workflow for fine-tuning and deployment an LLM using features of Huggingface, Weights and Biases (W&B), and DataRobot.  \n",
    "\n",
    "This accelerator covers:\n",
    "\n",
    "* [Downloading an LLM from the Huggingface modelhub](#Grab-Llama-3.2-1b-from-Huggingface) \n",
    "* [Acquiring a dataset from Huggingface](#Grab-the-Dataset-from-Huggingface)\n",
    "* [Leveraging DataRobot codespaces, notebooks, and GPU resources to facilitate fine-tuning via Huggingface and W&B](#Fine-tune-Llama)\n",
    "* [Leveraging DataRobot MLOps to register and deploy a model as an inference endpoint](#Take-our-finetuned-model-in-DataRobot-Model-Workshop)\n",
    "* [Leveraging DataRobot's LLM Playground to evaluate and compare your fine-tuned LLM against available LLMs](#Add-the-model-to-a-DataRobot-Playground)\n",
    "\n",
    "This accelerator uses Huggingface as a common example that you can modify based on your needs. It uses Weights and Biases to help keep track of your experiments. It is helpful to visualize training loss in real time as well as log prompt results for review during fine-tuning. Also, if you decide to do some hyperparameter tuning, you can do so with W&B Sweeps.  \n",
    "\n",
    "## Considerations\n",
    "\n",
    "This accelerator has been tested in a DataRobot codespace with a GPU resource bundle. `requirement.txt` has a pinned version of the required libraries.  \n",
    "\n",
    "Notebooks images in DataRobot have limited writable space (about 20GB). Therefore, checkpointing models during finetuning is not encouraged, and if you do checkpoint, limit it. This accelerator opts to fine-tune llama-3.2-1B since it is on the smaller side. \n",
    "\n",
    "Use Weights and Biases to track the experiment. The WANDB API Key is available in `.env`.  If you don't have a W&B account, get one at the W&B [sign up](https://www.wandb.ai) (it's free)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718dfa91",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "The first cell of his accelerator installs the requirements for the workflow. The second cell imports necessary packages and sets up connectiond to the DataRobot platform and W&B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff2df714-cc9d-4fa6-a17e-db6be83a6400",
   "metadata": {
    "collapsed": false,
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": 125073,
     "hide_code": false,
     "hide_results": false,
     "language": "python"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "name": "Install required libraries",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "pathos 0.3.3 requires dill>=0.3.9, but you have dill 0.3.8 which is incompatible.\r\n",
      "pathos 0.3.3 requires multiprocess>=0.70.17, but you have multiprocess 0.70.16 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m\n",
      "\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -U -r requirements.txt -q"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5b7a8457-3acb-4c14-84e0-845bbb504433",
   "metadata": {
    "collapsed": false,
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": null,
     "hide_code": false,
     "hide_results": false,
     "language": "markdown"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "scrolled": false
   },
   "source": [
    "In the following cell, update the tokens and remove `.template` from the file name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a42bade-a222-4892-a929-ce28af12aa62",
   "metadata": {
    "collapsed": false,
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": null,
     "hide_code": false,
     "hide_results": false,
     "language": "python"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%writefile .env.template\n",
    "HUGGINGFACE_TOKEN=your-hf-token\n",
    "WANDB_API_KEY=your-wandb-token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3499d488",
   "metadata": {
    "collapsed": false,
    "datarobot": {
     "disable_run": false,
     "execution_time_millis": 6287,
     "hide_code": false,
     "hide_results": false,
     "language": "python"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "scrolled": "auto"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/etc/system/kernel/.venv/lib64/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/notebooks/storage/.venv/lib64/python3.11/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "import time\n",
    "\n",
    "import datarobot as dr\n",
    "from datasets import load_dataset\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import snapshot_download\n",
    "import pandas as pd\n",
    "from peft import LoraConfig, PeftModel\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    logging,\n",
    "    pipeline,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from trl import SFTConfig, SFTTrainer\n",
    "import wandb\n",
    "\n",
    "## Load the environment variables in .env\n",
    "load_dotenv(override=True)\n",
    "\n",
    "## If in a DataRobot notebook, you can just call\n",
    "client = dr.Client()\n",
    "## If you are running this anywhere else, you should will need to provide API token and endpoint\n",
    "# api_key = \"\" # Get this from the Developer Tools page in the DataRobot UI\n",
    "# endpoint = \"https://app.datarobot.com/\" # This should be the URL you use to access the DataRobot UI\n",
    "\n",
    "## this will set the project to track our experiment\n",
    "os.environ[\"WANDB_PROJECT\"] = \"Llama 3.2 1B Fine-Tuning\"\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"/home/notebooks/storage/Finetuning.ipynb\"\n",
    "## we'll have to login to wandb.  You will need to provide your wandb api key when prompted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63be726c",
   "metadata": {
    "collapsed": false,
    "datarobot": {
     "disable_run": false,
     "hide_code": false,
     "hide_results": false,
     "language": "markdown"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "scrolled": "auto"
   },
   "source": [
    "## Get Llama 3.2 1b from Huggingface\n",
    "\n",
    "You are not going directly to Meta for Llama.  Instead use `unsloth/Llama-3.2-1B-Instruct` so that you don't have to request access and wait a few days. Also, you will be fine-tuning Llama Instruct as opposed to the base model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ea8351b-b5bd-44dd-8850-489ffd9023d4",
   "metadata": {
    "collapsed": false,
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": 45,
     "hide_code": false,
     "hide_results": false,
     "language": "python"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 8 files:   0%|          | 0/8 [00:00<?, ?it/s]\r\n",
      "Fetching 8 files: 100%|██████████| 8/8 [00:00<00:00, 67923.95it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/notebooks/storage/unsloth/Llama-3.2-1B-Instruct'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model = \"unsloth/Llama-3.2-1B-Instruct\"\n",
    "adapter = \"llama-3.2-1b-dad-jokes\"\n",
    "snapshot_download(repo_id=base_model, local_dir=base_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1436a989-4782-46d3-a676-03add77e83cb",
   "metadata": {
    "collapsed": false,
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": null,
     "hide_code": false,
     "hide_results": false,
     "language": "markdown"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "scrolled": false
   },
   "source": [
    "## Get the dataset from Huggingface\n",
    "\n",
    "To get the dataset, navigate to `shuttie/dadjokes`.  \n",
    "\n",
    "This dataset is generated from the Kaggle Reddit Dad Jokes by Oktay Ozturk, with the following modifications:\n",
    "\n",
    "* Only jokes with 5+ votes were sampled. Less upvoted jokes are too cringe.\n",
    "* With a set of heuristics, each joke was split into two parts: base and the punchline.\n",
    "\n",
    "There are 52,000 samples in the training dataset.\n",
    "\n",
    "The training data will have two features: question and response. For the purposes of supervised fine-tuning, you can use question as input and response as the label, or you could create a new input call `joke` which will be the concatenation of `question` and `repsonse`, and not provide any label. Seft will automatically set up this up as a next token prediction problem and will create the label for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b925b12b-94ae-4d36-a4da-8a7f920a8f8f",
   "metadata": {
    "collapsed": false,
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": 594,
     "hide_code": false,
     "hide_results": false,
     "language": "python"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict, load_dataset\n",
    "\n",
    "ds = load_dataset(\"shuttie/dadjokes\")\n",
    "df_train = ds[\"train\"].to_pandas()\n",
    "df_train[\"joke\"] = df_train[\"question\"] + \".  \" + df_train[\"response\"]\n",
    "df_train.index.name = \"ID\"\n",
    "df_test = ds[\"test\"].to_pandas()\n",
    "df_test[\"joke\"] = df_test[\"question\"] + \"\\n\" + df_test[\"response\"]\n",
    "train_dataset = Dataset.from_pandas(df_train[[\"joke\"]].dropna())\n",
    "test_dataset = Dataset.from_pandas(df_test[[\"joke\"]].dropna())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f008606e-f61c-4b42-8ce3-b469c1cd9619",
   "metadata": {
    "collapsed": false,
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": null,
     "hide_code": false,
     "hide_results": false,
     "language": "markdown"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "scrolled": false
   },
   "source": [
    "## Get a baseline\n",
    "\n",
    "The goal of this accelerator is to fine-tune Llama 3.2 1B on the data jokes dataset, so first you want to get a sense of how well it does off the shelf. \n",
    "\n",
    "You will end up logging the baseline response to W&B for review later if desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ab2f9ae",
   "metadata": {
    "datarobot": {
     "execution_time_millis": 3
    }
   },
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    \"where do baby cows eat lunch?\",  ## in the calf-eteria\n",
    "    \"What happens when a frog parks illegally\",  ## his car gets toad\n",
    "    \"why did mr potatoe head get pulled over\",  ## he was baked\n",
    "    \"what's a pirates favorite programming language\",  ## Rrrrrr!!\n",
    "    \"tell me a joke\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6daccbd7",
   "metadata": {
    "collapsed": false,
    "datarobot": {
     "disable_run": false,
     "execution_time_millis": 2909,
     "hide_code": false,
     "hide_results": false,
     "language": "python"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "scrolled": "auto"
   },
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(base_model, device_map={\"\": 0})\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e414fa66-ed37-4359-89d4-1b6335e85ab8",
   "metadata": {
    "collapsed": false,
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": 19732,
     "hide_code": false,
     "hide_results": false,
     "language": "python"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/notebooks/storage/wandb/run-20250204_183227-12g9t2ee</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tim-whittaker/Llama%203.2%201B%20Fine-Tuning/runs/12g9t2ee' target=\"_blank\">peach-sea-2</a></strong> to <a href='https://wandb.ai/tim-whittaker/Llama%203.2%201B%20Fine-Tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tim-whittaker/Llama%203.2%201B%20Fine-Tuning' target=\"_blank\">https://wandb.ai/tim-whittaker/Llama%203.2%201B%20Fine-Tuning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tim-whittaker/Llama%203.2%201B%20Fine-Tuning/runs/12g9t2ee' target=\"_blank\">https://wandb.ai/tim-whittaker/Llama%203.2%201B%20Fine-Tuning/runs/12g9t2ee</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">peach-sea-2</strong> at: <a href='https://wandb.ai/tim-whittaker/Llama%203.2%201B%20Fine-Tuning/runs/12g9t2ee' target=\"_blank\">https://wandb.ai/tim-whittaker/Llama%203.2%201B%20Fine-Tuning/runs/12g9t2ee</a><br> View project at: <a href='https://wandb.ai/tim-whittaker/Llama%203.2%201B%20Fine-Tuning' target=\"_blank\">https://wandb.ai/tim-whittaker/Llama%203.2%201B%20Fine-Tuning</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250204_183227-12g9t2ee/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.dataframe+json": {
       "columns": [
        {
         "name": "index",
         "type": "integer"
        },
        {
         "name": "promptText",
         "type": "string"
        },
        {
         "name": "resultText",
         "type": "string"
        }
       ],
       "count": 5,
       "data": [
        {
         "index": 0,
         "promptText": "where do baby cows eat lunch?",
         "resultText": "where do baby cows eat lunch? In the pasture, they eat grasses and other plants that grow in the fields. The plants grow in the fields because the cows help to spread them out. The cows help to spread them out by eating the plants and then leaving behind seeds. The seeds then grow into new plants. This is called a \"seed dispersal\" process. The cows eat the seeds and then leave behind a small piece of the plant. The plant grows into a new plant, which is then eaten by the cow. This is a natural process that has been happening for thousands of years. The cows are not the only ones that help to spread the plants. Many other animals, such as birds and insects, also help to spread the plants. This is why the grasslands are so diverse and rich in wildlife. The cows are the main grazers of the grasslands, and they help to keep the grasslands healthy and productive. The cows are not the only ones that help"
        },
        {
         "index": 1,
         "promptText": "What happens when a frog parks illegally",
         "resultText": "What happens when a frog parks illegally\nIf a frog is parked in a designated parking space, it will likely be ticketed by a parking enforcement officer. The officer will issue a citation to the frog, which will likely be a fine of some sort.\nIf a frog is parked in a no-parking zone or a restricted area, it may be towed by a tow truck. The frog may be taken to a nearby animal shelter or a wildlife rehabilitation center to be cared for until it can be released back into the wild.\nIf a frog is parked in a public space, such as a park or a street, and it is not causing a disturbance or is not obstructing traffic, it may be allowed to stay in its designated parking space. However, if the frog is causing a disturbance or is obstructing traffic, it may be asked to leave by a parking enforcement officer.\nIn some cases, a frog may be relocated to a different location if it is causing a disturbance or is obstruct"
        },
        {
         "index": 2,
         "promptText": "why did mr potatoe head get pulled over",
         "resultText": "why did mr potatoe head get pulled over by the police?\nMr. Potato Head was pulled over by the police because he was driving in a vehicle with a broken rearview mirror. The police officer was concerned that Mr. Potato Head might be driving recklessly or distractedly due to the broken mirror."
        },
        {
         "index": 3,
         "promptText": "what's a pirates favorite programming language",
         "resultText": "what's a pirates favorite programming language?\nA) Python\nB) JavaScript\nC) Java\nD) C++\nE) C#\nF) Ruby\nG) Swift\n\nThe best answer is F."
        },
        {
         "index": 4,
         "promptText": "tell me a joke",
         "resultText": "tell me a joke\nWhy did the math book look so sad?\nBecause it had too many problems.\n\nHow was that? Did I make you laugh?"
        }
       ],
       "error": [],
       "indexKey": "index",
       "limit": 10,
       "offset": 0,
       "referenceId": 139770152671696,
       "sortedBy": "",
       "totalCount": 5
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>promptText</th>\n",
       "      <th>resultText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>where do baby cows eat lunch?</td>\n",
       "      <td>where do baby cows eat lunch? In the pasture, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What happens when a frog parks illegally</td>\n",
       "      <td>What happens when a frog parks illegally\\nIf a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>why did mr potatoe head get pulled over</td>\n",
       "      <td>why did mr potatoe head get pulled over by the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what's a pirates favorite programming language</td>\n",
       "      <td>what's a pirates favorite programming language...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tell me a joke</td>\n",
       "      <td>tell me a joke\\nWhy did the math book look so ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       promptText  \\\n",
       "0                   where do baby cows eat lunch?   \n",
       "1        What happens when a frog parks illegally   \n",
       "2         why did mr potatoe head get pulled over   \n",
       "3  what's a pirates favorite programming language   \n",
       "4                                  tell me a joke   \n",
       "\n",
       "                                          resultText  \n",
       "0  where do baby cows eat lunch? In the pasture, ...  \n",
       "1  What happens when a frog parks illegally\\nIf a...  \n",
       "2  why did mr potatoe head get pulled over by the...  \n",
       "3  what's a pirates favorite programming language...  \n",
       "4  tell me a joke\\nWhy did the math book look so ...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with wandb.init(job_type=\"baseline-eval\") as run:\n",
    "    pipe = pipeline(\n",
    "        \"text-generation\", model=model, tokenizer=tokenizer, max_length=200, truncation=True\n",
    "    )\n",
    "    results = [result[0][\"generated_text\"] for result in pipe(prompts)]\n",
    "    test_df = pd.DataFrame({\"promptText\": prompts, \"resultText\": results})\n",
    "    wandb.log({\"prompts\": test_df})\n",
    "test_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a0415f6e-c279-4e36-8ec4-11b52b19e440",
   "metadata": {
    "collapsed": false,
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": null,
     "hide_code": false,
     "hide_results": false,
     "language": "markdown"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "scrolled": false
   },
   "source": [
    "## Fine-tune Llama\n",
    "\n",
    "Utilize QLoRA (Quantized Low-Rank Adaption) for fine-tuning.  QLoRA a technique designed to efficiently fine-tune large language models (LLMs) with reduced computational resources. It focuses on optimizing both the model’s performance and memory usage, which makes it particularly useful when working with massive models that would otherwise be too resource-intensive to fine-tune.\n",
    "\n",
    "Low-Rank Adaptation (LoRA): LoRA is a method that introduces low-rank matrices to the model’s weights during fine-tuning. Instead of updating all the parameters of the model (which can be very expensive), LoRA only modifies a small subset of parameters—specifically, the low-rank matrices that can capture important changes to the model's behavior. This reduces the number of parameters being trained, which reduces both the memory and computational costs.\n",
    "\n",
    "Quantization: In QLoRA, the idea of quantization comes into play, which involves reducing the precision of the model's weights (e.g., from 32-bit floating-point numbers to lower-bit precision like 8-bit or 4-bit). This can dramatically lower the memory footprint of the model and make it possible to fine-tune large models on hardware with limited resources, like consumer GPUs or cloud-based systems with memory constraints.\n",
    "\n",
    "There a number of tunable hyperparameters, but the ones that are of particular interest (based on empiral evidence) are the Rank of the Low-Rank Adaptation, and the modules to target. Meaning what modules in the LLM should we apply LoRA to.  Recommendations are to target linear layers, so that is exactly what we'll do.\n",
    "\n",
    "The result will be an adapter that you will be able to apply to Llama 3.2 1B that should do a better job telling dad jokes and making up puns for dad jokes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b139f878-ea0f-43ef-9c86-428fb8c5713b",
   "metadata": {
    "collapsed": false,
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": 5,
     "hide_code": false,
     "hide_results": false,
     "language": "python"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Identify all the linear modules\n",
    "import re\n",
    "\n",
    "model_modules = str(model.modules)\n",
    "pattern = r\"\\((\\w+)\\): Linear\"\n",
    "linear_layer_names = re.findall(pattern, model_modules)\n",
    "\n",
    "names = []\n",
    "# Print the names of the Linear layers\n",
    "for name in linear_layer_names:\n",
    "    names.append(name)\n",
    "target_modules = list(set(names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9bc145a6-fb00-4d5d-84e3-2957ef45249f",
   "metadata": {
    "collapsed": false,
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": 474,
     "hide_code": false,
     "hide_results": false,
     "language": "python"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Next, do some cleanup. To quantize the model at load time, get rid of\n",
    "## any previous instance\n",
    "try:\n",
    "    del model, tokenizer, pipe\n",
    "except:\n",
    "    pass\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f094b9d8-e045-4faf-91d7-69c8ecf1c345",
   "metadata": {
    "collapsed": false,
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": 65967,
     "hide_code": false,
     "hide_results": false,
     "language": "python"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/notebooks/storage/wandb/run-20250204_183303-ot1c0por</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tim-whittaker/Llama%203.2%201B%20Fine-Tuning/runs/ot1c0por' target=\"_blank\">kind-field-3</a></strong> to <a href='https://wandb.ai/tim-whittaker/Llama%203.2%201B%20Fine-Tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tim-whittaker/Llama%203.2%201B%20Fine-Tuning' target=\"_blank\">https://wandb.ai/tim-whittaker/Llama%203.2%201B%20Fine-Tuning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tim-whittaker/Llama%203.2%201B%20Fine-Tuning/runs/ot1c0por' target=\"_blank\">https://wandb.ai/tim-whittaker/Llama%203.2%201B%20Fine-Tuning/runs/ot1c0por</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_347/3402060699.py:61: FutureWarning: `tokenizer` is deprecated and removed starting from version 0.16.0 for `SFTTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = SFTTrainer(\n",
      "/home/notebooks/storage/.venv/lib64/python3.11/site-packages/peft/tuners/tuners_utils.py:543: UserWarning: Model with `tie_word_embeddings=True` and the tied_target_modules=['lm_head'] are part of the adapter. This can lead to complications, for example when merging the adapter or converting your model to formats other than safetensors. See for example https://github.com/huggingface/peft/issues/2018.\n",
      "  warnings.warn(\n",
      "Map: 100%|██████████| 51760/51760 [00:07<00:00, 7019.04 examples/s]\r\n",
      "Map: 100%|██████████| 51760/51760 [00:07<00:00, 7015.47 examples/s]\n",
      "Map:  72%|███████▏  | 1000/1391 [00:00<00:00, 6995.23 examples/s]\r\n",
      "Map: 100%|██████████| 1391/1391 [00:00<00:00, 7011.98 examples/s]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  2/100 : < :, Epoch 0.00/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/notebooks/storage/.venv/lib64/python3.11/site-packages/peft/utils/save_and_load.py:230: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "Device set to use cuda:0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./llama-3.2-1b-dad-jokes)... \n",
      "Done. 2.6s\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁▃▆██</td></tr><tr><td>train/global_step</td><td>▁▃▆███</td></tr><tr><td>train/grad_norm</td><td>▁█▁▅</td></tr><tr><td>train/learning_rate</td><td>▁▁▁▁</td></tr><tr><td>train/loss</td><td>█▃▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>total_flos</td><td>81881985515520.0</td></tr><tr><td>train/epoch</td><td>0.00773</td></tr><tr><td>train/global_step</td><td>100</td></tr><tr><td>train/grad_norm</td><td>7.33316</td></tr><tr><td>train/learning_rate</td><td>0.0002</td></tr><tr><td>train/loss</td><td>3.2073</td></tr><tr><td>train_loss</td><td>3.34339</td></tr><tr><td>train_runtime</td><td>23.6551</td></tr><tr><td>train_samples_per_second</td><td>16.91</td></tr><tr><td>train_steps_per_second</td><td>4.227</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">kind-field-3</strong> at: <a href='https://wandb.ai/tim-whittaker/Llama%203.2%201B%20Fine-Tuning/runs/ot1c0por' target=\"_blank\">https://wandb.ai/tim-whittaker/Llama%203.2%201B%20Fine-Tuning/runs/ot1c0por</a><br> View project at: <a href='https://wandb.ai/tim-whittaker/Llama%203.2%201B%20Fine-Tuning' target=\"_blank\">https://wandb.ai/tim-whittaker/Llama%203.2%201B%20Fine-Tuning</a><br>Synced 5 W&B file(s), 1 media file(s), 6 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250204_183303-ot1c0por/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with wandb.init(config=dict(lora_dropout=0.1, lora_rank=8)) as run:\n",
    "    compute_dtype = getattr(torch, \"float16\")\n",
    "    ## quantiziation configuration\n",
    "    quant_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=compute_dtype,\n",
    "        bnb_4bit_use_double_quant=False,\n",
    "    )\n",
    "    ## load the model\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        base_model, quantization_config=quant_config, device_map={\"\": 0}\n",
    "    )\n",
    "    model.config.use_cache = False\n",
    "    model.config.pretraining_tp = 1\n",
    "    ## load the tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.padding_side = \"right\"\n",
    "\n",
    "    ## lora configuration\n",
    "    lora_dropout = run.config.lora_dropout\n",
    "    lora_rank = run.config.lora_rank\n",
    "    peft_params = LoraConfig(\n",
    "        lora_alpha=16,\n",
    "        lora_dropout=lora_dropout,\n",
    "        r=lora_rank,\n",
    "        bias=\"none\",\n",
    "        task_type=\"CAUSAL_LM\",\n",
    "        target_modules=target_modules,\n",
    "    )\n",
    "\n",
    "    ## training argument.\n",
    "    training_args = SFTConfig(\n",
    "        max_seq_length=256,\n",
    "        dataset_text_field=\"joke\",\n",
    "        # dataset_labels_field\n",
    "        output_dir=f\"./dad-jokes/{run.id}\",\n",
    "        num_train_epochs=1,\n",
    "        per_device_train_batch_size=4,\n",
    "        gradient_accumulation_steps=1,\n",
    "        optim=\"paged_adamw_32bit\",\n",
    "        save_steps=0,  # Disable saving checkpoints\n",
    "        save_strategy=\"no\",  # Disable saving strategy\n",
    "        logging_steps=25,\n",
    "        learning_rate=2e-4,\n",
    "        weight_decay=0.001,\n",
    "        fp16=False,\n",
    "        bf16=False,\n",
    "        max_grad_norm=0.3,\n",
    "        max_steps=100,  ## we just ran through the first 400 (per_device_train_batch_size * max_steps). set this to -1 to use the entire dataset\n",
    "        warmup_ratio=0.03,\n",
    "        group_by_length=True,\n",
    "        lr_scheduler_type=\"constant\",\n",
    "        report_to=\"wandb\",\n",
    "    )\n",
    "\n",
    "    ## set up trainer\n",
    "    trainer = SFTTrainer(\n",
    "        model=model,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=test_dataset,\n",
    "        peft_config=peft_params,\n",
    "        tokenizer=tokenizer,\n",
    "        args=training_args,\n",
    "    )\n",
    "\n",
    "    ## finetune\n",
    "    ## this takes ~30-40min\n",
    "    trainer.train()\n",
    "\n",
    "    ## save the adapter\n",
    "    trainer.model.save_pretrained(f\"./dad-jokes/{wandb.run.id}/{adapter}\")\n",
    "\n",
    "    ## evaluate the model with some propts and log it to W&B\n",
    "    pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "    trainer.model.save_pretrained(adapter)\n",
    "    artifact = wandb.Artifact(name=\"adapter\", type=\"adapter\")\n",
    "    artifact.add_dir(adapter)\n",
    "    run.log_artifact(artifact)\n",
    "    prompt_results = [\n",
    "        result[0][\"generated_text\"] for result in pipe(prompts, max_length=25, truncation=True)\n",
    "    ]\n",
    "    results_df = pd.DataFrame(dict(promptText=prompts, resultsText=prompt_results))\n",
    "    ## log our fine tune model responses to wandb\n",
    "    wandb.log({\"prompts\": results_df})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de8ce119-a523-4d6f-8c45-bb1092184c2f",
   "metadata": {
    "collapsed": false,
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": 9,
     "hide_code": false,
     "hide_results": false,
     "language": "python"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.dataframe+json": {
       "columns": [
        {
         "name": "index",
         "type": "integer"
        },
        {
         "name": "promptText",
         "type": "string"
        },
        {
         "name": "resultsText",
         "type": "string"
        }
       ],
       "count": 5,
       "data": [
        {
         "index": 0,
         "promptText": "where do baby cows eat lunch?",
         "resultsText": "where do baby cows eat lunch?  In the pasture.  No, that's not it.  In the pasture"
        },
        {
         "index": 1,
         "promptText": "What happens when a frog parks illegally",
         "resultsText": "What happens when a frog parks illegally.  He's a hop-py man.  (Frog parkin'"
        },
        {
         "index": 2,
         "promptText": "why did mr potatoe head get pulled over",
         "resultsText": "why did mr potatoe head get pulled over.  because he was a-peeling.  no, because he was"
        },
        {
         "index": 3,
         "promptText": "what's a pirates favorite programming language",
         "resultsText": "what's a pirates favorite programming language.  Pirc.  Pirate.  C.  Pirate.  Pirate."
        },
        {
         "index": 4,
         "promptText": "tell me a joke",
         "resultsText": "tell me a joke.  A chicken.  Because he was egg-cellent.  But I'm egg-ha"
        }
       ],
       "error": [],
       "indexKey": "index",
       "limit": 10,
       "offset": 0,
       "referenceId": 139770720845392,
       "sortedBy": "",
       "totalCount": 5
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>promptText</th>\n",
       "      <th>resultsText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>where do baby cows eat lunch?</td>\n",
       "      <td>where do baby cows eat lunch?  In the pasture....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What happens when a frog parks illegally</td>\n",
       "      <td>What happens when a frog parks illegally.  He'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>why did mr potatoe head get pulled over</td>\n",
       "      <td>why did mr potatoe head get pulled over.  beca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what's a pirates favorite programming language</td>\n",
       "      <td>what's a pirates favorite programming language...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tell me a joke</td>\n",
       "      <td>tell me a joke.  A chicken.  Because he was eg...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       promptText  \\\n",
       "0                   where do baby cows eat lunch?   \n",
       "1        What happens when a frog parks illegally   \n",
       "2         why did mr potatoe head get pulled over   \n",
       "3  what's a pirates favorite programming language   \n",
       "4                                  tell me a joke   \n",
       "\n",
       "                                         resultsText  \n",
       "0  where do baby cows eat lunch?  In the pasture....  \n",
       "1  What happens when a frog parks illegally.  He'...  \n",
       "2  why did mr potatoe head get pulled over.  beca...  \n",
       "3  what's a pirates favorite programming language...  \n",
       "4  tell me a joke.  A chicken.  Because he was eg...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cfb99c33-1c32-459b-881f-1d76f12cd362",
   "metadata": {
    "collapsed": false,
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": 1515,
     "hide_code": false,
     "hide_results": false,
     "language": "python"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "name": "plot out training loss",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGdCAYAAAAxCSikAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/av/WaAAAACXBIWXMAAA9hAAAPYQGoP6dpAABIcklEQVR4nO3deVhU9eIG8PfMAAMCM4jKJqgICILhmoa5pKKgpvjrdm91K6w00+qWWXnjlit2celmtqFXK1uucW+WWy6oJLjhhqIs7oiAsrgxwyIDzJzfHyRFgjJsZ5b38zznSWe+Z3jPaZ7h9TvfOSOIoiiCiIiIyIjJpA5AREREdD8sLERERGT0WFiIiIjI6LGwEBERkdFjYSEiIiKjx8JCRERERo+FhYiIiIweCwsREREZPSupA7QEvV6Pq1evwtHREYIgSB2HiIiIGkEURZSUlMDDwwMy2b3nUMyisFy9ehVeXl5SxyAiIqImyM3Nhaen5z3HmEVhcXR0BFBzwEqlUuI0RERE1BgajQZeXl61v8fvxSwKy523gZRKJQsLERGRiWnMcg4uuiUiIiKjx8JCRERERo+FhYiIiIweCwsREREZPRYWIiIiMnosLERERGT0WFiIiIjI6LGwEBERkdFjYSEiIiKjx8JCRERERo+FhYiIiIweCwsREREZPbP48sPWUlGlw+d7LsBKLsNro/ykjkNERGSxWFju4cCF6/j4lwuwkcvwaLA7undykDoSERGRReJbQvcwMsAFj/h3QqVOj3mbMyCKotSRiIiILBILyz0IgoAFE4NgYyXDvvPXsS2tQOpIREREFomF5T66drDHjOE+AIDonzNRqq2WOBEREZHlMaiwxMbGIjg4GEqlEkqlEiEhIdi+fXuD49euXQtBEOpstra2dcY899xzd40JDw9v2tG0khmP+KCLczsUaCqwYvc5qeMQERFZHIMKi6enJxYvXoyUlBQcO3YMI0eOREREBDIyMhrcR6lUIj8/v3a7fPnyXWPCw8PrjPn+++8NP5JWZGstx4KIIADAlweycbagROJERERElsWgTwlNmDChzt/ff/99xMbG4tChQwgKCqp3H0EQ4Obmds/HVSgU9x0jtRH+LggLckV8RiHmbErHf6c9BEEQpI5FRERkEZq8hkWn0yEuLg5lZWUICQlpcFxpaSm6du0KLy+vBmdjEhMT4eLiAn9/f8yYMQM3bty458/WarXQaDR1trYwd0IQ7KzlOHLpJjacuNImP5OIiIiaUFjS0tLg4OAAhUKB6dOnY8OGDQgMDKx3rL+/P7788kts2rQJ3333HfR6PQYPHoy8vLzaMeHh4fjmm2+QkJCAJUuWICkpCWPHjoVOp2swQ0xMDFQqVe3m5eVl6GE0SWcnO/xtlC8A4J/bTkN9u6pNfi4REZGlE0QDLy5SWVmJnJwcqNVqrF+/HmvWrEFSUlKDpeX3qqqq0LNnTzz11FOIjo6ud0xWVhZ8fHywe/dujBo1qt4xWq0WWq229u8ajQZeXl5Qq9VQKpWGHI7BKqv1GLtiLy5eK8PkkK5YENGrVX8eERGRudJoNFCpVI36/W3wDIuNjQ18fX3Rv39/xMTEoHfv3lixYkWj9rW2tkbfvn1x4cKFBsd0794dHTt2vOcYhUJR+0mlO1tbsbGSIfrXkvLtoctIv6Jus59NRERkqZp9HRa9Xl9ntuNedDod0tLS4O7u3uCYvLw83Lhx455jpDbYtyMm9PaAXgTe25gOvZ5XwCUiImpNBhWWqKgo7N27F9nZ2UhLS0NUVBQSExPx9NNPAwAiIyMRFRVVO37hwoXYuXMnsrKycPz4cTzzzDO4fPkypk6dCqBmQe7bb7+NQ4cOITs7GwkJCYiIiICvry/CwsJa8DBb3nvje8JBYYXU3GL871iu1HGIiIjMmkEfay4qKkJkZCTy8/OhUqkQHByM+Ph4jB49GgCQk5MDmey3DnTr1i28+OKLKCgoQPv27dG/f38cPHiwdr2LXC7HqVOn8PXXX6O4uBgeHh4YM2YMoqOjoVAoWvAwW56r0hYzQ/2waOtpLNlxBmFBbmhvbyN1LCIiIrNk8KJbY2TIop2WVK3T49FP9uNMQQmeGuiFmMeC2+xnExERmbpWXXRLv7GSyxA9qWYBbtzRXJzIuSVxIiIiIvPEwtJMD3Zzxp/6eUIUgTmb0qHjAlwiIqIWx8LSAqLGBUBpa4X0Kxr85/Dd35VEREREzcPC0gI6Oijwdpg/AGBZ/FlcK2ncx7yJiIiocVhYWshfB3XFA51VKKmoRsy201LHISIiMissLC1ELhMQPakXBAH46cQVHM669xc4EhERUeOxsLSgPl5OeGpgFwA1C3CrdHqJExEREZkHFpYWNjvMH872NjhXWIq1B7KljkNERGQWWFhamFM7G7wTHgAA+Gj3ORSoKyROREREZPpYWFrB4/090a+LE8oqdYjemil1HCIiIpPHwtIKZL8uwJUJwNZT+dh//rrUkYiIiEwaC0srCfJQITKkGwBg7qZ0aKt10gYiIiIyYSwsrWjWmB7o5KhA1vUyrNl3Seo4REREJouFpRUpba3x7rieAIBPfjmP3JvlEiciIiIyTSwsrSyijwce6u6Miio9Fv7MBbhERERNwcLSygRBQHREL1jJBOzKLMQvZwqljkRERGRyWFjagJ+rI6YM8QYAzNucgYoqLsAlIiIyBAtLG3ltlB/cVbbIvXkbnydelDoOERGRSWFhaSP2CivMeTQQALAy6SIuXS+TOBEREZHpYGFpQ2N7uWGoX0dUVusxb3MGRFGUOhIREZFJYGFpQ4IgYGFEL9jIZdh77hp2pBdIHYmIiMgksLC0Me+O9pg+vDsAYOHPmSjTVkuciIiIyPixsEjg5RG+8HK2Q766Ah//cl7qOEREREaPhUUCttZyzJ8QBAD4Yt8lnC8skTgRERGRcWNhkcionq4I7emKar2IOZvSuQCXiIjoHlhYJDRvQiBsrWU4lHUTm09elToOERGR0WJhkZCXczu8OsIXALBo62loKqokTkRERGScWFgk9uKw7uje0R7XSrRYvuuc1HGIiIiMEguLxBRWciyIqFmA+/XBbGRe1UiciIiIyPiwsBiBoX6dMP4Bd+hFYM6mdOj1XIBLRET0eywsRuK9R3uinY0cKZdvYf3xPKnjEBERGRUWFiPhrrLDzFA/AMDi7WdQXF4pcSIiIiLjwcJiRJ5/2Bs9XB1ws6wSy+LPSh2HiIjIaLCwGBFruQwLI3oBANYdycHJ3GJpAxERERkJFhYj81D3Dvi/vp0hisB7G9Oh4wJcIiIiFhZjFDUuAI4KK6RdUWPdkRyp4xAREUmOhcUIuTja4s0xPQAAy3acwfVSrcSJiIiIpGVQYYmNjUVwcDCUSiWUSiVCQkKwffv2BsevXbsWgiDU2WxtbeuMEUURc+fOhbu7O+zs7BAaGorz58837WjMyDMPdUWQhxKaimos3n5G6jhERESSMqiweHp6YvHixUhJScGxY8cwcuRIREREICMjo8F9lEol8vPza7fLly/XuX/p0qX4+OOPsXLlShw+fBj29vYICwtDRUVF047ITFjJZYieVLMAd31KHo5l35Q4ERERkXQMKiwTJkzAuHHj4Ofnhx49euD999+Hg4MDDh061OA+giDAzc2tdnN1da29TxRFfPTRR3jvvfcQERGB4OBgfPPNN7h69So2btzY5IMyF/26tMeTD3oBqFmAW63TS5yIiIhIGk1ew6LT6RAXF4eysjKEhIQ0OK60tBRdu3aFl5fXXbMxly5dQkFBAUJDQ2tvU6lUGDRoEJKTkxt8TK1WC41GU2czV7PDA+DUzhpnCkrwdfLl++9ARERkhgwuLGlpaXBwcIBCocD06dOxYcMGBAYG1jvW398fX375JTZt2oTvvvsOer0egwcPRl5ezaXnCwoKAKDOrMudv9+5rz4xMTFQqVS1m5eXl6GHYTKc7W3w9/AAAMDyXedQqLHst8qIiMgyGVxY/P39kZqaisOHD2PGjBmYPHkyMjMz6x0bEhKCyMhI9OnTB8OHD8dPP/2ETp06YdWqVc0KHRUVBbVaXbvl5uY26/GM3RMDvNDHywml2mq8v/W01HGIiIjanMGFxcbGBr6+vujfvz9iYmLQu3dvrFixolH7Wltbo2/fvrhw4QIAwM3NDQBQWFhYZ1xhYWHtffVRKBS1n1S6s5kzmUzAokm9IBOAzSev4uCF61JHIiIialPNvg6LXq+HVtu464TodDqkpaXB3d0dAODt7Q03NzckJCTUjtFoNDh8+PA918VYol6dVXjmoa4AgDmb0lFZzQW4RERkOQwqLFFRUdi7dy+ys7ORlpaGqKgoJCYm4umnnwYAREZGIioqqnb8woULsXPnTmRlZeH48eN45plncPnyZUydOhVAzSeIZs6ciUWLFmHz5s1IS0tDZGQkPDw8MGnSpJY7SjPx5hh/dHSwwcVrZfhi/yWp4xAREbUZK0MGFxUVITIyEvn5+VCpVAgODkZ8fDxGjx4NAMjJyYFM9lsHunXrFl588UUUFBSgffv26N+/Pw4ePFhnke7s2bNRVlaGadOmobi4GEOGDMGOHTvuusAcASo7a0SN7Yk3fziJjxPOY2IfD3R2spM6FhERUasTRFE0+W/X02g0UKlUUKvVZr+eRRRFPLHqEI5k30R4kBtWPttf6khERERNYsjvb36XkIkRBAELJwVBLhOwI6MAiWeLpI5ERETU6lhYTFCAmxLPD+4GAJi3OQMVVTppAxEREbUyFhYTNXN0D7gqFbh8oxwrky5KHYeIiKhVsbCYKAeFFd4bX7N4+fPEi7h8o0ziRERERK2HhcWEPRrsjiG+HVFZrcf8zRkwg/XTRERE9WJhMWGCIGBBRBCs5QL2nL2GnZmF99+JiIjIBLGwmDifTg6YNqw7AGDhlkyUV1ZLnIiIiKjlsbCYgVdH+KGzkx2uFN/Gp79ckDoOERFRi2NhMQN2NnLMm1CzAHf1vixcKCqVOBEREVHLYmExE6MDXTEywAVVOhHzNqdzAS4REZkVFhYzIQgC5k8IgsJKhgMXbuDnU/lSRyIiImoxLCxmpEuHdnj5EV8AwKKtmSjVcgEuERGZBxYWM/PS8O7o2qEdCjVafLTrnNRxiIiIWgQLi5mxtZZjwcQgAMBXB7NxpkAjcSIiIqLmY2ExQ4/4uyA8yA06vYi5G3kFXCIiMn0sLGZq7oRA2FnLcST7Jn46fkXqOERERM3CwmKmPJzs8NooPwBAzPbTUJdXSZyIiIio6VhYzNiUId7wdXHA9dJKfLDzrNRxiIiImoyFxYzZWMmwMKJmAe53hy8jLU8tcSIiIqKmYWExc4N9OiKijwdEEXhvUzr0ei7AJSIi08PCYgHeHdcTjgornMwtRtzRXKnjEBERGYyFxQK4KG3xxugeAICl8Wdws6xS4kRERESGYWGxEJEhXdHTXYni8ios2X5G6jhEREQGYWGxEFZyGRZNqlmA+99juUi5fEviRERERI3HwmJB+nd1xp/7ewIA5mxMR7VOL3EiIiKixmFhsTDvjA2Ays4amfkafHfostRxiIiIGoWFxcJ0cFDg7TB/AMC/dp5DUUmFxImIiIjuj4XFAj01sAuCPVUo0VYjZhsX4BIRkfFjYbFAcpmARZN6QRCADSeu4FDWDakjERER3RMLi4UK9nTCXwd2AQDM3ZSOKi7AJSIiI8bCYsHeDvOHs70NzhWW4qsDl6SOQ0RE1CAWFgvm1M4G74wNAAB8tPs88tW3JU5ERERUPxYWC/d4P0/079oe5ZU6RP+cKXUcIiKierGwWDiZTEB0RC/IBGBbWgH2nrsmdSQiIqK7sLAQAj2UmDy4GwBg3uYMaKt10gYiIiL6AxYWAgDMGt0DLo4KXLpehn8nZUkdh4iIqA4WFgIAONpa493xPQEAn+65gNyb5RInIiIi+o1BhSU2NhbBwcFQKpVQKpUICQnB9u3bG7VvXFwcBEHApEmT6tz+3HPPQRCEOlt4eLghsaiFTOztgZDuHaCt1mPBlgyp4xAREdUyqLB4enpi8eLFSElJwbFjxzBy5EhEREQgI+Pev9yys7Px1ltvYejQofXeHx4ejvz8/Nrt+++/NyQWtRBBEBA9KQjWcgG7Txdhd2ah1JGIiIgAGFhYJkyYgHHjxsHPzw89evTA+++/DwcHBxw6dKjBfXQ6HZ5++mksWLAA3bt3r3eMQqGAm5tb7da+fXvDjoJajK+LI6YMqfn/NH9LBm5XcgEuERFJr8lrWHQ6HeLi4lBWVoaQkJAGxy1cuBAuLi6YMmVKg2MSExPh4uICf39/zJgxAzdu3Pu7bbRaLTQaTZ2NWs5ro3zhobJF3q3b+DzxgtRxiIiIDC8saWlpcHBwgEKhwPTp07FhwwYEBgbWO3b//v344osvsHr16gYfLzw8HN988w0SEhKwZMkSJCUlYezYsdDpGv6XfUxMDFQqVe3m5eVl6GHQPbSzscLcCTX/T1clZeHS9TKJExERkaUTRFEUDdmhsrISOTk5UKvVWL9+PdasWYOkpKS7SktJSQmCg4Px+eefY+zYsQBqFtgWFxdj48aNDT5+VlYWfHx8sHv3bowaNareMVqtFlqttvbvGo0GXl5eUKvVUCqVhhwONUAURTz31VEknbuGoX4d8c0LAyEIgtSxiIjIjGg0GqhUqkb9/ja4sPxRaGgofHx8sGrVqjq3p6amom/fvpDL5bW36fU13wgsk8lw9uxZ+Pj41PuYnTp1wqJFi/DSSy81KoMhB0yNl329DGM+2ovKaj0+f7ofxj3gLnUkIiIyI4b8/m72dVj0en2d2Y47AgICkJaWhtTU1Npt4sSJGDFiBFJTUxt8GycvLw83btyAuzt/OUqtW0d7TB9eUyoXbslEmbZa4kRERGSprAwZHBUVhbFjx6JLly4oKSnBunXrkJiYiPj4eABAZGQkOnfujJiYGNja2qJXr1519ndycgKA2ttLS0uxYMEC/OlPf4KbmxsuXryI2bNnw9fXF2FhYS1weNRcLz/igw0n8pB78zY+TjiPqHE9pY5EREQWyKAZlqKiIkRGRsLf3x+jRo3C0aNHER8fj9GjRwMAcnJykJ+f3+jHk8vlOHXqFCZOnIgePXpgypQp6N+/P/bt2weFQmHYkVCrsLWWY8HEIADAF/sv4VxhicSJiIjIEjV7DYsx4BqW1vfiN8ewK7MQA72d8d9pD3EBLhERNVubrmEhyzBvQiBsrWU4cukmNqZekToOERFZGBYWahTP9u3wt5F+AID3t56B+naVxImIiMiSsLBQo00d6o3unexxvVSL5bvOSR2HiIgsCAsLNZrCSo7oiJpPeH2TnI30K2qJExERkaVgYSGDPOzbEY8Gu0MvAnM2pUOvN/k120REZAJYWMhg740PhL2NHCdyivFDSq7UcYiIyAKwsJDB3FS2eGN0DwDA4u1ncKusUuJERERk7lhYqEkmD+4Gf1dH3CqvwtL4s1LHISIiM8fCQk1iLZchelLNAty4ozlIzS2WNhAREZk1FhZqsoHeznisX2eIIvDexjTouACXiIhaCQsLNUvU2J5wtLVC+hUN1h2+LHUcIiIyUyws1CydHBV4O8wfALAs/iyul2olTkREROaIhYWa7elBXdGrsxKaimrEbDsjdRwiIjJDLCzUbHKZgOiIXhAE4MfjeThy6abUkYiIyMywsFCL6NulPZ580AsAMGdjOqp0eokTERGROWFhoRYzOywA7dtZ42xhCb4+mC11HCIiMiMsLNRi2tvb4O/hAQCA5bvOoUBdIXEiIiIyFyws1KL+MsALfbs4oaxSh0VbM6WOQ0REZoKFhVqU7NcFuDIB+PlUPg5cuC51JCIiMgMsLNTienVWITKkGwBgzqZ0aKt10gYiIiKTx8JCrWLWmB7o6KBA1rUyrNl3Seo4RERk4lhYqFUoba3x7viaBbif/HIeebfKJU5ERESmjIWFWs2kPp0xyNsZFVV6LNzCBbhERNR0LCzUagRBQPSkXrCSCdiZWYg9Z4qkjkRERCaKhYVaVQ9XR7wwxBsAMG9zBiqquACXiIgMx8JCre71UX5wU9oi52Y5YhMvSh2HiIhMEAsLtTp7hRXmPBoIAIhNuojLN8okTkRERKaGhYXaxLgH3DDUryMqq/WYtzkDoihKHYmIiEwICwu1CUEQsGBiEGzkMiSevYb4jEKpIxERkQlhYaE2072TA6YN6w4AWLglA+WV1RInIiIiU8HCQm3qlRG+6Oxkh6vqCnyccEHqOEREZCJYWKhN2dnIMX9iEABgzb4sXCgqkTgRERGZAhYWanOjA10xKsAF1XoRczZyAS4REd0fCwtJYv7EICisZEjOuoHNJ69KHYeIiIwcCwtJwsu5HV4d4QsAeH/raZRUVEmciIiIjBkLC0lm2vDu8O5oj6ISLZbvOi91HCIiMmIGFZbY2FgEBwdDqVRCqVQiJCQE27dvb9S+cXFxEAQBkyZNqnO7KIqYO3cu3N3dYWdnh9DQUJw/z19elkBhJceCXxfgfp2cjdP5GokTERGRsTKosHh6emLx4sVISUnBsWPHMHLkSERERCAjI+Oe+2VnZ+Ott97C0KFD77pv6dKl+Pjjj7Fy5UocPnwY9vb2CAsLQ0VFhWFHQiZpWI9OGPeAG3R6EXM2pkOv5wJcIiK6myA28yMazs7OWLZsGaZMmVLv/TqdDsOGDcMLL7yAffv2obi4GBs3bgRQM7vi4eGBN998E2+99RYAQK1Ww9XVFWvXrsWTTz7ZqAwajQYqlQpqtRpKpbI5h0MSyFffxqh/JaG8UodljwfjzwO8pI5ERERtwJDf301ew6LT6RAXF4eysjKEhIQ0OG7hwoVwcXGpt9BcunQJBQUFCA0Nrb1NpVJh0KBBSE5Obmo0MjHuKju8PsoPALB4+xmoy7kAl4iI6rIydIe0tDSEhISgoqICDg4O2LBhAwIDA+sdu3//fnzxxRdITU2t9/6CggIAgKura53bXV1da++rj1arhVarrf27RsO1D6buhSHeWJ+Sh/NFpVi28wwWTXpA6khERGREDJ5h8ff3R2pqKg4fPowZM2Zg8uTJyMzMvGtcSUkJnn32WaxevRodO3ZskbB3xMTEQKVS1W5eXnwLwdRZy2VYGNELAPCfwzk4lVcsbSAiIjIqzV7DEhoaCh8fH6xatarO7ampqejbty/kcnntbXq9HgAgk8lw9uxZCIIAHx8fnDhxAn369KkdN3z4cPTp0wcrVqyo92fWN8Pi5eXFNSxmYGbcCWxMvYrenir89PLDkMsEqSMREVEraZM1LHfo9fo65eGOgIAApKWlITU1tXabOHEiRowYgdTUVHh5ecHb2xtubm5ISEioE/7w4cP3XBejUChqP1p9ZyPz8I/xPeGosMLJPDXijuZIHYeIiIyEQWtYoqKiMHbsWHTp0gUlJSVYt24dEhMTER8fDwCIjIxE586dERMTA1tbW/Tq1avO/k5OTgBQ5/aZM2di0aJF8PPzg7e3N+bMmQMPD4+7rtdClsHF0RazxvTAgi2ZWLrjLMKD3NDBQSF1LCIikphBhaWoqAiRkZHIz8+HSqVCcHAw4uPjMXr0aABATk4OZDLDJm1mz56NsrIyTJs2DcXFxRgyZAh27NgBW1tbgx6HzMezD3XFD8fykJmvweLtZ7Dsz72ljkRERBJr9hoWY8DrsJiflMu38KfYgwCA9dNDMKCbs8SJiIiopbXpGhai1tC/a3v8ZYAnAOC9jemo1uklTkRERFJiYSGj9ffwAKjsrHGmoATfJF+WOg4REUmIhYWMVgcHBf4eHgAA+HDXORRp+P1SRESWioWFjNqTD3qht5cTSrXVeH/baanjEBGRRFhYyKjJZAIWRfSCIACbUq/i4MXrUkciIiIJsLCQ0XvAU4VnBnUFAMzdlIHKai7AJSKyNCwsZBLeGuOPDvY2uFBUii8PXJI6DhERtTEWFjIJqnbWiBrXEwCwYvd5XC2+LXEiIiJqSywsZDL+1K8zHuzWHrerdIj++e5vCCciIvPFwkImQxAERE/qBblMwPb0AiSduyZ1JCIiaiMsLGRSAtyUeG5wNwDAvE3pqKjSSRuIiIjaBAsLmZyZoX5wcVQg+0Y5/r03S+o4RETUBlhYyOQ42lrjvUcDAQCf7bmAnBvlEiciIqLWxsJCJmlCsDsG+3SAtlqP+VsyYAZfOk5ERPfAwkImSRAELIzoBWu5gF/OFGFXZqHUkYiIqBWxsJDJ8nVxwNSh3QEAC7Zk4nYlF+ASEZkrFhYyaX8b6YvOTna4Unwbn+45L3UcIiJqJSwsZNLa2Vhh7oSaBbj/3puFi9dKJU5EREStgYWFTN6YQFeM8O+EKp2IeZu4AJeIyByxsJDJEwQB8ycGwcZKhv0XrmNrWr7UkYiIqIWxsJBZ6NrBHi8/4gMAiP45E6XaaokTERFRS2JhIbMxfbgPunZoh0KNFit2n5M6DhERtSAWFjIbttZyzJ8YBAD48kA2zhaUSJyIiIhaCgsLmZUR/i4IC3KFTi9izqZ0LsAlIjITLCxkduZOCIKdtRxHLt3EhhNXpI5DREQtgIWFzE5nJzv8bZQvAOCf205DfbtK4kRERNRcLCxklqYO6Q6fTva4XlqJD3eelToOERE1EwsLmSUbKxmiI3oBAL49dBnpV9QSJyIiouZgYSGzNdi3Iyb09oBeBN7bmA69ngtwiYhMFQsLmbX3xveEg8IKqbnF+O+xXKnjEBFRE7GwkFlzVdpiZqgfAGDJjjO4WVYpcSIiImoKFhYye88N7oYAN0cUl1dh6Y4zUschIqImYGEhs2cllyF6Us0C3LijuTiec0viREREZCgWFrIID3ZzxuP9PQEAczamQ8cFuEREJoWFhSzGO2MDoLS1QsZVDb47dFnqOEREZAAWFrIYHR0UeDs8AADwwc6zuFailTgRERE1FgsLWZS/DuyCYE8VSiqqEbPttNRxiIiokQwqLLGxsQgODoZSqYRSqURISAi2b9/e4PiffvoJAwYMgJOTE+zt7dGnTx98++23dcY899xzEAShzhYeHt60oyG6D7lMQHRELwgC8NOJKzicdUPqSERE1AgGFRZPT08sXrwYKSkpOHbsGEaOHImIiAhkZGTUO97Z2RnvvvsukpOTcerUKTz//PN4/vnnER8fX2dceHg48vPza7fvv/++6UdEdB+9vZzw1MAuAIA5m9JRpdNLnIiIiO5HEEWxWR+XcHZ2xrJlyzBlypRGje/Xrx/Gjx+P6OhoADUzLMXFxdi4cWOTM2g0GqhUKqjVaiiVyiY/DlmO4vJKjPxXEm6WVeLdcT3x4rDuUkciIrI4hvz+bvIaFp1Oh7i4OJSVlSEkJOS+40VRREJCAs6ePYthw4bVuS8xMREuLi7w9/fHjBkzcOMGp+mpdTm1s8E7vy7A/Wj3ORSoKyRORERE92Jl6A5paWkICQlBRUUFHBwcsGHDBgQGBjY4Xq1Wo3PnztBqtZDL5fj8888xevTo2vvDw8Px2GOPwdvbGxcvXsQ//vEPjB07FsnJyZDL5fU+plarhVb72yc8NBqNoYdBhMf7eyLuaA6O5xQjemsmPvtrP6kjERFRAwx+S6iyshI5OTlQq9VYv3491qxZg6SkpAZLi16vR1ZWFkpLS5GQkIDo6Ghs3LgRjzzySL3js7Ky4OPjg927d2PUqFH1jpk/fz4WLFhw1+18S4gMlXFVjQmf7IdeBL6bMghD/DpKHYmIyGIY8pZQs9ewhIaGwsfHB6tWrWrU+KlTpyI3N/euhbe/16lTJyxatAgvvfRSvffXN8Pi5eXFwkJNMn9zBtYezEb3jvbYPnMoFFb1z+wREVHLapM1LHfo9fo65aG54/Py8nDjxg24u7s3OEahUNR+tPrORtRUs8b0QCdHBbKul2H13iyp4xARUT0MKixRUVHYu3cvsrOzkZaWhqioKCQmJuLpp58GAERGRiIqKqp2fExMDHbt2oWsrCycPn0a//rXv/Dtt9/imWeeAQCUlpbi7bffxqFDh5CdnY2EhARERETA19cXYWFhLXiYRA1T2lrj3XE9AQCf7rmA3JvlEiciIqI/MmjRbVFRESIjI5Gfnw+VSoXg4GDEx8fXLqLNycmBTPZbByorK8PLL7+MvLw82NnZISAgAN999x2eeOIJAIBcLsepU6fw9ddfo7i4GB4eHhgzZgyio6OhUCha8DCJ7i2ijwfijubgUNZNLNiSiTWTB0gdiYiIfqfZa1iMAa/DQi3hfGEJxq7Yh2q9iC8mD8Conq5SRyIiMmttuoaFyFz4uTpiylBvAMD8LRmoqNJJnIiIiO5gYSH6nddG+sFdZYvcm7fx+Z4LUschIqJfsbAQ/Y69wgpzH625ptDKpCxcul4mcSIiIgJYWIjuEt7LDcN6dEKlTo95mzNgBsu8iIhMHgsL0R8IgoAFE4NgI5dh77lr2JFeIHUkIiKLx8JCVA/vjvaYPrzmG5wX/pyJMm21xImIiCwbCwtRA14e4QsvZzvkqyvw8S/npY5DRGTRWFiIGmBrLcf8CUEAgC/2XcL5whKJExERWS4WFqJ7GNXTFaE9XVGtFzFnUzoX4BIRSYSFheg+5k0IhK21DIeybmLzyatSxyEiskgsLET34eXcDq+O8AUALNp6GpqKKokTERFZHhYWokZ4cVh3dO9oj2slWny485zUcYiILA4LC1EjKKzkWBBRswD3m+RsZFxVS5yIiMiysLAQNdJQv04Y/4A79CIwZ2M69HouwCUiaissLEQGeO/RnmhnI8fxnGKsT8mTOg4RkcVgYSEygLvKDm+E9gAALN5xBsXllRInIiKyDCwsRAZ67uFu6OHqgJtllVgaf1bqOEREFoGFhchA1nIZoiN6AQC+P5KDk7nF0gYiIrIALCxETTCoewc81rczRBF4b2M6dFyAS0TUqlhYiJooalxPONpaIe2KGuuO5Egdh4jIrLGwEDVRJ0cF3hrjDwBYtuMMrpdqJU5ERGS+WFiImuGZh7oiyEMJTUU1Fm8/I3UcIiKzxcJC1AxymYDoSTULcNen5OFY9k2JExERmScWFqJm6telPZ580AtAzQLcap1e4kREROaHhYWoBcwOD4BTO2ucKSjB18mXpY5DRGR2WFiIWoCzvQ3+Hh4AAFi+6xwKNRUSJyIiMi8sLEQt5IkBXujj5YRSbTUWbT0tdRwiIrPCwkLUQmQyAYsm9YJMALacvIoDF65LHYmIyGywsBC1oF6dVXjmoa4AgLmb0lFZzQW4REQtgYWFqIW9OcYfHR1scPFaGdbsz5I6DhGRWWBhIWphKjtrRI3tCQD4JOECrhTfljgREZHps5I6AJE5eqxfZ/z3aC6OZN/Ewi0ZWPXsAKkjkQmrqNJBfbsK6ttVKC6/89/KOrcV//pnnV6PpwZ2wfgH3CEIgtTRiVoMCwtRKxCEmivgjvt4H+IzCrHnbBFG+LtIHYskpNeLKKmoRvHtyrrF43YV1OWVdxUPdXlV7diKKsPWQh24cANbgq4iOqIXXJS2rXRERG1LEEVRlDpEc2k0GqhUKqjVaiiVSqnjENV6f2smVu+7hK4d2iF+5jDYWsuljkTN9MfZjj/OdNwpIcXlldDU/rkKmooqNOfVVibUvN3o1M4GKjvrX/9sDadf/6xqZwMnO2tkXS/FqqQsVOtFKG2tMOfRQDze35OzLWSUDPn9zcJC1IpKtdUY9a9EFGq0mBnqh5mhPaSORKh/tuO3mY3KP8x+3Plzze3aZn7yq52NvE7hUNlZw8nOBk7trKGsLSE2de5XtbOGg40VZLLGlY7T+RrMXn8KaVfUAIBhPToh5rEH0NnJrlnZiVoaCwuREfn51FW8uu4EbKxk2PXGMHTtYC91JLNxZ7bj9+s6im9X1cxs1L6lUn3XLEhLzHb8caajpnjUzHTc+XPt7b+WEZWdNRRWbTPLVq3TY83+S/hw1zlUVuthbyPHO2MD8PSgro0uPkStjYWFyIiIoohnvziC/ReuY4R/J3z53IOcnv+d3892GLKuo6VmO5zsGpjZ+N3sR3NmO6R28Vop/r7+FI5dvgUAGOjtjCV/CoZ3RxZnkl6rFZbY2FjExsYiOzsbABAUFIS5c+di7Nix9Y7/6aef8M9//hMXLlxAVVUV/Pz88Oabb+LZZ5+tHSOKIubNm4fVq1ejuLgYDz/8MGJjY+Hn59fYWCwsZPQuXitF+Ed7UaUTserZ/ggLcpM6Uov7/WzHnRmN+t5SuTPT0VKzHXKZUDujoWxgXYfqD7Mdql9LiI2VZVzZQa8X8e2hy1iy4wzKK3VQWMnw5pgemDKkO+QmUrzIPLVaYdmyZQvkcjn8/PwgiiK+/vprLFu2DCdOnEBQUNBd4xMTE3Hr1i0EBATAxsYGP//8M958801s3boVYWFhAIAlS5YgJiYGX3/9Nby9vTFnzhykpaUhMzMTtraNW93OwkKmYFn8GXy25yI6O9lh16xhaGdjfB/S0+lFlFTc/VHZP67rKC7/9W2XVpjtqHlLxap2XcedWY27Zjp+/bODwoozVo2Ue7McUT+lYf+vXxvR21OFpY/3hr+bo8TJyFK16VtCzs7OWLZsGaZMmdKo8f369cP48eMRHR0NURTh4eGBN998E2+99RYAQK1Ww9XVFWvXrsWTTz7ZqMdkYSFTcLtSh9APk3Cl+DZefsQHs3/9dufWUFGlu2tdR31vqfzx0y0tOduh+t26Dqd2NjWzH3fNdFjebIfURFHED8fyEL01EyUV1bCWC3h1hB9mPOLD/wfU5gz5/d3kf+LpdDr88MMPKCsrQ0hIyH3Hi6KIX375BWfPnsWSJUsAAJcuXUJBQQFCQ0Nrx6lUKgwaNAjJycmNLixEpsDORo55EwIx7dsUrN6Xhcf6ecLXxaHB8XdmO+r9qGwDsx13bm/ubIf9nU+y/PEtlYbWdXC2w2QIgoC/POiF4f6d8O6GdOw+XYjlu89he3o+lj3eGw94qqSOSFQvgwtLWloaQkJCUFFRAQcHB2zYsAGBgYENjler1ejcuTO0Wi3kcjk+//xzjB49GgBQUFAAAHB1da2zj6ura+199dFqtdBqtbV/12g0hh4GkSRGB7piZIALfjlThDf/l4ohfh3rne0oLq9Eiba62bMdv63lsP5d8WhotuO3T73wX9rmz1Vpi9WR/bHlVD7mb87AmYISTPr8AF4c2h0zQ/14zSAyOgYXFn9/f6SmpkKtVmP9+vWYPHkykpKSGiwtjo6OSE1NRWlpKRISEjBr1ix0794djzzySJNDx8TEYMGCBU3en0gqgiBg/oQgHLhwHSfz1DiZp77vPvY28npLhuoP1/D440dsOdtB9yMIAib29sDDPh2wYEsmNp+8ipVJF7EzowBLHg/Gg92cpY5IVKvZa1hCQ0Ph4+ODVatWNWr81KlTkZubi/j4eGRlZcHHxwcnTpxAnz59ascMHz4cffr0wYoVK+p9jPpmWLy8vLiGhUzGjvQC7MwoqL02R+1VS3+3rsOpnTWUtpztoLazK7MQ725IQ1GJFoIARD7UFbPDA2CvML4F4mQe2mQNyx16vb5OeTBkvLe3N9zc3JCQkFBbWDQaDQ4fPowZM2Y0+BgKhQIKhaJZuYmkFN7LDeG9zO+jzWTaRge6YqC3M97fmon/HcvD18mXkXCmCIsfC8YQv45SxyMLZ1BhiYqKwtixY9GlSxeUlJRg3bp1SExMRHx8PAAgMjISnTt3RkxMDICat24GDBgAHx8faLVabNu2Dd9++y1iY2MB1ExHzpw5E4sWLYKfn1/tx5o9PDwwadKklj1SIiK6L5WdNZY+3hsTenvgnR/TkHfrNp754jCeGOCFf4zvCZWdtdQRyUIZVFiKiooQGRmJ/Px8qFQqBAcHIz4+vnYRbU5ODmSy36avy8rK8PLLLyMvLw92dnYICAjAd999hyeeeKJ2zOzZs1FWVoZp06ahuLgYQ4YMwY4dOxp9DRYiImp5Q/06Yecbw7As/iy+Ts7Gf4/lIvFcERZNegCjA13v/wBELYyX5icions6mn0Tf19/ClnXywAAE3p7YP6EQHRw4Fvz1DyG/P7maj4iIrqnB7s5Y9vrQzF9uA9kArDl5FWMXr4Xm09ehRn8m5dMBAsLERHdl611zbc9b3zlYQS4OeJmWSVe+/4EXvwmBYWaCqnjkQVgYSEiokYL9nTC5leH4I3QHrCWC9h9uhChHybhf0dzOdtCrYqFhYiIDGJjJcProX74+W9D0dtThZKKasz+8RQivzyC3JvlUscjM8XCQkRETeLv5ogfZwzGP8YFQGElw77z1xH20V58fTAbej1nW6hlsbAQEVGTWcllmDbMBztmDsPAbs4or9Rh3uYMPPHvZGRdK5U6HpkRFhYiImo27472iJv2EKIjgmBvI8fR7FsIX7EPK5MuolrXvG8PJwJYWIiIqIXIZAKeDemG+DeGYViPTqis1mPx9jP4v88P4nS+Rup4ZOJYWIiIqEV5tm+Hr59/EMseD4bS1gppV9SY8Ml+LN91DpXVnG2hpmFhISKiFicIAv48wAu7Zw1HWJArqvUiViScx4RP9uNkbrHU8cgEsbAQEVGrcVHaYuUz/fHZX/uhg70NzhaW4P8+P4B/bjuNiiqd1PHIhLCwEBFRqxIEAeOD3bFr1nBM6uMBvQj8e28Wwj/ai8NZN6SORyaChYWIiNqEs70NPnqyL76YPABuSltk3yjHE/8+hDkb01GqrZY6Hhk5FhYiImpTo3q6YuesYXhqoBcA4NtDlxG2fC/2nrsmcTIyZiwsRETU5pS21oh5LBjrpg6Cl7MdrhTfRuSXR/DWDyehLq+SOh4ZIRYWIiKSzGDfjoifOQzPP9wNggCsT8lD6PIk7EgvkDoaGRkWFiIiklQ7GyvMmxCE9dND0L2TPa6VaDH9uxS8su44rpdqpY5HRoKFhYiIjEL/rs7Y9tpQvPyID+QyAVtP5WP0h0nYlHoFosgvU7R0LCxERGQ0bK3lmB0egE2vPIye7krcKq/C63GpmPr1MRSoK6SORxJiYSEiIqPTq7MKm199GG+N6QEbuQwJZ4ow+sMkfH8kh7MtFoqFhYiIjJK1XIZXR/ph62tD0MfLCSXaakT9lIZnvjiM3JvlUsejNsbCQkRERs3P1RE/zhiM98b3hK21DAcu3MCY5Xvx5f5L0Ok522IpWFiIiMjoyWUCpg7tjh2vD8ND3Z1xu0qHhT9n4i+rknGhqFTqeNQGWFiIiMhkdOtoj3VTH8L7/9cLDgorpFy+hXEf78Nney6gSqeXOh61IhYWIiIyKTKZgKcHdcXON4bhEf9OqKzWY1n8WUz67AAyrqqljkethIWFiIhMkoeTHb567kF8+JfeUNlZI+OqBhGfHsC/dp6FtlondTxqYSwsRERksgRBwGP9PLFr1jCM7eWGar2IT365gEc/3o8TObekjkctiIWFiIhMnoujLWKf6Y/Yp/uho4MNzheV4k+xB7Ho50zcruRsizlgYSEiIrMx9gF37HpjOB7r2xl6EViz/xLCV+zFoawbUkejZmJhISIis9Le3gYfPtEHXz33INxVtrh8oxxP/vsQ3t2QhpKKKqnjUROxsBARkVkaEeCCnW8Mw9ODugAA/nM4B2HL92LP2SKJk1FTsLAQEZHZcrS1xvv/9wC+f/EhdHFuh6vqCjz/1VHM+l8qissrpY5HBmBhISIisxfi0wE7Zg7FlCHeEATgp+NXEPrhXmxPy5c6GjUSCwsREVmEdjZWmPNoIH6cMRi+Lg64XqrFjP8cx8v/ScG1Eq3U8eg+WFiIiMii9OvSHltfG4K/jfSFlUzAtrQCjF6ehJ+O50EU+WWKxoqFhYiILI7CSo43x/hj06sPI8hDieLyKsz630m8sPYorhbfljoe1YOFhYiILFaQhwobX3kYb4f5w0Yuw56z1zBm+V785/Bl6PWcbTEmBhWW2NhYBAcHQ6lUQqlUIiQkBNu3b29w/OrVqzF06FC0b98e7du3R2hoKI4cOVJnzHPPPQdBEOps4eHhTTsaIiIiA1nLZXhlhC+2vT4E/bo4oVRbjXc3pOOvaw7h8o0yqePRrwwqLJ6enli8eDFSUlJw7NgxjBw5EhEREcjIyKh3fGJiIp566ins2bMHycnJ8PLywpgxY3DlypU648LDw5Gfn1+7ff/9900/IiIioibwdXHED9MHY+6jgbCzluNQ1k2EfbQXa/ZlQcfZFskJYjNXGDk7O2PZsmWYMmXKfcfqdDq0b98en376KSIjIwHUzLAUFxdj48aNTc6g0WigUqmgVquhVCqb/DhEREQAkHOjHO/8dAoHL9Zc0r9vFycs/VMw/FwdJU5mXgz5/d3kNSw6nQ5xcXEoKytDSEhIo/YpLy9HVVUVnJ2d69yemJgIFxcX+Pv7Y8aMGbhxg9/5QERE0unSoR3+M3UQYh57AI4KK5zIKcb4j/fj01/Oo0qnlzqeRTJ4hiUtLQ0hISGoqKiAg4MD1q1bh3HjxjVq35dffhnx8fHIyMiAra0tACAuLg7t2rWDt7c3Ll68iH/84x9wcHBAcnIy5HJ5vY+j1Wqh1f72mXmNRgMvLy/OsBARUYvLV9/GuxvS8cuZmkv6B7orsfTxYPTqrJI4mekzZIbF4MJSWVmJnJwcqNVqrF+/HmvWrEFSUhICAwPvud/ixYuxdOlSJCYmIjg4uMFxWVlZ8PHxwe7duzFq1Kh6x8yfPx8LFiy463YWFiIiag2iKGJT6lUs2JKBW+VVkMsETB/eHX8b6Qdb6/r/cU3316qF5Y9CQ0Ph4+ODVatWNTjmgw8+wKJFi7B7924MGDDgvo/ZqVMnLFq0CC+99FK993OGhYiIpHC9VIt5mzOw9VTNJf19Otlj6eO90b9re4mTmaY2WcNyh16vr1Me/mjp0qWIjo7Gjh07GlVW8vLycOPGDbi7uzc4RqFQ1H60+s5GRETU2jo6KPDZX/th5TP90clRgYvXyvD4yoNYuCUT5ZXVUsczawYVlqioKOzduxfZ2dlIS0tDVFQUEhMT8fTTTwMAIiMjERUVVTt+yZIlmDNnDr788kt069YNBQUFKCgoQGlpKQCgtLQUb7/9Ng4dOoTs7GwkJCQgIiICvr6+CAsLa8HDJCIiajnhvdyw+43heLy/J0QR+PLAJYR/tA8HL1yXOprZMqiwFBUVITIyEv7+/hg1ahSOHj2K+Ph4jB49GgCQk5OD/PzfvvkyNjYWlZWVePzxx+Hu7l67ffDBBwAAuVyOU6dOYeLEiejRowemTJmC/v37Y9++fVAoFC14mERERC1L1c4aH/y5N75+YSA6O9kh52Y5/rrmMKJ+OgVNRZXU8cxOs9ewGANeh4WIiKRUqq3Gku1n8O2hywAAN6Ut/vlYL4wMcJU4mXFr0zUsREREls5BYYXoSb3w32kPoVuHdijQVOCFtccwM+4EbpVVSh3PLLCwEBERtZBB3Ttg++vDMG1Yd8gEYGPqVYxenoStp/JhBm9oSIqFhYiIqAXZ2cjxj3E98dPLD6OHqwOul1bilXXHMf27FBRpKqSOZ7JYWIiIiFpBHy8nbPnbELw2yg9WMgHxGYUI/TAJ61PyONvSBCwsRERErURhJces0T2w5W9D8EBnFTQV1Xjrh5N47qujuFJ8W+p4JoWFhYiIqJX1dFdiw8uD8ffwANhYyZB07hrGfJiEbw9dhl7P2ZbGYGEhIiJqA1ZyGWY84oPtrw/FgK7tUVapw5yN6Xhy9SFcul4mdTyjx8JCRETUhnw6OeB/L4VgwcQgtLOR48ilmwj/aC9W782CjrMtDWJhISIiamMymYDJg7shfuYwDPHtCG21Hu9vO43HYg/iXGGJ1PGMEgsLERGRRLyc2+HbKQOx5E8PwNHWCidzizH+431Ysfs8Kqv1UsczKiwsREREEhIEAU882AW7Zw1HaE9XVOlELN99DhM/3Y+0PLXU8YwGCwsREZERcFXaYnVkf3z8VF8429vgTEEJJn1+AIu3n0FFlU7qeJJjYSEiIjISgiBgYm8P7HpjGCb09oBOL2Jl0kWM+3gfjmXflDqepFhYiIiIjEwHBwU+eaovVkcOgIujAlnXyvDnVcmYvzkDZdpqqeNJgoWFiIjISI0OdMWuWcPxlwGeEEVg7cFshH20F/vPX5c6WptjYSEiIjJiKjtrLH28N76dMhCdneyQd+s2nvniMP6+/hTUt6ukjtdmWFiIiIhMwFC/Ttj5xjA8N7gbAOC/x3IxZnkSdmcWShusjbCwEBERmQh7hRXmTwzCD9ND0L2jPQo1Wkz95hhe+/4EbpRqpY7XqlhYiIiITMyD3Zyx7fWhmD7cBzIB2HzyKkYv34stJ69CFM3z8v4sLERERCbI1lqOd8YGYOMrDyPAzRE3yyrxt+9PYNq3KSjUVEgdr8WxsBAREZmwYE8nbH51CN4I7QFruYBdmYUI/TAJ/zuaa1azLSwsREREJs7GSobXQ/3w89+GorenCiUV1Zj94ylEfnkEuTfLpY7XIlhYiIiIzIS/myN+nDEY/xgXAIWVDPvOX0fYR3vxTXI29HrTnm1hYSEiIjIjVnIZpg3zwY6ZwzCwmzPKK3WYuykDT/77ELKulUodr8lYWIiIiMyQd0d7xE17CNERQbC3keNI9k2MXbEPK5MuolqnlzqewVhYiIiIzJRMJuDZkG6If2MYhvp1hLZaj8Xbz+Cx2IM4U6CROp5BWFiIiIjMnGf7dvjmhYFY9ngwlLZWOJWnxoRP9mP5rnOorDaN2RYWFiIiIgsgCAL+PMALu2cNR1iQK6p0IlYknMfET/fjZG6x1PHui4WFiIjIgrgobbHymf747K/90MHeBmcKSvB/nx9AzLbTqKjSSR2vQSwsREREFkYQBIwPdseuWcMxqY8H9CKwam8Wxq7YhyOXbkodr14sLERERBbK2d4GHz3ZF19MHgA3pS0uXS/DX1YlY+6mdJRqq6WOVwcLCxERkYUb1dMVO2cNw1MDvQAA3yRfRtjyvdh77prEyX7DwkJERERQ2loj5rFg/GfqIHg52+FK8W1EfnkEb/9wEuryKqnjsbAQERHRbx727Yj4mcPw/MPdIAjADyl5CF2ehPiMAklzsbAQERFRHe1srDBvQhDWTw9B9072uFailXymxUqyn0xERERGrX9XZ2x7bSg+TjiP7p0coGpnLVkWFhYiIiJqkK21HLPDA6SOYdhbQrGxsQgODoZSqYRSqURISAi2b9/e4PjVq1dj6NChaN++Pdq3b4/Q0FAcOXKkzhhRFDF37ly4u7vDzs4OoaGhOH/+fNOOhoiIiMySQYXF09MTixcvRkpKCo4dO4aRI0ciIiICGRkZ9Y5PTEzEU089hT179iA5ORleXl4YM2YMrly5Ujtm6dKl+Pjjj7Fy5UocPnwY9vb2CAsLQ0VFRfOOjIiIiMyGIIqi2JwHcHZ2xrJlyzBlypT7jtXpdGjfvj0+/fRTREZGQhRFeHh44M0338Rbb70FAFCr1XB1dcXatWvx5JNPNiqDRqOBSqWCWq2GUqlszuEQERFRGzHk93eTPyWk0+kQFxeHsrIyhISENGqf8vJyVFVVwdnZGQBw6dIlFBQUIDQ0tHaMSqXCoEGDkJyc3ODjaLVaaDSaOhsRERGZL4MLS1paGhwcHKBQKDB9+nRs2LABgYGBjdr373//Ozw8PGoLSkFBzWe6XV1d64xzdXWtva8+MTExUKlUtZuXl5ehh0FEREQmxODC4u/vj9TUVBw+fBgzZszA5MmTkZmZed/9Fi9ejLi4OGzYsAG2trZNCntHVFQU1Gp17Zabm9usxyMiIiLjZvDHmm1sbODr6wsA6N+/P44ePYoVK1Zg1apVDe7zwQcfYPHixdi9ezeCg4Nrb3dzcwMAFBYWwt3dvfb2wsJC9OnTp8HHUygUUCgUhkYnIiIiE9XsK93q9XpotdoG71+6dCmio6OxY8cODBgwoM593t7ecHNzQ0JCQu1tGo0Ghw8fbvS6GCIiIjJ/Bs2wREVFYezYsejSpQtKSkqwbt06JCYmIj4+HgAQGRmJzp07IyYmBgCwZMkSzJ07F+vWrUO3bt1q16U4ODjAwcEBgiBg5syZWLRoEfz8/ODt7Y05c+bAw8MDkyZNatkjJSIiIpNlUGEpKipCZGQk8vPzoVKpEBwcjPj4eIwePRoAkJOTA5nst0mb2NhYVFZW4vHHH6/zOPPmzcP8+fMBALNnz0ZZWRmmTZuG4uJiDBkyBDt27Gj2OhciIiIyH82+Dosx4HVYiIiITE+bXIeFiIiIqK2wsBAREZHRM4tva77zrhaveEtERGQ67vzebszqFLMoLCUlJQDAK94SERGZoJKSEqhUqnuOMYtFt3q9HlevXoWjoyMEQWjRx9ZoNPDy8kJubi4X9N4Hz1Xj8Vw1Hs9V4/FcGYbnq/Fa61yJooiSkhJ4eHjU+ZRxfcxihkUmk8HT07NVf4ZSqeQTupF4rhqP56rxeK4aj+fKMDxfjdca5+p+Myt3cNEtERERGT0WFiIiIjJ6LCz3oVAoMG/ePH7ZYiPwXDUez1Xj8Vw1Hs+VYXi+Gs8YzpVZLLolIiIi88YZFiIiIjJ6LCxERERk9FhYiIiIyOixsBAREZHRY2EB8Nlnn6Fbt26wtbXFoEGDcOTIkXuO/+GHHxAQEABbW1s88MAD2LZtWxsllZ4h52rt2rUQBKHOZmtr24ZppbN3715MmDABHh4eEAQBGzduvO8+iYmJ6NevHxQKBXx9fbF27dpWz2kMDD1XiYmJdz2vBEFAQUFB2wSWUExMDB588EE4OjrCxcUFkyZNwtmzZ++7nyW+ZjXlXFnqa1ZsbCyCg4NrLwoXEhKC7du333MfKZ5TFl9Y/vvf/2LWrFmYN28ejh8/jt69eyMsLAxFRUX1jj948CCeeuopTJkyBSdOnMCkSZMwadIkpKent3HytmfouQJqroqYn59fu12+fLkNE0unrKwMvXv3xmeffdao8ZcuXcL48eMxYsQIpKamYubMmZg6dSri4+NbOan0DD1Xd5w9e7bOc8vFxaWVEhqPpKQkvPLKKzh06BB27dqFqqoqjBkzBmVlZQ3uY6mvWU05V4BlvmZ5enpi8eLFSElJwbFjxzBy5EhEREQgIyOj3vGSPadECzdw4EDxlVdeqf27TqcTPTw8xJiYmHrH/+UvfxHHjx9f57ZBgwaJL730UqvmNAaGnquvvvpKVKlUbZTOeAEQN2zYcM8xs2fPFoOCgurc9sQTT4hhYWGtmMz4NOZc7dmzRwQg3rp1q00yGbOioiIRgJiUlNTgGEt+zfq9xpwrvmb9pn379uKaNWvqvU+q55RFz7BUVlYiJSUFoaGhtbfJZDKEhoYiOTm53n2Sk5PrjAeAsLCwBsebi6acKwAoLS1F165d4eXldc/Gbuks9XnVHH369IG7uztGjx6NAwcOSB1HEmq1GgDg7Ozc4Bg+t2o05lwBfM3S6XSIi4tDWVkZQkJC6h0j1XPKogvL9evXodPp4OrqWud2V1fXBt8PLygoMGi8uWjKufL398eXX36JTZs24bvvvoNer8fgwYORl5fXFpFNSkPPK41Gg9u3b0uUyji5u7tj5cqV+PHHH/Hjjz/Cy8sLjzzyCI4fPy51tDal1+sxc+ZMPPzww+jVq1eD4yz1Nev3GnuuLPk1Ky0tDQ4ODlAoFJg+fTo2bNiAwMDAesdK9Zwyi29rJuMUEhJSp6EPHjwYPXv2xKpVqxAdHS1hMjJl/v7+8Pf3r/374MGDcfHiRSxfvhzffvuthMna1iuvvIL09HTs379f6ihGr7HnypJfs/z9/ZGamgq1Wo3169dj8uTJSEpKarC0SMGiZ1g6duwIuVyOwsLCOrcXFhbCzc2t3n3c3NwMGm8umnKu/sja2hp9+/bFhQsXWiOiSWvoeaVUKmFnZydRKtMxcOBAi3pevfrqq/j555+xZ88eeHp63nOspb5m3WHIufojS3rNsrGxga+vL/r374+YmBj07t0bK1asqHesVM8piy4sNjY26N+/PxISEmpv0+v1SEhIaPC9u5CQkDrjAWDXrl0NjjcXTTlXf6TT6ZCWlgZ3d/fWimmyLPV51VJSU1Mt4nkliiJeffVVbNiwAb/88gu8vb3vu4+lPreacq7+yJJfs/R6PbRabb33SfacatUlvSYgLi5OVCgU4tq1a8XMzExx2rRpopOTk1hQUCCKoig+++yz4jvvvFM7/sCBA6KVlZX4wQcfiKdPnxbnzZsnWltbi2lpaVIdQpsx9FwtWLBAjI+PFy9evCimpKSITz75pGhraytmZGRIdQhtpqSkRDxx4oR44sQJEYD44YcfiidOnBAvX74siqIovvPOO+Kzzz5bOz4rK0ts166d+Pbbb4unT58WP/vsM1Eul4s7duyQ6hDajKHnavny5eLGjRvF8+fPi2lpaeLrr78uymQycffu3VIdQpuZMWOGqFKpxMTERDE/P792Ky8vrx3D16waTTlXlvqa9c4774hJSUnipUuXxFOnTonvvPOOKAiCuHPnTlEUjec5ZfGFRRRF8ZNPPhG7dOki2tjYiAMHDhQPHTpUe9/w4cPFyZMn1xn/v//9T+zRo4doY2MjBgUFiVu3bm3jxNIx5FzNnDmzdqyrq6s4btw48fjx4xKkbnt3Pnr7x+3O+Zk8ebI4fPjwu/bp06ePaGNjI3bv3l386quv2jy3FAw9V0uWLBF9fHxEW1tb0dnZWXzkkUfEX375RZrwbay+8wSgznOFr1k1mnKuLPU164UXXhC7du0q2tjYiJ06dRJHjRpVW1ZE0XieU4IoimLrzuEQERERNY9Fr2EhIiIi08DCQkREREaPhYWIiIiMHgsLERERGT0WFiIiIjJ6LCxERERk9FhYiIiIyOixsBAREZHRY2EhIiIio8fCQkREREaPhYWIiIiMHgsLERERGb3/B+WnoqTMgin+AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Look at training performance\n",
    "api = wandb.Api()\n",
    "# Run is specified by <entity>/<project>/<run_id>\n",
    "run = api.run(f\"{run.entity}/{run.project}/{run.id}\")\n",
    "# Save the metrics for the run to a csv file\n",
    "metrics_dataframe = run.history()\n",
    "metrics_dataframe[\"train/loss\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3476d69b-0a69-427d-adcf-f0f45b4399c4",
   "metadata": {
    "collapsed": false,
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": 775,
     "hide_code": false,
     "hide_results": false,
     "language": "python"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Do some cleanup\n",
    "del model\n",
    "del pipe\n",
    "del trainer\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d6d4ae5c-3170-4eee-a185-de39c1992576",
   "metadata": {
    "collapsed": false,
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": null,
     "hide_code": false,
     "hide_results": false,
     "language": "markdown"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "scrolled": false
   },
   "source": [
    "The cell above saves your adapter to disk and wipes everything out. Now you can reload Llama 3.2 1B with fp16 precision, and merge it with the saved adapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "63def1ca-4d84-4317-a871-35dfeca76158",
   "metadata": {
    "collapsed": false,
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": 2936,
     "hide_code": false,
     "hide_results": false,
     "language": "python"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/notebooks/storage/.venv/lib64/python3.11/site-packages/peft/tuners/tuners_utils.py:543: UserWarning: Model with `tie_word_embeddings=True` and the tied_target_modules=['lm_head'] are part of the adapter. This can lead to complications, for example when merging the adapter or converting your model to formats other than safetensors. See for example https://github.com/huggingface/peft/issues/2018.\n",
      "  warnings.warn(\n",
      "/home/notebooks/storage/.venv/lib64/python3.11/site-packages/peft/tuners/tuners_utils.py:396: UserWarning: Model with `tie_word_embeddings=True` and the tied_target_modules=['lm_head'] are part of the adapter. This can lead to complications. You can opt to merge the adapter after cloning the weights (to untie the embeddings). You can untie the embeddings by loading the model with `tie_word_embeddings=False`. For example:\n",
      "```python\n",
      "from transformers import AutoModelForCausalLM\n",
      "\n",
      "# Load original tied model\n",
      "model = AutoModelForCausalLM.from_pretrained(\"google/gemma-2-2b-it\", tie_word_embeddings=False)\n",
      "\n",
      "# Set the randomly initialized lm_head to the previously tied embeddings\n",
      "model.lm_head.weight.data = model.model.embed_tokens.weight.data.clone()\n",
      "\n",
      "# Save the untied model\n",
      "untied_model_dir = \"dir/for/untied/model\"\n",
      "model.save_pretrained(untied_model_dir)\n",
      "model.config.save_pretrained(untied_model_dir)\n",
      "\n",
      "# Now use the original model but in untied format\n",
      "model = AutoModelForCausalLM.from_pretrained(untied_model_dir)\n",
      "```\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Reload model in FP16 and merge it with LoRA weights\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    low_cpu_mem_usage=True,\n",
    "    return_dict=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map={\"\": 0},\n",
    ")\n",
    "model = PeftModel.from_pretrained(model, adapter)\n",
    "model = model.merge_and_unload()\n",
    "\n",
    "# Reload tokenizer to save it\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a7f5d33e-f372-41ec-b6b9-8dca5dba51dc",
   "metadata": {
    "collapsed": false,
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": null,
     "hide_code": false,
     "hide_results": false,
     "language": "markdown"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "scrolled": false
   },
   "source": [
    "Now push the new model back to Huggingface and take note of the `repo_id`.  \n",
    "\n",
    "In this example, the user name is `tim-w` and the adapter variable used below is set to `llama-3.2-1b-dad-jokes` so the repo_id will be `tim-w/llama-3.2-1b-dad-jokes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a6b7c566-a45a-4867-aeed-486b9cf06a60",
   "metadata": {
    "collapsed": false,
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": 61609,
     "hide_code": false,
     "hide_results": false,
     "language": "python"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|█████████▉| 2.46G/2.47G [00:45<00:00, 69.3MB/s]\r\n",
      "model.safetensors: 100%|██████████| 2.47G/2.47G [00:45<00:00, 53.7MB/s]\n",
      "tokenizer.json:  93%|█████████▎| 16.0M/17.2M [00:00<00:00, 27.4MB/s]\r\n",
      "tokenizer.json: 100%|██████████| 17.2M/17.2M [00:00<00:00, 24.0MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/tim-w/llama-3.2-1b-dad-jokes/commit/8dd3f5e542003ef7c9707f8ad78f9eb5b57d99b1', commit_message='Upload tokenizer', commit_description='', oid='8dd3f5e542003ef7c9707f8ad78f9eb5b57d99b1', pr_url=None, repo_url=RepoUrl('https://huggingface.co/tim-w/llama-3.2-1b-dad-jokes', endpoint='https://huggingface.co', repo_type='model', repo_id='tim-w/llama-3.2-1b-dad-jokes'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub(adapter, use_temp_dir=False, token=os.environ[\"HUGGINGFACE_TOKEN\"])\n",
    "tokenizer.push_to_hub(adapter, use_temp_dir=False, token=os.environ[\"HUGGINGFACE_TOKEN\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "367f55a0-5f5a-4baf-bf01-694a886e776d",
   "metadata": {
    "collapsed": false,
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": null,
     "hide_code": false,
     "hide_results": false,
     "language": "markdown"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "scrolled": false
   },
   "source": [
    "## Bring the fine-tuned model to the Model Workshop \n",
    "\n",
    "Utilize DataRobot's custom model framework to take the fine-tuned LLM into DataRobot.\n",
    "\n",
    "Push the `./custom-model` folder to DataRobot. This contains assets DataRobot requires to host your LLM.\n",
    "\n",
    "* `engine_config.json` - The model location in HuggingFace.\n",
    "* `custom.py` - The boilerplate code called by DataRobot when getting the model ready for inference. Review it for more details.\n",
    "* `model-metadata.yaml` - The metadata for your model (i.e., the model name, expected runtime variables, etc.).\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5b285d09-cf0c-4797-8ccf-e1485df8839c",
   "metadata": {
    "collapsed": false,
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": null,
     "hide_code": false,
     "hide_results": false,
     "language": "markdown"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "scrolled": false
   },
   "source": [
    "You must only update the following cell and run it.  Make sure you replace `tim-w/llama-3.2-1b-dad-jokes` with your `repo-id`.  The purpose is to make sure it points at the model you uploaded to the Huggingface model hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dca3f50-34ce-45c2-b993-24203a2cec6b",
   "metadata": {
    "collapsed": false,
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": null,
     "hide_code": false,
     "hide_results": false,
     "language": "python"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%writefile ./custom-model/engine_config.json \n",
    "{\n",
    "  \"args\": [\n",
    "    \"--model\", \"tim-w/llama-3.2-1b-dad-jokes\"\n",
    "  ]\n",
    "}\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fc936451-eba2-4bc4-97d6-0e88742e39a3",
   "metadata": {
    "collapsed": false,
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": null,
     "hide_code": false,
     "hide_results": false,
     "language": "markdown"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "scrolled": false
   },
   "source": [
    "### Choose an environment\n",
    "\n",
    "Identify the environment suitable for your model. For this example, you can select a DataRobot environment that uses [vLLM](https://docs.vllm.ai/en/latest/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2f5f239a-63a1-439c-ab03-2c226b1452d4",
   "metadata": {
    "collapsed": false,
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": 354,
     "hide_code": false,
     "hide_results": false,
     "language": "python"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "name": "Pick your DataRobot Execution Environment",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExecutionEnvironment('[GenAI] vLLM Inference Server')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "environment = dr.ExecutionEnvironment.list(\"vLLM\").pop()\n",
    "environment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "95afc011-5953-4483-a95f-8d4f1b55c789",
   "metadata": {
    "collapsed": false,
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": null,
     "hide_code": false,
     "hide_results": false,
     "language": "markdown"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "scrolled": false
   },
   "source": [
    "Create a place for the custom model in DataRobot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "11d79bd3-94d5-4315-abc9-924dd3919e25",
   "metadata": {
    "collapsed": false,
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": 309,
     "hide_code": false,
     "hide_results": false,
     "language": "python"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "name": "Create Custom DataRobot Inference Model in the DataRobot workshop",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cim = dr.CustomInferenceModel.create(\n",
    "    name=\"Llama-3.2 1b Dad Jokes\",\n",
    "    target_type=dr.enums.TARGET_TYPE.TEXT_GENERATION,\n",
    "    target_name=\"resultText\",\n",
    "    network_egress_policy=dr.enums.NETWORK_EGRESS_POLICY.PUBLIC,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "15b034ce-a745-4a62-b46f-581bd3658bdf",
   "metadata": {
    "collapsed": false,
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": 1568,
     "hide_code": false,
     "hide_results": false,
     "language": "python"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "name": "Add a verson to our Custom DataRobot Inference Model",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cimv = dr.CustomModelVersion.create_clean(\n",
    "    custom_model_id=cim.id,\n",
    "    base_environment_id=environment.id,\n",
    "    folder_path=\"./custom-model\",\n",
    "    max_wait=1200,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1f84bd55-3e05-4f7e-bef1-eda710cf57c5",
   "metadata": {
    "collapsed": false,
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": null,
     "hide_code": false,
     "hide_results": false,
     "language": "markdown"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "scrolled": false
   },
   "source": [
    "In the next cell, patch the custom model version so that it is using GPUs instead of only CPUs. This is not availabe in the DataRobot Python client, which is why there is a requirement to patch the version via REST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4367b854-2722-4b6a-b05d-d152ed5da685",
   "metadata": {
    "collapsed": false,
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": 1401,
     "hide_code": false,
     "hide_results": false,
     "language": "python"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [201]>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.patch(\n",
    "    f\"customModels/{cim.id}/versions/\",\n",
    "    data={\n",
    "        \"isMajorUpdate\": \"false\",\n",
    "        \"baseEnvironmentId\": environment.id,\n",
    "        \"replicas\": 1,\n",
    "        \"networkEgressPolicy\": \"PUBLIC\",\n",
    "        \"resourceBundleId\": \"DRAWS_g4dn.xlarge_frac1_regular\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9bc4058b-33a8-4230-bfbe-a6b83d6cef38",
   "metadata": {
    "collapsed": false,
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": 1002,
     "hide_code": false,
     "hide_results": false,
     "language": "python"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## since we just ran the patch, the version of the model has been bumped, so we'll use the following to grab the latest version.\n",
    "cim.update()\n",
    "cimv = cim.latest_version"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e92bcb7e-fac6-4466-a1e0-27b2aad97948",
   "metadata": {
    "collapsed": false,
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": null,
     "hide_code": false,
     "hide_results": false,
     "language": "markdown"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "scrolled": false
   },
   "source": [
    "The following cell tests the model in DataRobot to make sure DataRobot can effectively make predictions. Allow time for this to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5bcd26e7-df8d-47c9-9929-0cc80955f0d7",
   "metadata": {
    "collapsed": false,
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": 100407,
     "hide_code": false,
     "hide_results": false,
     "language": "python"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dict(promptText=prompts))\n",
    "llm_dataset_test = dr.Dataset.create_from_in_memory_data(data_frame=df)\n",
    "custom_model_test = dr.CustomModelTest.create(\n",
    "    cim.id,\n",
    "    cimv.id,\n",
    "    dataset_id=llm_dataset_test.id,\n",
    "    network_egress_policy=dr.enums.NETWORK_EGRESS_POLICY.PUBLIC,\n",
    "    max_wait=1200,\n",
    ")\n",
    "print(custom_model_test.overall_status)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "26395988-e891-4f74-a066-4268fb069ff3",
   "metadata": {
    "collapsed": false,
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": null,
     "hide_code": false,
     "hide_results": false,
     "language": "markdown"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "scrolled": false
   },
   "source": [
    "## Register the model in DataRobot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "90a7f193-195c-49d1-a174-da8eba8a991f",
   "metadata": {
    "collapsed": false,
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": 2429,
     "hide_code": false,
     "hide_results": false,
     "language": "python"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## register the custom model version in the dr model registry\n",
    "registered_model_version = dr.RegisteredModelVersion.create_for_custom_model_version(\n",
    "    custom_model_version_id=cimv.id,\n",
    "    name=\"llama 3.2 1b dad jokes v1\",\n",
    "    registered_model_name=\"llama 3.2 1b dad jokes\",\n",
    "    description=\"llama 3.2 1b fine tuned on a bunch of dad jokes\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4760da85-ce00-4943-99bf-de3e6e9f41a5",
   "metadata": {
    "collapsed": false,
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": null,
     "hide_code": false,
     "hide_results": false,
     "language": "markdown"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "scrolled": false
   },
   "source": [
    "A prediction enviornment corresponds to where the model lives in DataRobot. This example hosts the model in DataRobot in a serverless prediction environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "885be9d0-d9a4-49fe-85bc-d55abc3b7be5",
   "metadata": {
    "collapsed": false,
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": 221,
     "hide_code": false,
     "hide_results": false,
     "language": "python"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictionEnvironment('66a929580c3e174abc7542cb', 'DataRobot Serverless', 'datarobotServerless', '')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datarobot as dr\n",
    "\n",
    "client = dr.Client()\n",
    "# prediction_environment = [ pe for pe in dr.PredictionEnvironment.list() if pe.name == \"DataRobot Serverless\"]\n",
    "## this prediction environment id below is specific to your datarobot account.  the one provided below will not work for you\n",
    "prediction_environment = dr.PredictionEnvironment.get(\"66a929580c3e174abc7542cb\")\n",
    "prediction_environment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b090fab8-5f6b-4b27-a4d4-94ab3daca7b8",
   "metadata": {
    "collapsed": false,
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": null,
     "hide_code": false,
     "hide_results": false,
     "language": "markdown"
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "scrolled": false
   },
   "source": [
    "## Deploy the model in DataRobot \n",
    "\n",
    "Use the following cell to deploy the model in DataRobot. Allow time for the deployment process to complete. You might experience a timeout error. Navigate to the [DataRobot Console](https://app.datarobot.com/console-nextgen/). Select your model, and retrieve the `Deployment ID` in the overview.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a3897d0",
   "metadata": {
    "collapsed": false,
    "datarobot": {
     "disable_run": false,
     "execution_time_millis": 608176,
     "hide_code": false,
     "hide_results": false,
     "language": "python"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "scrolled": "auto"
   },
   "outputs": [],
   "source": [
    "deployment = dr.Deployment.create_from_registered_model_version(\n",
    "    registered_model_version.id,\n",
    "    prediction_environment_id=prediction_environment.id,\n",
    "    label=\"llama 3.2 1b dad jokes\",\n",
    "    max_wait=3600,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "276818cc-4e8d-4c87-9374-bd95a420d9b7",
   "metadata": {
    "collapsed": false,
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": 679,
     "hide_code": false,
     "hide_results": false,
     "language": "python"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "deployment = dr.Deployment.get(\"67a26ec947b2d87607acd517\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b3a4cd",
   "metadata": {
    "collapsed": false,
    "datarobot": {
     "disable_run": false,
     "hide_code": false,
     "hide_results": false,
     "language": "markdown"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "scrolled": "auto"
   },
   "source": [
    "Make predictions with the original test prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e498a632-1487-4373-870a-df114533732c",
   "metadata": {
    "collapsed": false,
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": 4211,
     "hide_code": false,
     "hide_results": false,
     "language": "python"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': [{'deploymentApprovalStatus': 'APPROVED',\n",
      "           'prediction': \"I think you're going to chuckle at that one.  They \"\n",
      "                         'stomach.  The moooos',\n",
      "           'predictionValues': [{'label': 'resultText',\n",
      "                                 'value': \"I think you're going to chuckle at \"\n",
      "                                          'that one.  They stomach.  The '\n",
      "                                          'moooos'}],\n",
      "           'rowId': 0},\n",
      "          {'deploymentApprovalStatus': 'APPROVED',\n",
      "           'prediction': 'I can’t assist with that.  Is there anything else.',\n",
      "           'predictionValues': [{'label': 'resultText',\n",
      "                                 'value': 'I can’t assist with that.  Is there '\n",
      "                                          'anything else.'}],\n",
      "           'rowId': 1},\n",
      "          {'deploymentApprovalStatus': 'APPROVED',\n",
      "           'prediction': 'Why did Mr Potato Head get pulled over.  He had a '\n",
      "                         'few spuds floating around in his ears.',\n",
      "           'predictionValues': [{'label': 'resultText',\n",
      "                                 'value': 'Why did Mr Potato Head get pulled '\n",
      "                                          'over.  He had a few spuds floating '\n",
      "                                          'around in his ears.'}],\n",
      "           'rowId': 2},\n",
      "          {'deploymentApprovalStatus': 'APPROVED',\n",
      "           'prediction': \"A pirate's language of choice.  It's Fin clic.  \"\n",
      "                         '*sining sound',\n",
      "           'predictionValues': [{'label': 'resultText',\n",
      "                                 'value': \"A pirate's language of choice.  \"\n",
      "                                          \"It's Fin clic.  *sining sound\"}],\n",
      "           'rowId': 3},\n",
      "          {'deploymentApprovalStatus': 'APPROVED',\n",
      "           'prediction': 'A man walked into a bar with a slab of asphalt under '\n",
      "                         'his arm and belonging to a horse named Betsy.',\n",
      "           'predictionValues': [{'label': 'resultText',\n",
      "                                 'value': 'A man walked into a bar with a slab '\n",
      "                                          'of asphalt under his arm and '\n",
      "                                          'belonging to a horse named Betsy.'}],\n",
      "           'rowId': 4}]}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import pprint\n",
    "\n",
    "import datarobot as dr\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# deployment = dr.Deployment.get(\"673505fb8a477d1f2fbaed3b\")\n",
    "URL = f\"https://app.datarobot.com/api/v2/deployments/{deployment.id}/predictions\"\n",
    "headers = {\n",
    "    \"Content-Type\": \"text/plain; charset=UTF-8\",\n",
    "    \"Authorization\": \"Bearer {}\".format(os.environ[\"DATAROBOT_API_TOKEN\"]),\n",
    "}\n",
    "df = pd.DataFrame(dict(promptText=prompts))\n",
    "response = requests.post(URL, headers=headers, data=df.to_csv(index=False))\n",
    "pprint.pprint(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cfdaf6",
   "metadata": {
    "collapsed": false,
    "datarobot": {
     "disable_run": false,
     "hide_code": false,
     "hide_results": false,
     "language": "markdown"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "scrolled": "auto"
   },
   "source": [
    "## Add the model to a DataRobot Playground\n",
    "\n",
    "A playground in DataRobot is a space for creating and interacting with LLM blueprints. LLM blueprints represent the full context for what is needed to generate a response from an LLM, captured in the LLM blueprint settings. Within the playground you compare LLM blueprint responses to determine which blueprint to use in production for solving a business problem.\n",
    "\n",
    "In this section you will:\n",
    "* Create a Playground in the default Use Case (the Use Case to which this codespace belongs).\n",
    "* Create an LLM Blueprint in the Playground that uses the fine-tuned Llama 3.2 1B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2de7de4f",
   "metadata": {
    "collapsed": false,
    "datarobot": {
     "disable_run": false,
     "execution_time_millis": 424,
     "hide_code": false,
     "hide_results": false,
     "language": "python"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "scrolled": "auto"
   },
   "outputs": [],
   "source": [
    "## Create a Use Case\n",
    "\n",
    "use_case = dr.UseCase.get(os.environ[\"DATAROBOT_DEFAULT_USE_CASE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2fa7e153-6660-48b9-8784-5afe9e9635d4",
   "metadata": {
    "collapsed": false,
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": 5,
     "hide_code": false,
     "hide_results": false,
     "language": "python"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UseCase(id=67a25401df6cc07065bd5181, name=Finetuning V3, description=None, models=0, projects=0, datasets=1, notebooks=1, applications=0)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e3a1ac8a",
   "metadata": {
    "datarobot": {
     "execution_time_millis": 644
    }
   },
   "outputs": [],
   "source": [
    "## Create a playground in the Use Case\n",
    "playground = dr.models.genai.playground.Playground.create(name=\"playground\", use_case=use_case.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eb3f21eb-73d6-4381-8e7d-71cf98b617cb",
   "metadata": {
    "collapsed": false,
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": 11469,
     "hide_code": false,
     "hide_results": false,
     "language": "python"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Create the blueprint\n",
    "## First you need to make sure your LLM will work with the blueprint framework\n",
    "custom_model_llm_validation = dr.genai.CustomModelLLMValidation.create(\n",
    "    prompt_column_name=\"promptText\",\n",
    "    target_column_name=\"resultText\",\n",
    "    deployment_id=deployment.id,\n",
    "    wait_for_completion=True,\n",
    "    name=deployment.__str__(),\n",
    "    use_case=use_case.id,\n",
    ")\n",
    "\n",
    "assert custom_model_llm_validation.validation_status == \"PASSED\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258b0ba6-5253-44b8-a5d7-6b55e1e2aa0f",
   "metadata": {
    "collapsed": false,
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": 537,
     "hide_code": false,
     "hide_results": false,
     "language": "python"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Create the Llama dad joke blueprint\n",
    "llm_settings = {\n",
    "    # \"system_prompt\": \"some instruction\"\n",
    "    \"validation_id\": custom_model_llm_validation.id\n",
    "}\n",
    "\n",
    "llm_blueprint = dr.models.genai.llm_blueprint.LLMBlueprint.create(\n",
    "    playground=playground.id, name=\"Llama Dad Jokes\", llm=\"custom-model\", llm_settings=llm_settings\n",
    ")\n",
    "\n",
    "## Create a blueprint for gpt4o\n",
    "gpt4_llm_blueprint = dr.models.genai.llm_blueprint.LLMBlueprint.create(\n",
    "    playground=playground.id,\n",
    "    name=\"gpt4o mini\",\n",
    "    llm=\"azure-openai-gpt-4-o-mini\",\n",
    "    llm_settings={\"system_prompt\": \"some instruction\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cdf5ba8-ead8-4596-bc01-27e86e2e7cc5",
   "metadata": {
    "collapsed": false,
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": 425,
     "hide_code": false,
     "hide_results": false,
     "language": "python"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What do you call a fake noodle.  An impasta\n",
      "=====\n",
      "Why don't skeletons fight each other? \n",
      "\n",
      "They don't have the guts!\n"
     ]
    }
   ],
   "source": [
    "prompt = dr.models.genai.ChatPrompt.create(\"tell me a joke\", llm_blueprint.id)\n",
    "time.sleep(2)\n",
    "prompt.update()\n",
    "print(dr.models.genai.ChatPrompt.get(prompt.id).result_text)\n",
    "print(\"=====\")\n",
    "prompt = dr.models.genai.ChatPrompt.create(\"tell me a joke\", gpt4_llm_blueprint.id)\n",
    "time.sleep(2)\n",
    "prompt.update()\n",
    "print(dr.models.genai.ChatPrompt.get(prompt.id).result_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec482610-5835-4240-b6a4-a3eb14f7b635",
   "metadata": {
    "collapsed": false,
    "datarobot": {
     "chart_settings": null,
     "custom_llm_metric_settings": null,
     "custom_metric_settings": null,
     "dataframe_view_options": null,
     "disable_run": false,
     "execution_time_millis": 3297,
     "hide_code": false,
     "hide_results": false,
     "language": "python"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Because he was spud-tacularly driving.\n",
      "=====\n",
      "Because he was driving with his eyes too close together!\n"
     ]
    }
   ],
   "source": [
    "setup = \"Why did mr potato head get pulled over?\"\n",
    "prompt = dr.models.genai.ChatPrompt.create(setup, llm_blueprint.id)\n",
    "time.sleep(2)\n",
    "prompt.update()\n",
    "print(dr.models.genai.ChatPrompt.get(prompt.id).result_text)\n",
    "print(\"=====\")\n",
    "prompt = dr.models.genai.ChatPrompt.create(setup, gpt4_llm_blueprint.id)\n",
    "time.sleep(2)\n",
    "prompt.update()\n",
    "print(dr.models.genai.ChatPrompt.get(prompt.id).result_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

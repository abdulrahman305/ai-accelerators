{
 "cells": [
  {
   "id": "65cb46f4cb56e661b7bc47d3",
   "cell_type": "code",
   "source": [
    "!pip install \"langchain==0.1.0\" \\\n",
    "             \"faiss-cpu==1.7.4\" \\\n",
    "             \"sentence-transformers==2.2.2\" \\\n",
    "             \"unstructured==0.8.4\" \\\n",
    "             \"openai==0.27.8\" \\\n",
    "             \"datarobotx\" \\\n",
    "             \"pydantic\""
   ],
   "metadata": {
    "name": "First cell",
    "collapsed": true,
    "scrolled": "auto",
    "datarobot": {
     "language": "python"
    },
    "hide_code": false,
    "hide_results": false,
    "disable_run": false,
    "chart_settings": null,
    "custom_metric_settings": null,
    "custom_llm_metric_settings": null,
    "dataframe_view_options": null
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 1,
     "data": {
      "text/plain": "Collecting langchain==0.1.0\n  Downloading langchain-0.1.0-py3-none-any.whl (797 kB)\n\r\u001b[K     |████████████████████████████████| 797 kB 13.9 MB/s \n\u001b[?25hCollecting faiss-cpu==1.7.4\n  Downloading faiss_cpu-1.7.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n\r\u001b[K     |████████████████████████████████| 17.6 MB 47.2 MB/s \n\u001b[?25hCollecting sentence-transformers==2.2.2\n  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n\r\u001b[K     |████████████████████████████████| 85 kB 51.5 MB/s \n\u001b[?25hCollecting unstructured==0.8.4\n  Downloading unstructured-0.8.4-py3-none-any.whl (1.4 MB)\n\r\u001b[K     |████████████████████████████████| 1.4 MB 62.4 MB/s \n\u001b[?25hCollecting openai==0.27.8\n  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n\r\u001b[K     |████████████████████████████████| 73 kB 45.5 MB/s \n\u001b[?25hCollecting datarobotx\n  Downloading datarobotx-0.1.21-py3-none-any.whl (179 kB)\n\r\u001b[K     |████████████████████████████████| 179 kB 65.0 MB/s \n\u001b[?25hRequirement already satisfied: pydantic in /etc/system/kernel/.venv/lib/python3.9/site-packages (2.5.2)\nRequirement already satisfied: PyYAML>=5.3 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from langchain==0.1.0) (6.0.1)\nRequirement already satisfied: numpy<2,>=1 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from langchain==0.1.0) (1.23.3)\nCollecting dataclasses-json<0.7,>=0.5.7\n  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\nCollecting langchain-community<0.1,>=0.0.9\n  Downloading langchain_community-0.0.20-py3-none-any.whl (1.7 MB)\n\r\u001b[K     |████████████████████████████████| 1.7 MB 58.8 MB/s \n\u001b[?25h"
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "execution_count": 1,
     "data": {
      "text/plain": "Collecting jsonpatch<2.0,>=1.33\n  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\nRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from langchain==0.1.0) (8.2.3)\nCollecting langsmith<0.1.0,>=0.0.77\n  Downloading langsmith-0.0.92-py3-none-any.whl (56 kB)\n\r\u001b[K     |████████████████████████████████| 56 kB 54.6 MB/s \n\u001b[?25hCollecting langchain-core<0.2,>=0.1.7\n  Downloading langchain_core-0.1.23-py3-none-any.whl (241 kB)\n\r\u001b[K     |████████████████████████████████| 241 kB 59.6 MB/s \n\u001b[?25hCollecting SQLAlchemy<3,>=1.4\n  Downloading SQLAlchemy-2.0.27-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n\r\u001b[K     |████████████████████████████████| 3.1 MB 59.8 MB/s \n\u001b[?25hRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from langchain==0.1.0) (3.9.3)\nRequirement already satisfied: async-timeout<5.0.0,>=4.0.0; python_version < \"3.11\" in /etc/system/kernel/.venv/lib/python3.9/site-packages (from langchain==0.1.0) (4.0.3)\nRequirement already satisfied: requests<3,>=2 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from langchain==0.1.0) (2.31.0)\nCollecting transformers<5.0.0,>=4.6.0\n  Downloading transformers-4.37.2-py3-none-any.whl (8.4 MB)\n\r\u001b[K     |████████████████████████████████| 8.4 MB 50.5 MB/s \n\u001b[?25h"
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "execution_count": 1,
     "data": {
      "text/plain": "Requirement already satisfied: tqdm in /etc/system/kernel/.venv/lib/python3.9/site-packages (from sentence-transformers==2.2.2) (4.64.1)\nCollecting torch>=1.6.0\n  Downloading torch-2.2.0-cp39-cp39-manylinux1_x86_64.whl (755.5 MB)\n\r\u001b[K     |█████████▋                      | 228.2 MB 70.9 MB/s eta 0:00:08"
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "execution_count": 1,
     "data": {
      "text/plain": "\r\u001b[K     |█████████████████████           | 495.9 MB 80.0 MB/s eta 0:00:04"
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "execution_count": 1,
     "data": {
      "text/plain": "\r\u001b[K     |███████████████████████████████▊| 749.2 MB 71.3 MB/s eta 0:00:01"
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "execution_count": 1,
     "data": {
      "text/plain": "\r\u001b[K     |████████████████████████████████| 755.5 MB 71.3 MB/s \n\u001b[?25hCollecting torchvision\n  Downloading torchvision-0.17.0-cp39-cp39-manylinux1_x86_64.whl (6.9 MB)\n\r\u001b[K     |████████████████████████████████| 6.9 MB 57.4 MB/s \n\u001b[?25hRequirement already satisfied: scikit-learn in /etc/system/kernel/.venv/lib/python3.9/site-packages (from sentence-transformers==2.2.2) (1.3.2)\nRequirement already satisfied: scipy in /etc/system/kernel/.venv/lib/python3.9/site-packages (from sentence-transformers==2.2.2) (1.10.1)\nCollecting nltk\n  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n\r\u001b[K     |████████████████████████████████| 1.5 MB 55.7 MB/s \n\u001b[?25hCollecting sentencepiece\n  Downloading sentencepiece-0.1.99-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n\r\u001b[K     |████████████████████████████████| 1.3 MB 53.7 MB/s \n\u001b[?25hCollecting huggingface-hub>=0.4.0\n  Downloading huggingface_hub-0.20.3-py3-none-any.whl (330 kB)\n\r\u001b[K     |████████████████████████████████| 330 kB 60.0 MB/s \n\u001b[?25hCollecting filetype\n  Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\nCollecting msg-parser\n  Downloading msg_parser-1.2.0-py2.py3-none-any.whl (101 kB)\n\r\u001b[K     |████████████████████████████████| 101 kB 54.5 MB/s \n\u001b[?25h"
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "execution_count": 1,
     "data": {
      "text/plain": "Collecting python-docx\n  Downloading python_docx-1.1.0-py3-none-any.whl (239 kB)\n\r\u001b[K     |████████████████████████████████| 239 kB 55.6 MB/s \n\u001b[?25hCollecting lxml\n  Downloading lxml-5.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.0 MB)\n\r\u001b[K     |████████████████████████████████| 8.0 MB 51.6 MB/s \n\u001b[?25hCollecting pdf2image\n  Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\nRequirement already satisfied: pandas in /etc/system/kernel/.venv/lib/python3.9/site-packages (from unstructured==0.8.4) (1.5.1)\nRequirement already satisfied: tabulate in /etc/system/kernel/.venv/lib/python3.9/site-packages (from unstructured==0.8.4) (0.9.0)\nCollecting python-pptx\n  Downloading python_pptx-0.6.23-py3-none-any.whl (471 kB)\n\r\u001b[K     |████████████████████████████████| 471 kB 57.5 MB/s \n\u001b[?25hCollecting xlrd\n  Downloading xlrd-2.0.1-py2.py3-none-any.whl (96 kB)\n\r\u001b[K     |████████████████████████████████| 96 kB 57.6 MB/s \n\u001b[?25hCollecting chardet\n  Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\n\r\u001b[K     |████████████████████████████████| 199 kB 63.5 MB/s \n\u001b[?25hCollecting pypandoc\n  Downloading pypandoc-1.12-py3-none-any.whl (20 kB)\nCollecting python-magic\n  Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\nCollecting pdfminer.six\n  Downloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n\r\u001b[K     |████████████████████████████████| 5.6 MB 56.2 MB/s \n\u001b[?25hCollecting markdown\n  Downloading Markdown-3.5.2-py3-none-any.whl (103 kB)\n\r\u001b[K     |████████████████████████████████| 103 kB 57.8 MB/s \n\u001b[?25hRequirement already satisfied: pillow in /etc/system/kernel/.venv/lib/python3.9/site-packages (from unstructured==0.8.4) (10.2.0)\nRequirement already satisfied: openpyxl in /etc/system/kernel/.venv/lib/python3.9/site-packages (from unstructured==0.8.4) (3.0.10)\nRequirement already satisfied: setuptools in /etc/system/kernel/.venv/lib/python3.9/site-packages (from datarobotx) (68.2.2)\nRequirement already satisfied: termcolor in /etc/system/kernel/.venv/lib/python3.9/site-packages (from datarobotx) (2.4.0)\nRequirement already satisfied: urllib3<2.0.0 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from datarobotx) (1.26.18)\n"
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "execution_count": 1,
     "data": {
      "text/plain": "Collecting ipywidgets\n  Downloading ipywidgets-8.1.2-py3-none-any.whl (139 kB)\n\r\u001b[K     |████████████████████████████████| 139 kB 58.2 MB/s \n\u001b[?25hCollecting names-generator\n  Downloading names_generator-0.1.0-py3-none-any.whl (26 kB)\nRequirement already satisfied: IPython in /etc/system/kernel/.venv/lib/python3.9/site-packages (from datarobotx) (8.18.1)\nRequirement already satisfied: altair<5.0.0 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from datarobotx) (4.2.0)\nRequirement already satisfied: cloudpickle==2.2.1 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from datarobotx) (2.2.1)\nRequirement already satisfied: datarobot>=3.2.0 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from datarobotx) (3.3.0)\nRequirement already satisfied: annotated-types>=0.4.0 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from pydantic) (0.6.0)\nRequirement already satisfied: typing-extensions>=4.6.1 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from pydantic) (4.9.0)\nRequirement already satisfied: pydantic-core==2.14.5 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from pydantic) (2.14.5)\nCollecting typing-inspect<1,>=0.4.0\n  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\nCollecting marshmallow<4.0.0,>=3.18.0\n  Downloading marshmallow-3.20.2-py3-none-any.whl (49 kB)\n\r\u001b[K     |████████████████████████████████| 49 kB 45.5 MB/s \n\u001b[?25hCollecting jsonpointer>=1.9\n  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\nRequirement already satisfied: packaging<24.0,>=23.2 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from langchain-core<0.2,>=0.1.7->langchain==0.1.0) (23.2)\nRequirement already satisfied: anyio<5,>=3 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from langchain-core<0.2,>=0.1.7->langchain==0.1.0) (3.7.1)\nCollecting greenlet!=0.4.17; platform_machine == \"aarch64\" or (platform_machine == \"ppc64le\" or (platform_machine == \"x86_64\" or (platform_machine == \"amd64\" or (platform_machine == \"AMD64\" or (platform_machine == \"win32\" or platform_machine == \"WIN32\")))))\n  Downloading greenlet-3.0.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (660 kB)\n\r\u001b[K     |████████████████████████████████| 660 kB 58.2 MB/s \n\u001b[?25hRequirement already satisfied: yarl<2.0,>=1.0 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.0) (1.9.4)\nRequirement already satisfied: frozenlist>=1.1.1 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.0) (1.4.1)\nRequirement already satisfied: attrs>=17.3.0 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.0) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.0) (6.0.5)\nRequirement already satisfied: aiosignal>=1.1.2 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.0) (1.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from requests<3,>=2->langchain==0.1.0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from requests<3,>=2->langchain==0.1.0) (3.6)\nRequirement already satisfied: certifi>=2017.4.17 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from requests<3,>=2->langchain==0.1.0) (2024.2.2)\n"
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "execution_count": 1,
     "data": {
      "text/plain": "Collecting regex!=2019.12.17\n  Downloading regex-2023.12.25-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n\r\u001b[K     |████████████████████████████████| 773 kB 59.4 MB/s \n\u001b[?25hCollecting tokenizers<0.19,>=0.14\n  Downloading tokenizers-0.15.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n\r\u001b[K     |████████████████████████████████| 3.6 MB 57.7 MB/s \n\u001b[?25hCollecting safetensors>=0.4.1\n  Downloading safetensors-0.4.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n\r\u001b[K     |████████████████████████████████| 1.3 MB 52.5 MB/s \n\u001b[?25hRequirement already satisfied: filelock in /etc/system/kernel/.venv/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (3.13.1)\nCollecting nvidia-nccl-cu12==2.19.3; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n\r\u001b[K     |███████████████▌                | 80.6 MB 77.1 MB/s eta 0:00:02"
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "execution_count": 1,
     "data": {
      "text/plain": "\r\u001b[K     |████████████████████████████████| 166.0 MB 75.9 MB/s \n\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n\r\u001b[K     |██████▊                         | 154.7 MB 79.9 MB/s eta 0:00:08"
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "execution_count": 1,
     "data": {
      "text/plain": "\r\u001b[K     |██████████████████▏             | 416.3 MB 73.8 MB/s eta 0:00:05"
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "execution_count": 1,
     "data": {
      "text/plain": "\r\u001b[K     |█████████████████████████████▊  | 680.1 MB 80.8 MB/s eta 0:00:01"
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "execution_count": 1,
     "data": {
      "text/plain": "\r\u001b[K     |████████████████████████████████| 731.7 MB 80.8 MB/s \n\u001b[?25hRequirement already satisfied: networkx in /etc/system/kernel/.venv/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.2.1)\nRequirement already satisfied: fsspec in /etc/system/kernel/.venv/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (2024.2.0)\nCollecting nvidia-cuda-cupti-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n\r\u001b[K     |████████████████████████████████| 14.1 MB 58.9 MB/s \n\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n\r\u001b[K     |███████                         | 91.0 MB 71.2 MB/s eta 0:00:05"
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "execution_count": 1,
     "data": {
      "text/plain": "\r\u001b[K     |███████████████████████████     | 346.0 MB 75.8 MB/s eta 0:00:01"
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "execution_count": 1,
     "data": {
      "text/plain": "\r\u001b[K     |████████████████████████████████| 410.6 MB 73.8 MB/s \n\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n\r\u001b[K     |██████████████████████▌         | 138.0 MB 73.3 MB/s eta 0:00:01"
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "execution_count": 1,
     "data": {
      "text/plain": "\r\u001b[K     |████████████████████████████████| 196.0 MB 64.7 MB/s \n\u001b[?25hCollecting nvidia-cuda-nvrtc-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n\r\u001b[K     |████████████████████████████████| 23.7 MB 54.6 MB/s \n\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n\r\u001b[K     |████████████████████████████████| 56.5 MB 54.5 MB/s \n\u001b[?25hCollecting triton==2.2.0; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n  Downloading triton-2.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n\r\u001b[K     |██████▊                         | 35.5 MB 51.9 MB/s eta 0:00:03"
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "execution_count": 1,
     "data": {
      "text/plain": "\r\u001b[K     |████████████████████████████████| 167.9 MB 69.8 MB/s \n\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n\r\u001b[K     |████████████████████████████████| 823 kB 54.2 MB/s \n\u001b[?25hCollecting sympy\n  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n\r\u001b[K     |████████████████████████████████| 5.7 MB 48.8 MB/s \n\u001b[?25hRequirement already satisfied: jinja2 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.1.3)\nCollecting nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n\r\u001b[K     |██████████▏                     | 39.3 MB 48.4 MB/s eta 0:00:02"
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "execution_count": 1,
     "data": {
      "text/plain": "\r\u001b[K     |████████████████████████████████| 124.2 MB 78.7 MB/s \n\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n\r\u001b[K     |████████████████████████████████| 99 kB 60.8 MB/s \n\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n\r\u001b[K     |████████████████████████████████| 121.6 MB 76.7 MB/s \n\u001b[?25h"
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "execution_count": 1,
     "data": {
      "text/plain": "Requirement already satisfied: threadpoolctl>=2.0.0 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from scikit-learn->sentence-transformers==2.2.2) (3.2.0)\nRequirement already satisfied: joblib>=1.1.1 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from scikit-learn->sentence-transformers==2.2.2) (1.2.0)\nRequirement already satisfied: click in /etc/system/kernel/.venv/lib/python3.9/site-packages (from nltk->sentence-transformers==2.2.2) (8.1.7)\nCollecting olefile>=0.46\n  Downloading olefile-0.47-py2.py3-none-any.whl (114 kB)\n\r\u001b[K     |████████████████████████████████| 114 kB 62.2 MB/s \n\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from pandas->unstructured==0.8.4) (2024.1)\nRequirement already satisfied: python-dateutil>=2.8.1 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from pandas->unstructured==0.8.4) (2.8.2)\nCollecting XlsxWriter>=0.5.7\n  Downloading XlsxWriter-3.1.9-py3-none-any.whl (154 kB)\n\r\u001b[K     |████████████████████████████████| 154 kB 57.5 MB/s \n\u001b[?25hRequirement already satisfied: cryptography>=36.0.0 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from pdfminer.six->unstructured==0.8.4) (41.0.7)\nRequirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in /etc/system/kernel/.venv/lib/python3.9/site-packages (from markdown->unstructured==0.8.4) (7.0.1)\nRequirement already satisfied: et-xmlfile in /etc/system/kernel/.venv/lib/python3.9/site-packages (from openpyxl->unstructured==0.8.4) (1.1.0)\nRequirement already satisfied: comm>=0.1.3 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from ipywidgets->datarobotx) (0.2.1)\nCollecting widgetsnbextension~=4.0.10\n  Downloading widgetsnbextension-4.0.10-py3-none-any.whl (2.3 MB)\n\r\u001b[K     |████████████████████████████████| 2.3 MB 52.3 MB/s \n\u001b[?25hCollecting jupyterlab-widgets~=3.0.10\n  Downloading jupyterlab_widgets-3.0.10-py3-none-any.whl (215 kB)\n\r\u001b[K     |████████████████████████████████| 215 kB 58.8 MB/s \n\u001b[?25hRequirement already satisfied: traitlets>=4.3.1 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from ipywidgets->datarobotx) (5.14.1)\nCollecting cmdkit>=2.1.2\n  Downloading cmdkit-2.7.4-py3-none-any.whl (26 kB)\nRequirement already satisfied: matplotlib-inline in /etc/system/kernel/.venv/lib/python3.9/site-packages (from IPython->datarobotx) (0.1.6)\nRequirement already satisfied: jedi>=0.16 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from IPython->datarobotx) (0.19.1)\nRequirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from IPython->datarobotx) (3.0.43)\nRequirement already satisfied: stack-data in /etc/system/kernel/.venv/lib/python3.9/site-packages (from IPython->datarobotx) (0.6.3)\nRequirement already satisfied: pygments>=2.4.0 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from IPython->datarobotx) (2.17.2)\nRequirement already satisfied: exceptiongroup; python_version < \"3.11\" in /etc/system/kernel/.venv/lib/python3.9/site-packages (from IPython->datarobotx) (1.2.0)\nRequirement already satisfied: pexpect>4.3; sys_platform != \"win32\" in /etc/system/kernel/.venv/lib/python3.9/site-packages (from IPython->datarobotx) (4.9.0)\nRequirement already satisfied: decorator in /etc/system/kernel/.venv/lib/python3.9/site-packages (from IPython->datarobotx) (5.1.1)\nRequirement already satisfied: entrypoints in /etc/system/kernel/.venv/lib/python3.9/site-packages (from altair<5.0.0->datarobotx) (0.4)\nRequirement already satisfied: toolz in /etc/system/kernel/.venv/lib/python3.9/site-packages (from altair<5.0.0->datarobotx) (0.12.1)\nRequirement already satisfied: jsonschema>=3.0 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from altair<5.0.0->datarobotx) (4.21.1)\nRequirement already satisfied: strenum>=0.4.15 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from datarobot>=3.2.0->datarobotx) (0.4.15)\nRequirement already satisfied: trafaret!=1.1.0,<2.2,>=0.7 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from datarobot>=3.2.0->datarobotx) (2.1.1)\nRequirement already satisfied: requests-toolbelt>=0.6 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from datarobot>=3.2.0->datarobotx) (1.0.0)\nRequirement already satisfied: mypy-extensions<2,>=0.4.0 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from datarobot>=3.2.0->datarobotx) (1.0.0)\nRequirement already satisfied: sniffio>=1.1 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.7->langchain==0.1.0) (1.3.0)\nCollecting nvidia-nvjitlink-cu12\n  Downloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (20.5 MB)\n\r\u001b[K     |████████████████████████████████| 20.5 MB 51.5 MB/s \n\u001b[?25hCollecting mpmath>=0.19\n  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n\r\u001b[K     |████████████████████████████████| 536 kB 61.4 MB/s \n\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from jinja2->torch>=1.6.0->sentence-transformers==2.2.2) (2.1.3)\nRequirement already satisfied: six>=1.5 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->unstructured==0.8.4) (1.16.0)\nRequirement already satisfied: cffi>=1.12 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from cryptography>=36.0.0->pdfminer.six->unstructured==0.8.4) (1.16.0)\nRequirement already satisfied: zipp>=0.5 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown->unstructured==0.8.4) (3.17.0)\nCollecting toml<0.11.0,>=0.10.2\n  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\nRequirement already satisfied: parso<0.9.0,>=0.8.3 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from jedi>=0.16->IPython->datarobotx) (0.8.3)\nRequirement already satisfied: wcwidth in /etc/system/kernel/.venv/lib/python3.9/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->IPython->datarobotx) (0.2.13)\nRequirement already satisfied: pure-eval in /etc/system/kernel/.venv/lib/python3.9/site-packages (from stack-data->IPython->datarobotx) (0.2.2)\nRequirement already satisfied: executing>=1.2.0 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from stack-data->IPython->datarobotx) (2.0.1)\nRequirement already satisfied: asttokens>=2.1.0 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from stack-data->IPython->datarobotx) (2.4.1)\nRequirement already satisfied: ptyprocess>=0.5 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from pexpect>4.3; sys_platform != \"win32\"->IPython->datarobotx) (0.7.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from jsonschema>=3.0->altair<5.0.0->datarobotx) (2023.12.1)\nRequirement already satisfied: referencing>=0.28.4 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from jsonschema>=3.0->altair<5.0.0->datarobotx) (0.33.0)\nRequirement already satisfied: rpds-py>=0.7.1 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from jsonschema>=3.0->altair<5.0.0->datarobotx) (0.17.1)\nRequirement already satisfied: pycparser in /etc/system/kernel/.venv/lib/python3.9/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->unstructured==0.8.4) (2.21)\nBuilding wheels for collected packages: sentence-transformers\n  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/"
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "execution_count": 1,
     "data": {
      "text/plain": "\b \bdone\n\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125923 sha256=e7f42b419912c88da5d989fea55600d877b0186a5aac86fc61ab47eb893efeee\n  Stored in directory: /tmp/pip-ephem-wheel-cache-u6_2kklv/wheels/71/67/06/162a3760c40d74dd40bc855d527008d26341c2b0ecf3e8e11f\nSuccessfully built sentence-transformers\n"
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "execution_count": 1,
     "data": {
      "text/plain": "Installing collected packages: typing-inspect, marshmallow, dataclasses-json, jsonpointer, jsonpatch, langsmith, langchain-core, greenlet, SQLAlchemy, langchain-community, langchain, faiss-cpu, regex, huggingface-hub, tokenizers, safetensors, transformers, nvidia-nccl-cu12, nvidia-cublas-cu12, nvidia-cudnn-cu12, nvidia-cuda-cupti-cu12, nvidia-nvjitlink-cu12, nvidia-cusparse-cu12, nvidia-cuda-nvrtc-cu12, nvidia-curand-cu12, triton, nvidia-cuda-runtime-cu12, mpmath, sympy, nvidia-cusolver-cu12, nvidia-nvtx-cu12, nvidia-cufft-cu12, torch, torchvision, nltk, sentencepiece, sentence-transformers, filetype, olefile, msg-parser, lxml, python-docx, pdf2image, XlsxWriter, python-pptx, xlrd, chardet, pypandoc, python-magic, pdfminer.six, markdown, unstructured, openai, widgetsnbextension, jupyterlab-widgets, ipywidgets, toml, cmdkit, names-generator, datarobotx\n"
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "execution_count": 1,
     "data": {
      "text/plain": "\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\nWe recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\nlangchain-core 0.1.23 requires langsmith<0.0.88,>=0.0.87, but you'll have langsmith 0.0.92 which is incompatible.\u001b[0m\nSuccessfully installed SQLAlchemy-2.0.27 XlsxWriter-3.1.9 chardet-5.2.0 cmdkit-2.7.4 dataclasses-json-0.6.4 datarobotx-0.1.21 faiss-cpu-1.7.4 filetype-1.2.0 greenlet-3.0.3 huggingface-hub-0.20.3 ipywidgets-8.1.2 jsonpatch-1.33 jsonpointer-2.4 jupyterlab-widgets-3.0.10 langchain-0.1.0 langchain-community-0.0.20 langchain-core-0.1.23 langsmith-0.0.92 lxml-5.1.0 markdown-3.5.2 marshmallow-3.20.2 mpmath-1.3.0 msg-parser-1.2.0 names-generator-0.1.0 nltk-3.8.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.3.101 nvidia-nvtx-cu12-12.1.105 olefile-0.47 openai-0.27.8 pdf2image-1.17.0 pdfminer.six-20231228 pypandoc-1.12 python-docx-1.1.0 python-magic-0.4.27 python-pptx-0.6.23 regex-2023.12.25 safetensors-0.4.2 sentence-transformers-2.2.2 sentencepiece-0.1.99 sympy-1.12 tokenizers-0.15.2 toml-0.10.2 torch-2.2.0 torchvision-0.17.0 transformers-4.37.2 triton-2.2.0 typing-inspect-0.9.0 unstructured-0.8.4 widgetsnbextension-4.0.10 xlrd-2.0.1\n"
     },
     "metadata": {}
    }
   ],
   "execution_count": null
  },
  {
   "id": "65cc181dcb56e661b7bc89ef",
   "cell_type": "code",
   "source": [
    "# Decompress the documents\n",
    "!tar -xf ./storage/dr_docs.tar -C ./storage/"
   ],
   "metadata": {
    "collapsed": false,
    "scrolled": false,
    "datarobot": {
     "language": "python"
    },
    "hide_code": false,
    "hide_results": false,
    "disable_run": false,
    "chart_settings": null,
    "custom_metric_settings": null,
    "custom_llm_metric_settings": null,
    "dataframe_view_options": null
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "65cc1839cb56e661b7bc89f7",
   "cell_type": "code",
   "source": [
    "import re\n",
    "\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.text_splitter import MarkdownTextSplitter\n",
    "\n",
    "SOURCE_DOCUMENTS_DIR = \"storage/datarobot_docs/\"\n",
    "SOURCE_DOCUMENTS_FILTER = \"**/*.md\"\n",
    "\n",
    "loader = DirectoryLoader(f\"{SOURCE_DOCUMENTS_DIR}\", glob=SOURCE_DOCUMENTS_FILTER)\n",
    "splitter = MarkdownTextSplitter(\n",
    "    chunk_size=2000,\n",
    "    chunk_overlap=1000,\n",
    ")\n",
    "\n",
    "print(f\"Loading {SOURCE_DOCUMENTS_DIR} directory\")\n",
    "data = loader.load()\n",
    "print(f\"Splitting {len(data)} documents\")\n",
    "docs = splitter.split_documents(data)\n",
    "for doc in docs:\n",
    "    doc.metadata[\"source\"] = re.sub(\n",
    "        r\"storage/datarobot_docs/en/(.+)\\.md\",\n",
    "        r\"https://docs.datarobot.com/en/docs/\\1.html\",\n",
    "        doc.metadata[\"source\"],\n",
    "    )\n",
    "print(f\"Created {len(docs)} documents\")"
   ],
   "metadata": {
    "collapsed": false,
    "scrolled": false,
    "datarobot": {
     "language": "python"
    },
    "hide_code": false,
    "hide_results": false,
    "disable_run": false,
    "chart_settings": null,
    "custom_metric_settings": null,
    "custom_llm_metric_settings": null,
    "dataframe_view_options": null
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 3,
     "data": {
      "text/plain": "Loading storage/datarobot_docs/ directory\n[nltk_data] Downloading package punkt to /home/notebooks/nltk_data...\n[nltk_data]   Unzipping tokenizers/punkt.zip.\n[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     /home/notebooks/nltk_data...\n[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "execution_count": 3,
     "data": {
      "text/plain": "Splitting 726 documents\nCreated 3466 documents\n"
     },
     "metadata": {}
    }
   ],
   "execution_count": null
  },
  {
   "id": "65cc184a5628a360da417ae8",
   "cell_type": "code",
   "source": [
    "from langchain.docstore.document import Document\n",
    "from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "from langchain.vectorstores.faiss import FAISS\n",
    "import torch\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    EMBEDDING_MODEL_NAME = \"all-MiniLM-L6-v2\"\n",
    "else:\n",
    "    EMBEDDING_MODEL_NAME = \"all-mpnet-base-v2\"\n",
    "\n",
    "# Will download the model the first time it runs\n",
    "embedding_function = SentenceTransformerEmbeddings(\n",
    "    model_name=EMBEDDING_MODEL_NAME,\n",
    "    cache_folder=\"storage/deploy/sentencetransformers\",\n",
    ")\n",
    "try:\n",
    "    # Load existing db from disk if previously built\n",
    "    db = FAISS.load_local(\"storage/deploy/faiss-db\", embedding_function)\n",
    "except:\n",
    "    texts = [doc.page_content for doc in docs]\n",
    "    metadatas = [doc.metadata for doc in docs]\n",
    "    # Build and save the FAISS db to persistent notebook storage; this can take some time w/o GPUs\n",
    "    db = FAISS.from_texts(texts, embedding_function, metadatas=metadatas)\n",
    "    db.save_local(\"storage/deploy/faiss-db\")\n",
    "\n",
    "print(f\"FAISS VectorDB has {db.index.ntotal} documents\")"
   ],
   "metadata": {
    "collapsed": false,
    "scrolled": false,
    "datarobot": {
     "language": "python"
    },
    "hide_code": false,
    "hide_results": false,
    "disable_run": false,
    "chart_settings": null,
    "custom_metric_settings": null,
    "custom_llm_metric_settings": null,
    "dataframe_view_options": null
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 4,
     "data": {
      "text/plain": "FAISS VectorDB has 3466 documents\n"
     },
     "metadata": {}
    }
   ],
   "execution_count": null
  },
  {
   "id": "65cc1778231f36cec7a1a975",
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "OPENAI_API_BASE = os.environ[\"OPENAI_API_BASE\"]\n",
    "OPENAI_ORGANIZATION = os.environ[\"OPENAI_ORGANIZATION\"]\n",
    "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]\n",
    "OPENAI_API_TYPE = os.environ[\"OPENAI_API_TYPE\"]\n",
    "OPENAI_API_VERSION = os.environ[\"OPENAI_API_VERSION\"]\n",
    "OPENAI_DEPLOYMENT_NAME = os.environ[\"OPENAI_DEPLOYMENT_NAME\"]\n",
    "\n",
    "\n",
    "def load_model(input_dir):\n",
    "    \"\"\"Custom model hook for loading our knowledge base.\"\"\"\n",
    "    import os\n",
    "\n",
    "    from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "    from langchain.vectorstores.faiss import FAISS\n",
    "\n",
    "    os.environ[\"OPENAI_API_TYPE\"] = OPENAI_API_TYPE\n",
    "    os.environ[\"OPENAI_API_BASE\"] = OPENAI_API_BASE\n",
    "    EMBEDDING_MODEL_NAME = \"all-MiniLM-L6-v2\"\n",
    "    embedding_function = SentenceTransformerEmbeddings(\n",
    "        model_name=EMBEDDING_MODEL_NAME,\n",
    "        cache_folder=input_dir + \"/\" + \"storage/deploy/sentencetransformers\",\n",
    "    )\n",
    "    db = FAISS.load_local(input_dir + \"/\" + \"storage/deploy/faiss-db\", embedding_function)\n",
    "    return OPENAI_DEPLOYMENT_NAME, db\n",
    "\n",
    "\n",
    "def score_unstructured(model, data, query, **kwargs) -> str:\n",
    "    \"\"\"Custom model hook for making completions with our knowledge base.\"\"\"\n",
    "\n",
    "    import json\n",
    "\n",
    "    from langchain.chains import ConversationalRetrievalChain\n",
    "    from langchain.chat_models import AzureChatOpenAI\n",
    "    from langchain.vectorstores.base import VectorStoreRetriever\n",
    "\n",
    "    try:\n",
    "        deployment_name, db = model\n",
    "        data_dict = json.loads(data)\n",
    "        llm = AzureChatOpenAI(\n",
    "            deployment_name=OPENAI_DEPLOYMENT_NAME,\n",
    "            openai_api_type=OPENAI_API_TYPE,\n",
    "            openai_api_base=OPENAI_API_BASE,\n",
    "            openai_api_version=OPENAI_API_VERSION,\n",
    "            openai_api_key=OPENAI_API_KEY,\n",
    "            openai_organization=OPENAI_ORGANIZATION,\n",
    "            model_name=OPENAI_DEPLOYMENT_NAME,\n",
    "            temperature=0,\n",
    "            verbose=True,\n",
    "            max_retries=0,\n",
    "            request_timeout=20,\n",
    "        )\n",
    "        retriever = VectorStoreRetriever(vectorstore=db)\n",
    "        chain = ConversationalRetrievalChain.from_llm(\n",
    "            llm, retriever=retriever, return_source_documents=True\n",
    "        )\n",
    "        if \"chat_history\" in data_dict:\n",
    "            chat_history = [\n",
    "                (\n",
    "                    human,\n",
    "                    ai,\n",
    "                )\n",
    "                for human, ai in data_dict[\"chat_history\"]\n",
    "            ]\n",
    "        else:\n",
    "            chat_history = []\n",
    "        rv = chain(\n",
    "            inputs={\n",
    "                \"question\": data_dict[\"question\"],\n",
    "                \"chat_history\": chat_history,\n",
    "            },\n",
    "        )\n",
    "        rv[\"references\"] = [doc.metadata[\"source\"] for doc in rv.pop(\"source_documents\")]\n",
    "    except Exception as e:\n",
    "        rv = {\"error\": f\"{e.__class__.__name__}: {str(e)}\"}\n",
    "    return json.dumps(rv)"
   ],
   "metadata": {
    "collapsed": false,
    "scrolled": false,
    "datarobot": {
     "language": "python"
    },
    "hide_code": false,
    "hide_results": false,
    "disable_run": false,
    "chart_settings": null,
    "custom_metric_settings": null,
    "custom_llm_metric_settings": null,
    "dataframe_view_options": null
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "65cc17a4cb56e661b7bc89c8",
   "cell_type": "code",
   "source": [
    "import datarobotx as drx\n",
    "\n",
    "deployment = drx.deploy(\n",
    "    \"storage/deploy/\",\n",
    "    name=\"Teams Bot\",\n",
    "    hooks={\"score_unstructured\": score_unstructured, \"load_model\": load_model},\n",
    "    extra_requirements=[\n",
    "        \"langchain==0.1.0\",\n",
    "        #                    \"faiss-cpu==1.7.4\",\n",
    "        #                    \"sentence-transformers==2.2.2\",\n",
    "        #                    \"unstructured==0.8.4\",\n",
    "        #                    \"openai==0.27.8\",\n",
    "        #                    \"datarobotx\",\n",
    "        #                    \"pydantic\"\n",
    "    ],\n",
    "    # Re-use existing environment if you want to change the hook code,\n",
    "    # and not requirements\n",
    "    environment_id=\"64c964448dd3f0c07f47d040\",\n",
    ")\n",
    "# enable storing prediction data, necessary for Data Export for monitoring purposes\n",
    "deployment.dr_deployment.update_predictions_data_collection_settings(enabled=True)"
   ],
   "metadata": {
    "collapsed": false,
    "scrolled": false,
    "datarobot": {
     "language": "python"
    },
    "hide_code": false,
    "hide_results": false,
    "disable_run": false,
    "chart_settings": null,
    "custom_metric_settings": null,
    "custom_llm_metric_settings": null,
    "dataframe_view_options": null
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 14,
     "data": {
      "text/plain": "\u001b[1m\u001b[34m#\u001b[0m\u001b[1m Deploying custom model\u001b[0m\n\u001b[1m  - \u001b[0mUnable to auto-detect model type; any provided paths and files will be\n    exported - dependencies should be explicitly specified using\n    `extra_requirements` or `environment_id`\n\u001b[1m  - \u001b[0mPreparing model and environment...\n\u001b[1m  - \u001b[0mUsing environment [[DataRobot] Python 3.9 GenAI\n    v9](https://app.datarobot.com/model-registry/custom-environments/64c964448dd3f0c07f47d040)\n    for deployment\n\u001b[1m  - \u001b[0mConfiguring and uploading custom model...\n\r    100%|█████████████████████████████████████| 104M/104M [00:00<00:00, 119MB/s]\n"
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "execution_count": 14,
     "data": {
      "text/plain": "\u001b[1m  - \u001b[0mRegistered custom model [Teams\n    Bot](https://app.datarobot.com/model-registry/custom-models/65cd8bfdccac699266d98725/info)\n    with target type: Unstructured\n\u001b[1m  - \u001b[0mInstalling additional dependencies...\n"
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "execution_count": 14,
     "data": {
      "text/plain": "\u001b[1m  - \u001b[0mCreating and deploying model package...\n"
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "execution_count": 14,
     "data": {
      "text/plain": "\u001b[1m  - \u001b[0mCreated deployment [Teams\n    Bot](https://app.datarobot.com/deployments/65cd8cb6481e3be33dcd194c/overview)\n\u001b[1m\u001b[34m#\u001b[0m\u001b[1m Custom model deployment complete\u001b[0m\n"
     },
     "metadata": {}
    }
   ],
   "execution_count": null
  },
  {
   "id": "65cc2028cb56e661b7bc8c8a",
   "cell_type": "code",
   "source": [
    "deployment.predict_unstructured({\"question\": \"Does datarobot support Azure AD?\"})"
   ],
   "metadata": {
    "collapsed": false,
    "scrolled": false,
    "datarobot": {
     "language": "python"
    },
    "hide_code": false,
    "hide_results": false,
    "disable_run": false,
    "chart_settings": null,
    "custom_metric_settings": null,
    "custom_llm_metric_settings": null,
    "dataframe_view_options": null
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 15,
     "data": {
      "text/plain": "\u001b[1m\u001b[34m#\u001b[0m\u001b[1m Making predictions\u001b[0m\n\u001b[1m  - \u001b[0mMaking predictions with deployment [Teams\n    Bot](https://app.datarobot.com/deployments/65cd8cb6481e3be33dcd194c/overview)\n"
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "execution_count": 15,
     "data": {
      "text/plain": "\u001b[1m\u001b[34m#\u001b[0m\u001b[1m Predictions complete\u001b[0m\n{'question': 'Does datarobot support Azure AD?', 'chat_history': [], 'answer': 'Yes, DataRobot does support Azure AD. It can be configured for Single Sign-On (SSO) with Azure AD as the Identity Provider (IdP). The user must grant DataRobot permission to access data on their behalf, which includes logging in with Azure credentials.', 'references': ['https://docs.datarobot.com/en/docs/platform/authentication/sso-ref.html', 'https://docs.datarobot.com/en/docs/data/data-preview/connector.html', 'https://docs.datarobot.com/en/docs/includes/browser-compatibility.html', 'https://docs.datarobot.com/en/docs/data/connect-data/data-sources/dc-azure.html']}"
     },
     "metadata": {}
    }
   ],
   "execution_count": null
  },
  {
   "id": "65cc208a5628a360da417d96",
   "cell_type": "code",
   "source": "",
   "metadata": {
    "collapsed": false,
    "scrolled": false,
    "datarobot": {
     "language": "python"
    },
    "hide_code": false,
    "hide_results": false,
    "disable_run": false,
    "chart_settings": null,
    "custom_metric_settings": null,
    "custom_llm_metric_settings": null,
    "dataframe_view_options": null
   },
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python",
   "language": "python",
   "display_name": "Python 3.9.18"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
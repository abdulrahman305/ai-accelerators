{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "298dad7e-a4cb-47fb-b71d-6b4bade31173",
   "metadata": {},
   "source": [
    "# Fraud Detection with DataRobot & Neo4j Knowledge Graph\n",
    "\n",
    "This notebook demonstrates an end-to-end pipeline for:\n",
    "1) Flattening a Neo4j graph of (Clientâ€“Loan) pairs into train + holdout CSV files.\n",
    "2) Creating a DataRobot project from the training data, with 'Fraud' as the target label.\n",
    "3) Retrieving detailed model attributes from the best model on the Leaderboard using the DataRobot Python SDK.\n",
    "4) Scoring (predicting on) the holdout (pending) dataset, collecting predictions & explanations.\n",
    "5) (Optional) Updating Neo4j with these predictions for deeper analysis.\n",
    "\n",
    "Dependencies:\n",
    " - `pip install -r requirements.txt`\n",
    " - Your environment must have a class \"ClientLoanFeatureExtractor\" that extracts a DataFrame from Neo4j\n",
    "   and optionally a method to update predictions back into Neo4j.\n",
    "\n",
    "Remember to adapt or remove code as needed for your environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd4012a-cca2-4bc4-a407-102670249ffd",
   "metadata": {},
   "source": [
    "### 0. Imports, Setup, and Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f743709-9ee0-40a6-a165-8ea471949003",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "from FraudGraphFeatureExtractor import (\n",
    "    ClientLoanFeatureExtractor,\n",
    "    update_neo4j_predictions,\n",
    ")\n",
    "import datarobot as dr\n",
    "from neo4j import GraphDatabase\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8668d4f-cb42-434c-822e-dd4035353c9f",
   "metadata": {},
   "source": [
    "### 1. DataRobot Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba79b2f3-eaee-4eee-88e2-a3b0d6b28885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example:\n",
    "# DR_TOKEN = \"YOUR_DATAROBOT_API_TOKEN\"\n",
    "# DR_ENDPOINT = \"https://app.datarobot.com/api/v2\"  # or your DR cluster\n",
    "#\n",
    "# If you haven't already called dr.Client(...), do so below:\n",
    "# dr.Client(token=DR_TOKEN, endpoint=DR_ENDPOINT)\n",
    "dr.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed7d989-8cbe-41e3-9f8e-c7654eb75f3f",
   "metadata": {},
   "source": [
    "### 2. Neo4j Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ec170e-a5ed-4767-9312-174bc9b355ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEO4J_URI = \"bolt://localhost:7687\"\n",
    "NEO4J_USER = \"neo4j\"\n",
    "NEO4J_PASSWORD = \"password\"\n",
    "NEO4J_DATABASE = \"neo4j\"  # or None if single db\n",
    "\n",
    "# Connect to DataRobot (assuming you've already configured dr.Client(...) globally)\n",
    "dr.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2651cc-2d9c-4cb0-a92e-97ca65c6ec22",
   "metadata": {},
   "source": [
    "### 3) Create Two CSVs from Neo4j\n",
    "\n",
    "In this step, we:\n",
    "1. Use 'ClientLoanFeatureExtractor' to flatten the Neo4j graph into a single DataFrame 'df'.\n",
    "2. Split 'df' into:\n",
    "   - df_train: all rows with loan_status != 'pending' (i.e., closed loans, labeled Fraud=0/1)\n",
    "   - df_holdout: all rows with loan_status == 'pending' (unlabeled)\n",
    "3. Save these to 'train.csv' (for modeling) and 'holdout.csv' (for scoring).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3ef5fa-6f0e-4ffd-b285-fe4262e0078a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Extracting data from Neo4j -> dataframes...\")\n",
    "\n",
    "extractor = ClientLoanFeatureExtractor(\n",
    "    uri=NEO4J_URI, user=NEO4J_USER, password=NEO4J_PASSWORD, database=NEO4J_DATABASE\n",
    ")\n",
    "df = extractor.extract_client_loan_rows()\n",
    "extractor.close()\n",
    "\n",
    "print(\"Full DataFrame shape:\", df.shape)\n",
    "print(df.head(5))\n",
    "\n",
    "# Separate training vs. holdout\n",
    "df_train = df[df[\"loan_status\"] != \"pending\"].copy()\n",
    "df_holdout = df[df[\"loan_status\"] == \"pending\"].copy()\n",
    "\n",
    "# Save to CSV\n",
    "df_train.to_csv(\"train.csv\", index=False)\n",
    "df_holdout.to_csv(\"holdout.csv\", index=False)\n",
    "\n",
    "print(\"train.csv shape:\", df_train.shape)\n",
    "print(\"holdout.csv shape:\", df_holdout.shape)\n",
    "print(\"Saved train.csv, holdout.csv.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53962430-b1f1-4f85-9fbc-3942425c5cb9",
   "metadata": {},
   "source": [
    "### 4) Upload the Training Dataset to DataRobot and Start AutoPilot\n",
    "\n",
    "Next, we:\n",
    "1. Create a UseCase object (optional) in DataRobot to categorize our project. \n",
    "2. Upload 'train.csv' as a DataRobot dataset.\n",
    "3. (Optionally) create a feature list if we have a known subset of features.\n",
    "4. Create a Project using 'Project.create_from_dataset(...)'.\n",
    "5. Set 'Fraud' as our target label. DataRobot runs Autopilot to train multiple models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8360e3e9-481b-4089-af38-76a1f2f82a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_case_name = \"AI Accelerator: Fraud Detection with Knowledge Graphs\"\n",
    "\n",
    "use_case = dr.UseCase.create(\n",
    "    name=use_case_name, \n",
    "    description=\"Fraud Detection with Knowledge Graphs and DataRobot\"\n",
    ")\n",
    "\n",
    "train_ds = dr.Dataset.create_from_file(\"./train.csv\", categories=[\"TRAINING\"], use_cases=[use_case])\n",
    "\n",
    "# Load a separate CSV for selected features and create feature list\n",
    "features = pd.read_csv(\"./Selected Features.csv\", header=None)[0].to_list()\n",
    "train_ds.create_featurelist(\"Selected Features\", features)\n",
    "\n",
    "project_name = f\"Fraud_Loan_Demo_{datetime.datetime.now().strftime('%Y%m%d_%H%M')}\"\n",
    "print(f\"\n",
    "Creating new DataRobot project: {project_name}\")\n",
    "\n",
    "project = dr.Project.create_from_dataset(\n",
    "    dataset_id=train_ds.id,\n",
    "    project_name=project_name,\n",
    "    use_case=use_case\n",
    ")\n",
    "\n",
    "fl = project.get_featurelist_by_name(\"Selected Features\")\n",
    "\n",
    "project.set_options(shap_only_mode=True)\n",
    "project.analyze_and_model(\n",
    "    target=\"Fraud\",\n",
    "    mode=dr.AUTOPILOT_MODE.FULL_AUTO,\n",
    "    worker_count=-1\n",
    "    featurelist_id=fl.id, \n",
    ")\n",
    "print(\"Autopilot started. Building models...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e89f24-4f79-48d6-a1e5-33b92ef1de36",
   "metadata": {},
   "source": [
    "### 5) Choose the Best Model & Retrieve Detailed Info from the Python SDK\n",
    "\n",
    "We wait for autopilot to finish, then pick the top model from the leaderboard\n",
    "and display some advanced attributes, e.g., blueprint_id, metrics, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23df5c4c-0d9a-45e6-9f42-5cc1ba681e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nWaiting for Autopilot to finish (this may take a while).\")\n",
    "project.wait_for_autopilot()\n",
    "\n",
    "# Retrieve models sorted by rank\n",
    "models = project.get_models()\n",
    "best_model = models[0]\n",
    "print(f\"Best model = {best_model.model_type}, id={best_model.id}\")\n",
    "\n",
    "print(\"\\n--- Detailed Model Info ---\")\n",
    "# Let's print each relevant attribute from the Model class\n",
    "print(\"Model ID:\", best_model.id)\n",
    "print(\"Project ID:\", best_model.project_id)\n",
    "print(\"Processes:\", best_model.processes)\n",
    "print(\"Featurelist Name:\", best_model.featurelist_name)\n",
    "print(\"Featurelist ID:\", best_model.featurelist_id)\n",
    "print(\"Sample pct (if non-datetime partition):\", best_model.sample_pct)\n",
    "print(\"Training row count:\", best_model.training_row_count)\n",
    "print(\"Training duration (datetime partition):\", best_model.training_duration)\n",
    "print(\"Training start date:\", best_model.training_start_date)\n",
    "print(\"Training end date:\", best_model.training_end_date)\n",
    "print(\"Model Type:\", best_model.model_type)\n",
    "print(\"Model Category:\", best_model.model_category)\n",
    "print(\"Is Frozen?:\", best_model.is_frozen)\n",
    "print(\"Blueprint ID:\", best_model.blueprint_id)\n",
    "print(\"Metrics:\", best_model.metrics)\n",
    "print(\"N Clusters:\", best_model.n_clusters)\n",
    "print(\"Has Empty Clusters?:\", best_model.has_empty_clusters)\n",
    "print(\"Is starred?:\", best_model.is_starred)\n",
    "print(\"Prediction Threshold:\", best_model.prediction_threshold)\n",
    "print(\"Model Number:\", best_model.model_number)\n",
    "print(\"Parent Model ID:\", best_model.parent_model_id)\n",
    "print(\"Supports composable ml?:\", best_model.supports_composable_ml)\n",
    "if hasattr(best_model, \"use_project_settings\"):\n",
    "    print(\"Use project settings:\", best_model.use_project_settings)\n",
    "print(\"------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2634abd-c643-4ef1-8367-ba7c6ac83ed5",
   "metadata": {},
   "source": [
    "### 6) Predict on the Holdout (Pending) Dataset & Possibly Request Explanations\n",
    "We upload 'holdout.csv' to DataRobot as a separate dataset, \n",
    "then request predictions using the best model. \n",
    "We optionally also request prediction explanations to see top feature drivers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a36514d-406a-49d6-8708-e68f478719f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nScoring holdout.csv with best model...\")\n",
    "holdout_ds = project.upload_dataset(\"holdout.csv\")\n",
    "\n",
    "# Request predictions on the holdout dataset\n",
    "pred_job = best_model.request_predictions(holdout_ds.id)\n",
    "pred_df = pred_job.get_result_when_complete(max_wait=600)\n",
    "\n",
    "print(\"Predictions shape:\", pred_df.shape)\n",
    "print(\"Sample predictions:\")\n",
    "print(pred_df.head())\n",
    "\n",
    "# If you want explanations:\n",
    "explanations_job = dr.PredictionExplanations.create(\n",
    "    project_id=project.id,\n",
    "    model_id=best_model.id,\n",
    "    dataset_id=holdout_ds.id,\n",
    "    max_explanations=5,\n",
    ")\n",
    "explanations_df = explanations_job.get_result_when_complete(max_wait=999).get_all_as_dataframe()\n",
    "print(\"\\nExplanations sample:\\n\", explanations_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3751d79c-1104-4e29-9570-8169f63321c5",
   "metadata": {},
   "source": [
    "### 7. Combine predictions + top explanation with the original holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e228f29c-f523-4ae4-b6a8-00cc9d4ff40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scored = df_holdout.copy()\n",
    "\n",
    "# The output column might be 'positive_probability' or 'prediction'\n",
    "pred_col = \"positive_probability\" if \"positive_probability\" in pred_df.columns else \"prediction\"\n",
    "df_scored[\"pred_fraud_probability\"] = pred_df[pred_col].values\n",
    "\n",
    "# Minimal approach for top explanation\n",
    "df_scored[\"top_feature\"] = explanations_df[\"explanation_0_feature\"]\n",
    "df_scored[\"top_feature_value\"] = explanations_df[\"explanation_0_feature_value\"]\n",
    "df_scored[\"top_feat_qual_strgth\"] = explanations_df[\"explanation_0_qualitative_strength\"]\n",
    "\n",
    "df_scored.to_csv(\"holdout_scored.csv\", index=False)\n",
    "print(\"holdout_scored.csv saved with predictions + top explanation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99536803-466d-428c-a764-523f98bd8089",
   "metadata": {},
   "source": [
    "### 8) Post-Processing & Update Neo4j with DataRobot Predictions\n",
    "\n",
    "We might define a threshold for \"flagged_as_fraud\". \n",
    "Then we can re-inject these predictions back to Neo4j if we choose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca296eeb-2f05-4437-a4dc-7abeea21efdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scored[\"flagged_as_fraud\"] = (df_scored[\"pred_fraud_probability\"] > 0.45).astype(int)\n",
    "print(\"\\nHigh-level summary of flagged loans:\")\n",
    "print(df_scored[\"flagged_as_fraud\"].value_counts())\n",
    "\n",
    "\n",
    "print(\"\\nUpdating Neo4j with predictions from best model...\")\n",
    "update_neo4j_predictions(df_scored, best_model)\n",
    "print(\"All done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

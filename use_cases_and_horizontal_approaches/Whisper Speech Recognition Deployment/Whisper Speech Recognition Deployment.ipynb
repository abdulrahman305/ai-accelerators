{
 "cells": [
  {
   "id": "65a4fac2278b632343e481fd",
   "cell_type": "markdown",
   "source": "# Introduction\n## Implementing a Speech Recognition capability in DataRobot\n\nThis accelerator demonstrates the use of DataRobot custom models functionality to deploy a speech recognition capability to DataRobot based on the OpenAI Whisper models (currently uses the \"base\" model). This allows the capability to leverage the DataRobot environment and resources, on cloud or on prem.\n\nPossible Enhancements\n- Using alternative models from the OpenAI Whisper set (larger or smaller), or a different model altogether\n- Adding custom metrics to track in MLProd (e.g. total audio length, average audio length)\n- Adding the ability to batch process files in a given URL location\n\nReferences:\n\nhttps://openai.com/research/whisper\n\nhttps://ffmpeg.org",
   "metadata": {
    "collapsed": false,
    "scrolled": false,
    "datarobot": {
     "language": "markdown"
    },
    "hide_code": false,
    "hide_results": true,
    "disable_run": false,
    "chart_settings": null,
    "custom_metric_settings": null,
    "dataframe_view_options": null
   }
  },
  {
   "id": "65a79bfcb7e1adf036c8cf89",
   "cell_type": "markdown",
   "source": "# Setup\n## READ BEFORE STARTING NOTEBOOK\n1. Use a Python 3.9 notebook and deployment environment\n2. Enable the following **feature flags** on your account:\n    - Enable Notebooks Filesystem Management\n    - Enable Public Network Access for all Custom Models\n3. Enable the notebook filesystem for this notebook in the notebook sidebar\n4. Set the notebook session timeout to 180 minutes\n5. Upload ffmpeg file into the notebook filesystem (see below)",
   "metadata": {
    "collapsed": false,
    "scrolled": false,
    "datarobot": {
     "language": "markdown"
    },
    "hide_code": false,
    "hide_results": true,
    "disable_run": false,
    "chart_settings": null,
    "custom_metric_settings": null,
    "dataframe_view_options": null
   }
  },
  {
   "id": "65a56d57b7e1adf036c81e86",
   "cell_type": "code",
   "source": [
    "# Download a static Linux build of ffmpeg, and upload the >>>single<<< \"ffmpeg\" file into the notebook\n",
    "# filesystem (directly under storage)\n",
    "# Source: https://johnvansickle.com/ffmpeg/\n",
    "# For example: https://johnvansickle.com/ffmpeg/releases/ffmpeg-release-amd64-static.tar.xz\n",
    "# Tested with ffmpeg-6.1-amd64-static\n",
    "\n",
    "ffmpeg_file_path = \"./storage/ffmpeg\"\n",
    "\n",
    "try:\n",
    "    import os\n",
    "\n",
    "    assert os.path.isfile(ffmpeg_file_path)\n",
    "    print(\"Found ffmpeg file\")\n",
    "except Exception as e:\n",
    "    raise RuntimeError(\n",
    "        \"Please follow the setup steps before running the notebook to upload ffmpeg.\"\n",
    "    ) from e"
   ],
   "metadata": {
    "name": "Check for the presence of the ffmpeg file",
    "collapsed": false,
    "scrolled": false,
    "datarobot": {
     "language": "python"
    },
    "hide_code": false,
    "hide_results": false,
    "disable_run": false,
    "chart_settings": null,
    "custom_metric_settings": null,
    "dataframe_view_options": null
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 1,
     "data": {
      "text/plain": "Found ffmpeg file\n"
     },
     "metadata": {}
    }
   ],
   "execution_count": 1
  },
  {
   "id": "65a4fac2278b632343e481fe",
   "cell_type": "code",
   "source": [
    "!pip install -U openai-whisper \\\n",
    "                ffmpeg \\\n",
    "                datarobotx"
   ],
   "metadata": {
    "collapsed": false,
    "scrolled": false,
    "datarobot": {
     "language": "python"
    },
    "hide_code": false,
    "hide_results": false,
    "disable_run": false,
    "chart_settings": null,
    "custom_metric_settings": null,
    "dataframe_view_options": null
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 2,
     "data": {
      "text/plain": "Collecting openai-whisper\n  Downloading openai-whisper-20231117.tar.gz (798 kB)\n\r\u001b[K     |████████████████████████████████| 798 kB 14.4 MB/s \n\u001b[?25h  Installing build dependencies ... \u001b[?25l-\b \b\\"
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "execution_count": 2,
     "data": {
      "text/plain": "\b \b|\b \b/\b \bdone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25l-\b \bdone\n\u001b[?25h    Preparing wheel metadata ... \u001b[?25l-\b \bdone\n\u001b[?25hCollecting ffmpeg\n  Downloading ffmpeg-1.4.tar.gz (5.1 kB)\nCollecting datarobotx\n  Downloading datarobotx-0.1.20-py3-none-any.whl (177 kB)\n\r\u001b[K     |████████████████████████████████| 177 kB 46.6 MB/s \n\u001b[?25h"
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "execution_count": 2,
     "data": {
      "text/plain": "Collecting tiktoken\n  Downloading tiktoken-0.5.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n\r\u001b[K     |████████████████████████████████| 2.0 MB 47.1 MB/s \n\u001b[?25hRequirement already satisfied, skipping upgrade: numpy in /etc/system/kernel/.venv/lib/python3.9/site-packages (from openai-whisper) (1.23.3)\nCollecting torch\n  Downloading torch-2.1.2-cp39-cp39-manylinux1_x86_64.whl (670.2 MB)\n\r\u001b[K     |██████████▊                     | 224.5 MB 73.5 MB/s eta 0:00:07"
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "execution_count": 2,
     "data": {
      "text/plain": "\r\u001b[K     |███████████████████████         | 482.4 MB 77.9 MB/s eta 0:00:03"
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "execution_count": 2,
     "data": {
      "text/plain": "\r\u001b[K     |████████████████████████████████| 670.2 MB 73.7 MB/s \n\u001b[?25h"
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "execution_count": 2,
     "data": {
      "text/plain": "Collecting triton<3,>=2.0.0\n  Downloading triton-2.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n\r\u001b[K     |████████████████████████████████| 167.9 MB 211 kB/s \n\u001b[?25h"
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "execution_count": 2,
     "data": {
      "text/plain": "Requirement already satisfied, skipping upgrade: more-itertools in /etc/system/kernel/.venv/lib/python3.9/site-packages (from openai-whisper) (10.2.0)\nRequirement already satisfied, skipping upgrade: tqdm in /etc/system/kernel/.venv/lib/python3.9/site-packages (from openai-whisper) (4.64.1)\nRequirement already satisfied, skipping upgrade: numba in /etc/system/kernel/.venv/lib/python3.9/site-packages (from openai-whisper) (0.58.1)\nRequirement already satisfied, skipping upgrade: IPython in /etc/system/kernel/.venv/lib/python3.9/site-packages (from datarobotx) (8.18.1)\nRequirement already satisfied, skipping upgrade: tenacity in /etc/system/kernel/.venv/lib/python3.9/site-packages (from datarobotx) (8.2.3)\nRequirement already satisfied, skipping upgrade: PyYaml in /etc/system/kernel/.venv/lib/python3.9/site-packages (from datarobotx) (6.0.1)\nRequirement already satisfied, skipping upgrade: aiohttp in /etc/system/kernel/.venv/lib/python3.9/site-packages (from datarobotx) (3.9.1)\nCollecting ipywidgets\n  Downloading ipywidgets-8.1.1-py3-none-any.whl (139 kB)\n\r\u001b[K     |████████████████████████████████| 139 kB 62.3 MB/s \n\u001b[?25hRequirement already satisfied, skipping upgrade: setuptools in /etc/system/kernel/.venv/lib/python3.9/site-packages (from datarobotx) (68.2.2)\nRequirement already satisfied, skipping upgrade: termcolor in /etc/system/kernel/.venv/lib/python3.9/site-packages (from datarobotx) (2.4.0)\nRequirement already satisfied, skipping upgrade: urllib3<2.0.0 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from datarobotx) (1.26.18)\nRequirement already satisfied, skipping upgrade: altair<5.0.0 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from datarobotx) (4.2.0)\nRequirement already satisfied, skipping upgrade: cloudpickle==2.2.1 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from datarobotx) (2.2.1)\nCollecting names-generator\n  Downloading names_generator-0.1.0-py3-none-any.whl (26 kB)\nRequirement already satisfied, skipping upgrade: datarobot>=3.2.0 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from datarobotx) (3.3.0)\nRequirement already satisfied, skipping upgrade: pandas in /etc/system/kernel/.venv/lib/python3.9/site-packages (from datarobotx) (1.5.1)\nRequirement already satisfied, skipping upgrade: requests>=2.26.0 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from tiktoken->openai-whisper) (2.31.0)\nCollecting regex>=2022.1.18\n  Downloading regex-2023.12.25-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n\r\u001b[K     |████████████████████████████████| 773 kB 58.6 MB/s \n\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n\r\u001b[K     |██                              | 45.3 MB 55.0 MB/s eta 0:00:13"
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "execution_count": 2,
     "data": {
      "text/plain": "\r\u001b[K     |█████████████▎                  | 304.6 MB 70.4 MB/s eta 0:00:07"
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "execution_count": 2,
     "data": {
      "text/plain": "\r\u001b[K     |████████████████████████▋       | 563.7 MB 83.0 MB/s eta 0:00:03"
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "execution_count": 2,
     "data": {
      "text/plain": "\r\u001b[K     |████████████████████████████████| 731.7 MB 69.1 MB/s \n\u001b[?25hRequirement already satisfied, skipping upgrade: networkx in /etc/system/kernel/.venv/lib/python3.9/site-packages (from torch->openai-whisper) (3.2.1)\nCollecting nvidia-nvtx-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n\r\u001b[K     |████████████████████████████████| 99 kB 53.7 MB/s \n\u001b[?25h"
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "execution_count": 2,
     "data": {
      "text/plain": "Collecting nvidia-cuda-runtime-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n\r\u001b[K     |████████████████████████████████| 823 kB 55.7 MB/s \n\u001b[?25hRequirement already satisfied, skipping upgrade: filelock in /etc/system/kernel/.venv/lib/python3.9/site-packages (from torch->openai-whisper) (3.13.1)\nCollecting nvidia-cufft-cu12==11.0.2.54; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n\r\u001b[K     |████████████████████████████████| 121.6 MB 79.1 MB/s \n\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n\r\u001b[K     |██████████████████████          | 85.6 MB 63.0 MB/s eta 0:00:01"
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "execution_count": 2,
     "data": {
      "text/plain": "\r\u001b[K     |████████████████████████████████| 124.2 MB 63.0 MB/s \n\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n\r\u001b[K     |████████████████████████████████| 56.5 MB 59.1 MB/s \n\u001b[?25hCollecting sympy\n  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n\r\u001b[K     |████████████████████████████████| 5.7 MB 62.2 MB/s \n\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n\r\u001b[K     |███████████████▏                | 93.2 MB 78.1 MB/s eta 0:00:02"
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "execution_count": 2,
     "data": {
      "text/plain": "\r\u001b[K     |████████████████████████████████| 196.0 MB 63.4 MB/s \n\u001b[?25hCollecting nvidia-nccl-cu12==2.18.1; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n\r\u001b[K     |█████████████████▎              | 113.5 MB 70.8 MB/s eta 0:00:02"
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "execution_count": 2,
     "data": {
      "text/plain": "\r\u001b[K     |████████████████████████████████| 209.8 MB 74.0 MB/s \n\u001b[?25hCollecting nvidia-cuda-nvrtc-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n\r\u001b[K     |████████████████████████████████| 23.7 MB 59.0 MB/s \n\u001b[?25hRequirement already satisfied, skipping upgrade: jinja2 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from torch->openai-whisper) (3.1.3)\nCollecting nvidia-cublas-cu12==12.1.3.1; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n\r\u001b[K     |███████▎                        | 93.8 MB 75.0 MB/s eta 0:00:05"
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "execution_count": 2,
     "data": {
      "text/plain": "\r\u001b[K     |████████████████████████████▎   | 362.4 MB 74.9 MB/s eta 0:00:01"
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "execution_count": 2,
     "data": {
      "text/plain": "\r\u001b[K     |████████████████████████████████| 410.6 MB 74.4 MB/s \n\u001b[?25hRequirement already satisfied, skipping upgrade: fsspec in /etc/system/kernel/.venv/lib/python3.9/site-packages (from torch->openai-whisper) (2023.12.2)\nCollecting nvidia-cuda-cupti-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n\r\u001b[K     |████████████████████████████████| 14.1 MB 57.2 MB/s \n\u001b[?25hRequirement already satisfied, skipping upgrade: typing-extensions in /etc/system/kernel/.venv/lib/python3.9/site-packages (from torch->openai-whisper) (4.9.0)\nRequirement already satisfied, skipping upgrade: llvmlite<0.42,>=0.41.0dev0 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from numba->openai-whisper) (0.41.1)\nRequirement already satisfied, skipping upgrade: prompt-toolkit<3.1.0,>=3.0.41 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from IPython->datarobotx) (3.0.43)\nRequirement already satisfied, skipping upgrade: exceptiongroup; python_version < \"3.11\" in /etc/system/kernel/.venv/lib/python3.9/site-packages (from IPython->datarobotx) (1.2.0)\nRequirement already satisfied, skipping upgrade: matplotlib-inline in /etc/system/kernel/.venv/lib/python3.9/site-packages (from IPython->datarobotx) (0.1.6)\nRequirement already satisfied, skipping upgrade: jedi>=0.16 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from IPython->datarobotx) (0.19.1)\nRequirement already satisfied, skipping upgrade: decorator in /etc/system/kernel/.venv/lib/python3.9/site-packages (from IPython->datarobotx) (5.1.1)\nRequirement already satisfied, skipping upgrade: traitlets>=5 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from IPython->datarobotx) (5.14.1)\nRequirement already satisfied, skipping upgrade: pexpect>4.3; sys_platform != \"win32\" in /etc/system/kernel/.venv/lib/python3.9/site-packages (from IPython->datarobotx) (4.9.0)\nRequirement already satisfied, skipping upgrade: stack-data in /etc/system/kernel/.venv/lib/python3.9/site-packages (from IPython->datarobotx) (0.6.3)\nRequirement already satisfied, skipping upgrade: pygments>=2.4.0 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from IPython->datarobotx) (2.17.2)\nRequirement already satisfied, skipping upgrade: multidict<7.0,>=4.5 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from aiohttp->datarobotx) (6.0.4)\nRequirement already satisfied, skipping upgrade: aiosignal>=1.1.2 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from aiohttp->datarobotx) (1.3.1)\nRequirement already satisfied, skipping upgrade: async-timeout<5.0,>=4.0; python_version < \"3.11\" in /etc/system/kernel/.venv/lib/python3.9/site-packages (from aiohttp->datarobotx) (4.0.3)\nRequirement already satisfied, skipping upgrade: frozenlist>=1.1.1 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from aiohttp->datarobotx) (1.4.1)\nRequirement already satisfied, skipping upgrade: yarl<2.0,>=1.0 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from aiohttp->datarobotx) (1.9.4)\nRequirement already satisfied, skipping upgrade: attrs>=17.3.0 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from aiohttp->datarobotx) (23.2.0)\nRequirement already satisfied, skipping upgrade: comm>=0.1.3 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from ipywidgets->datarobotx) (0.2.1)\nCollecting widgetsnbextension~=4.0.9\n  Downloading widgetsnbextension-4.0.9-py3-none-any.whl (2.3 MB)\n\r\u001b[K     |████████████████████████████████| 2.3 MB 60.1 MB/s \n\u001b[?25hCollecting jupyterlab-widgets~=3.0.9\n  Downloading jupyterlab_widgets-3.0.9-py3-none-any.whl (214 kB)\n\r\u001b[K     |████████████████████████████████| 214 kB 60.8 MB/s \n\u001b[?25hRequirement already satisfied, skipping upgrade: entrypoints in /etc/system/kernel/.venv/lib/python3.9/site-packages (from altair<5.0.0->datarobotx) (0.4)\nRequirement already satisfied, skipping upgrade: toolz in /etc/system/kernel/.venv/lib/python3.9/site-packages (from altair<5.0.0->datarobotx) (0.12.0)\nRequirement already satisfied, skipping upgrade: jsonschema>=3.0 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from altair<5.0.0->datarobotx) (4.20.0)\nCollecting cmdkit>=2.1.2\n  Downloading cmdkit-2.7.3-py3-none-any.whl (26 kB)\nRequirement already satisfied, skipping upgrade: requests-toolbelt>=0.6 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from datarobot>=3.2.0->datarobotx) (1.0.0)\nRequirement already satisfied, skipping upgrade: strenum>=0.4.15 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from datarobot>=3.2.0->datarobotx) (0.4.15)\nRequirement already satisfied, skipping upgrade: trafaret!=1.1.0,<2.2,>=0.7 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from datarobot>=3.2.0->datarobotx) (2.1.1)\nRequirement already satisfied, skipping upgrade: mypy-extensions<2,>=0.4.0 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from datarobot>=3.2.0->datarobotx) (1.0.0)\nRequirement already satisfied, skipping upgrade: pytz>=2020.1 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from pandas->datarobotx) (2023.3.post1)\nRequirement already satisfied, skipping upgrade: python-dateutil>=2.8.1 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from pandas->datarobotx) (2.8.2)\nRequirement already satisfied, skipping upgrade: charset-normalizer<4,>=2 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.3.2)\nRequirement already satisfied, skipping upgrade: idna<4,>=2.5 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.6)\nRequirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2023.11.17)\nCollecting nvidia-nvjitlink-cu12\n  Downloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (20.5 MB)\n\r\u001b[K     |████████████████████████████████| 20.5 MB 56.5 MB/s \n\u001b[?25hCollecting mpmath>=0.19\n  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n\r\u001b[K     |████████████████████████████████| 536 kB 52.8 MB/s \n\u001b[?25h"
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "execution_count": 2,
     "data": {
      "text/plain": "Requirement already satisfied, skipping upgrade: MarkupSafe>=2.0 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from jinja2->torch->openai-whisper) (2.1.3)\nRequirement already satisfied, skipping upgrade: wcwidth in /etc/system/kernel/.venv/lib/python3.9/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->IPython->datarobotx) (0.2.13)\nRequirement already satisfied, skipping upgrade: parso<0.9.0,>=0.8.3 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from jedi>=0.16->IPython->datarobotx) (0.8.3)\nRequirement already satisfied, skipping upgrade: ptyprocess>=0.5 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from pexpect>4.3; sys_platform != \"win32\"->IPython->datarobotx) (0.7.0)\nRequirement already satisfied, skipping upgrade: asttokens>=2.1.0 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from stack-data->IPython->datarobotx) (2.4.1)\nRequirement already satisfied, skipping upgrade: executing>=1.2.0 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from stack-data->IPython->datarobotx) (2.0.1)\nRequirement already satisfied, skipping upgrade: pure-eval in /etc/system/kernel/.venv/lib/python3.9/site-packages (from stack-data->IPython->datarobotx) (0.2.2)\nRequirement already satisfied, skipping upgrade: referencing>=0.28.4 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from jsonschema>=3.0->altair<5.0.0->datarobotx) (0.32.1)\nRequirement already satisfied, skipping upgrade: rpds-py>=0.7.1 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from jsonschema>=3.0->altair<5.0.0->datarobotx) (0.17.1)\nRequirement already satisfied, skipping upgrade: jsonschema-specifications>=2023.03.6 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from jsonschema>=3.0->altair<5.0.0->datarobotx) (2023.12.1)\nCollecting toml>=0.10.1\n  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\nRequirement already satisfied, skipping upgrade: six>=1.5 in /etc/system/kernel/.venv/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->datarobotx) (1.16.0)\nBuilding wheels for collected packages: openai-whisper, ffmpeg\n  Building wheel for openai-whisper (PEP 517) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\n\u001b[?25h  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=801356 sha256=be89ef2448b07e0d06cc6f8ac13ffad42781135942034cdb2f9c4b3a29df8f01\n  Stored in directory: /tmp/pip-ephem-wheel-cache-710f3ttd/wheels/f5/77/96/4bb7b94449a47b726127100ad66bd72cba123fb4d0a8948473\n  Building wheel for ffmpeg (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\n\u001b[?25h  Created wheel for ffmpeg: filename=ffmpeg-1.4-py3-none-any.whl size=6080 sha256=a36ef8b651c5ec4449350c8e5fe2e40e86d5f6519af1870a7a0d89fd13b50b1b\n  Stored in directory: /tmp/pip-ephem-wheel-cache-710f3ttd/wheels/1d/57/24/4eff6a03a9ea0e647568e8a5a0546cdf957e3cf005372c0245\nSuccessfully built openai-whisper ffmpeg\n"
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "execution_count": 2,
     "data": {
      "text/plain": "Installing collected packages: regex, tiktoken, nvidia-cublas-cu12, nvidia-cudnn-cu12, triton, nvidia-nvtx-cu12, nvidia-cuda-runtime-cu12, nvidia-cufft-cu12, nvidia-nvjitlink-cu12, nvidia-cusparse-cu12, nvidia-cusolver-cu12, nvidia-curand-cu12, mpmath, sympy, nvidia-nccl-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, torch, openai-whisper, ffmpeg, widgetsnbextension, jupyterlab-widgets, ipywidgets, toml, cmdkit, names-generator, datarobotx\n"
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "execution_count": 2,
     "data": {
      "text/plain": "\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\nWe recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\ntorch 2.1.2 requires triton==2.1.0; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you'll have triton 2.2.0 which is incompatible.\u001b[0m\nSuccessfully installed cmdkit-2.7.3 datarobotx-0.1.20 ffmpeg-1.4 ipywidgets-8.1.1 jupyterlab-widgets-3.0.9 mpmath-1.3.0 names-generator-0.1.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.3.101 nvidia-nvtx-cu12-12.1.105 openai-whisper-20231117 regex-2023.12.25 sympy-1.12 tiktoken-0.5.2 toml-0.10.2 torch-2.1.2 triton-2.2.0 widgetsnbextension-4.0.9\n"
     },
     "metadata": {}
    }
   ],
   "execution_count": 2
  },
  {
   "id": "65a700985d984fdd670016d5",
   "cell_type": "code",
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import whisper\n",
    "\n",
    "model = whisper.load_model(\"base\")\n",
    "\n",
    "path = \"./storage/whisper\"\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "source = \"./.cache/whisper/base.pt\"\n",
    "target = \"./storage/whisper/base.pt\"\n",
    "\n",
    "shutil.copyfile(source, target)"
   ],
   "metadata": {
    "name": "Download the Whisper model and store it to be included in the deployment, avoiding the need to download it again",
    "collapsed": false,
    "scrolled": false,
    "datarobot": {
     "language": "python"
    },
    "hide_code": false,
    "hide_results": false,
    "disable_run": false,
    "chart_settings": null,
    "custom_metric_settings": null,
    "dataframe_view_options": null
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 3,
     "data": {
      "text/plain": "\r100%|████████████████████████████████████████| 139M/139M [00:00<00:00, 188MiB/s]\n'./storage/whisper/base.pt'"
     },
     "metadata": {}
    }
   ],
   "execution_count": 3
  },
  {
   "id": "65a4fba915b02fcffbf0fbe9",
   "cell_type": "markdown",
   "source": "# Model Deployment\n## Setup of custom model hooks\n\nReference: \n\nhttps://docs.datarobot.com/en/docs/mlops/deployment/custom-models/custom-model-assembly/unstructured-custom-models.html\n\nThe following code is used to set up the hooks that will be executed when the deployment starts up, and when it is called for scoring (transcription) purposes.",
   "metadata": {
    "collapsed": false,
    "scrolled": false,
    "datarobot": {
     "language": "markdown"
    },
    "hide_code": false,
    "hide_results": false,
    "disable_run": false,
    "chart_settings": null,
    "custom_metric_settings": null,
    "dataframe_view_options": null
   }
  },
  {
   "id": "65a6a935f28a37c32c442a63",
   "cell_type": "code",
   "source": [
    "import base64\n",
    "import codecs\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def file_to_base_64(filepath: str):\n",
    "    \"\"\"\n",
    "    Convert content of a file path and converts to base64\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filepath : str\n",
    "        Path to a file. In our case, this will be used only for pdfs\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bytes\n",
    "        Base64 representation of a file\n",
    "    \"\"\"\n",
    "    with open(filepath, \"rb\") as file:\n",
    "        encoded_string = base64.b64encode(file.read())\n",
    "        return encoded_string\n",
    "\n",
    "\n",
    "def base_64_to_file(b64_string: bytes, filepath: str = \"data/temp.pdf\") -> str:\n",
    "    \"\"\"\n",
    "    Decode a base64 string and write into a pdf file\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    b64_string : bytes\n",
    "        Base64 representation of a file\n",
    "    filepath : str, default temp.pdf\n",
    "        Path to write a pdf file\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "    Path of resulting pdf file\n",
    "    \"\"\"\n",
    "    parent_directory = Path(filepath).parent.absolute()\n",
    "    if not os.path.exists(parent_directory):\n",
    "        os.makedirs(parent_directory)\n",
    "\n",
    "    with open(filepath, \"wb\") as f:\n",
    "        f.write(codecs.decode(b64_string, \"base64\"))\n",
    "    return filepath"
   ],
   "metadata": {
    "name": "Helper functions to assist with transferring binary files in JSON format",
    "collapsed": false,
    "scrolled": false,
    "datarobot": {
     "language": "python"
    },
    "hide_code": false,
    "hide_results": false,
    "disable_run": false,
    "chart_settings": null,
    "custom_metric_settings": null,
    "dataframe_view_options": null
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "65a4fbb115b02fcffbf0fbed",
   "cell_type": "code",
   "source": [
    "def load_model(input_dir):\n",
    "    import os\n",
    "    import stat\n",
    "\n",
    "    import whisper\n",
    "\n",
    "    # Ensure we have ffmpeg defined in the PATH\n",
    "    path = os.environ[\"PATH\"]\n",
    "    if \"ffmpeg\" not in path:\n",
    "        os.environ[\"PATH\"] = path + \":\" + \"./storage\"\n",
    "\n",
    "    # Change the permissions to allow execution of ffmpeg\n",
    "    file = \"./storage/ffmpeg\"\n",
    "    os.chmod(file, stat.S_IRWXU | stat.S_IRWXG | stat.S_IRWXO)\n",
    "\n",
    "    # Dynamically load this (note this encounters a permissions error when deployed, writing to the .cache folder)\n",
    "    # model = whisper.load_model(\"base\")\n",
    "\n",
    "    model_file = \"./storage/whisper/base.pt\"\n",
    "    model = whisper.load_model(model_file)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def score_unstructured(model, data, query, **kwargs) -> str:\n",
    "    import requests\n",
    "\n",
    "    temp_file_name = \"temp/tempfile\"\n",
    "    data_dict = json.loads(data)\n",
    "\n",
    "    if \"file\" in data_dict.keys():\n",
    "        # Write encoding to file\n",
    "        base_64_to_file(data_dict[\"file\"].encode(), filepath=temp_file_name)\n",
    "    elif \"url\" in data_dict.keys():\n",
    "        with open(temp_file_name, \"wb\") as f:\n",
    "            resp = requests.get(data_dict[\"url\"])\n",
    "            f.write(resp.content)\n",
    "            f.close()\n",
    "    else:\n",
    "        result = {\"error\": \"Missing parameter - either a file or url must be specified\"}\n",
    "        return json.dumps(result)\n",
    "\n",
    "    try:\n",
    "        result = model.transcribe(temp_file_name, fp16=False)\n",
    "        os.remove(temp_file_name)\n",
    "    except Exception as e:\n",
    "        result = {\"error\": f\"{e.__class__.__name__}: {str(e)}\"}\n",
    "    return json.dumps(result)"
   ],
   "metadata": {
    "name": "Prepare custom hooks for deploying Whisper as a custom model",
    "collapsed": false,
    "scrolled": false,
    "datarobot": {
     "language": "python"
    },
    "hide_code": false,
    "hide_results": false,
    "disable_run": false,
    "chart_settings": null,
    "custom_metric_settings": null,
    "dataframe_view_options": null
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "65a6fcaab7e1adf036c89cbb",
   "cell_type": "markdown",
   "source": "# Test by calling the local functions\n\nWe can test by downloading a file locally and submitting it directly, and also by providing the URL to a publically available audio file\n\nSample files source: https://github.com/microsoft/MS-SNSD/tree/master\n\nNote that here we will be returning the full output from the Whisper model, which includes the transcribed text along with additional metadata.",
   "metadata": {
    "collapsed": false,
    "scrolled": false,
    "datarobot": {
     "language": "markdown"
    },
    "hide_code": false,
    "hide_results": false,
    "disable_run": false,
    "chart_settings": null,
    "custom_metric_settings": null,
    "dataframe_view_options": null
   }
  },
  {
   "id": "65a6a96ab7e1adf036c8827d",
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "import requests\n",
    "\n",
    "# ------------- Test using a file -------------\n",
    "\n",
    "# Download the file first\n",
    "url = \"https://github.com/microsoft/MS-SNSD/raw/master/clean_test/clnsp0.wav\"\n",
    "data_file_name = \"./storage/sample_audio\"\n",
    "resp = requests.get(url)\n",
    "with open(data_file_name, \"wb\") as f:\n",
    "    f.write(resp.content)\n",
    "f.close()\n",
    "\n",
    "# Open the file and encode it\n",
    "data_file = open(data_file_name, \"rb\")\n",
    "data_file_bytes = data_file.read()\n",
    "encoding = base64.b64encode(data_file_bytes)\n",
    "\n",
    "# Test the hooks locally\n",
    "result = score_unstructured(\n",
    "    load_model(\".\"),\n",
    "    json.dumps(\n",
    "        {\n",
    "            \"file\": encoding.decode(),\n",
    "        }\n",
    "    ),\n",
    "    None,\n",
    ")\n",
    "result"
   ],
   "metadata": {
    "collapsed": false,
    "scrolled": false,
    "datarobot": {
     "language": "python"
    },
    "hide_code": false,
    "hide_results": false,
    "disable_run": false,
    "chart_settings": null,
    "custom_metric_settings": null,
    "dataframe_view_options": null
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 6,
     "data": {
      "text/plain": "'{\"text\": \" She seemed irritated. You\\'ve got no business up here. You took me by surprise. There would still be plenty of moments of regret and sadness and guilty relief. A warm breeze played across it, moving it like waves.\", \"segments\": [{\"id\": 0, \"seek\": 0, \"start\": 0.0, \"end\": 1.2, \"text\": \" She seemed irritated.\", \"tokens\": [50364, 1240, 6576, 43650, 13, 50424], \"temperature\": 0.0, \"avg_logprob\": -0.20225826331547328, \"compression_ratio\": 1.3766233766233766, \"no_speech_prob\": 0.003493815427646041}, {\"id\": 1, \"seek\": 0, \"start\": 1.2, \"end\": 2.64, \"text\": \" You\\'ve got no business up here.\", \"tokens\": [50424, 509, 600, 658, 572, 1606, 493, 510, 13, 50496], \"temperature\": 0.0, \"avg_logprob\": -0.20225826331547328, \"compression_ratio\": 1.3766233766233766, \"no_speech_prob\": 0.003493815427646041}, {\"id\": 2, \"seek\": 0, \"start\": 2.64, \"end\": 3.92, \"text\": \" You took me by surprise.\", \"tokens\": [50496, 509, 1890, 385, 538, 6365, 13, 50560], \"temperature\": 0.0, \"avg_logprob\": -0.20225826331547328, \"compression_ratio\": 1.3766233766233766, \"no_speech_prob\": 0.003493815427646041}, {\"id\": 3, \"seek\": 0, \"start\": 3.92, \"end\": 7.92, \"text\": \" There would still be plenty of moments of regret and sadness and guilty relief.\", \"tokens\": [50560, 821, 576, 920, 312, 7140, 295, 6065, 295, 10879, 293, 22462, 293, 12341, 10915, 13, 50760], \"temperature\": 0.0, \"avg_logprob\": -0.20225826331547328, \"compression_ratio\": 1.3766233766233766, \"no_speech_prob\": 0.003493815427646041}, {\"id\": 4, \"seek\": 0, \"start\": 7.92, \"end\": 11.040000000000001, \"text\": \" A warm breeze played across it, moving it like waves.\", \"tokens\": [50760, 316, 4561, 24532, 3737, 2108, 309, 11, 2684, 309, 411, 9417, 13, 50916], \"temperature\": 0.0, \"avg_logprob\": -0.20225826331547328, \"compression_ratio\": 1.3766233766233766, \"no_speech_prob\": 0.003493815427646041}], \"language\": \"en\"}'"
     },
     "metadata": {}
    }
   ],
   "execution_count": 6
  },
  {
   "id": "65a78ec95d984fdd670043fc",
   "cell_type": "code",
   "source": [
    "# ------------- Test using a URL -------------\n",
    "\n",
    "# Test the hooks locally\n",
    "result = score_unstructured(\n",
    "    load_model(\".\"),\n",
    "    json.dumps({\"url\": \"https://github.com/microsoft/MS-SNSD/raw/master/clean_test/clnsp1.wav\"}),\n",
    "    None,\n",
    ")\n",
    "result"
   ],
   "metadata": {
    "collapsed": false,
    "scrolled": false,
    "datarobot": {
     "language": "python"
    },
    "hide_code": false,
    "hide_results": false,
    "disable_run": false,
    "chart_settings": null,
    "custom_metric_settings": null,
    "dataframe_view_options": null
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 7,
     "data": {
      "text/plain": "'{\"text\": \" In some measure, they depend upon the structure of individual personality. Many selections are themselves convincing contributions to this appraisal. What shall these effects be?\", \"segments\": [{\"id\": 0, \"seek\": 0, \"start\": 0.0, \"end\": 4.84, \"text\": \" In some measure, they depend upon the structure of individual personality.\", \"tokens\": [50364, 682, 512, 3481, 11, 436, 5672, 3564, 264, 3877, 295, 2609, 9033, 13, 50606], \"temperature\": 0.0, \"avg_logprob\": -0.23194175017507454, \"compression_ratio\": 1.3185185185185184, \"no_speech_prob\": 0.006317353807389736}, {\"id\": 1, \"seek\": 0, \"start\": 4.84, \"end\": 9.76, \"text\": \" Many selections are themselves convincing contributions to this appraisal.\", \"tokens\": [50606, 5126, 47829, 366, 2969, 24823, 15725, 281, 341, 724, 20769, 304, 13, 50852], \"temperature\": 0.0, \"avg_logprob\": -0.23194175017507454, \"compression_ratio\": 1.3185185185185184, \"no_speech_prob\": 0.006317353807389736}, {\"id\": 2, \"seek\": 0, \"start\": 9.76, \"end\": 11.28, \"text\": \" What shall these effects be?\", \"tokens\": [50852, 708, 4393, 613, 5065, 312, 30, 50928], \"temperature\": 0.0, \"avg_logprob\": -0.23194175017507454, \"compression_ratio\": 1.3185185185185184, \"no_speech_prob\": 0.006317353807389736}], \"language\": \"en\"}'"
     },
     "metadata": {}
    }
   ],
   "execution_count": 7
  },
  {
   "id": "65a5027c365b78461657a434",
   "cell_type": "markdown",
   "source": "# Deploy the Whisper model\n\nThis convenience method uses the DataRobot package drx\nhttps://drx.datarobot.com/consume/deploy.html\n\n- Builds a new Custom Model Environment (OR reuses an existing one) and loads the contents of storage/deploy/\n- Assembles a new Custom Model with the provided hooks\n- Deploys an Unstructured Custom Model to your Deployments\n- Returns an object which can be used to make predictions\n\nUse `environment_id` to re-use an existing Custom Model Environment that you're happy with for shorter iteration cycles on the custom model hooks.",
   "metadata": {
    "collapsed": false,
    "scrolled": false,
    "datarobot": {
     "language": "markdown"
    },
    "hide_code": false,
    "hide_results": false,
    "disable_run": false,
    "chart_settings": null,
    "custom_metric_settings": null,
    "dataframe_view_options": null
   }
  },
  {
   "id": "65a5021a15b02fcffbf0fdf7",
   "cell_type": "code",
   "source": [
    "import datarobotx as drx\n",
    "\n",
    "deployment = drx.deploy(\n",
    "    \"storage\",\n",
    "    name=\"Whisper Speech Recognition\",\n",
    "    hooks={\"score_unstructured\": score_unstructured, \"load_model\": load_model},\n",
    "    extra_requirements=[\"openai-whisper\", \"ffmpeg\"],\n",
    "    # Re-use existing environment if a suitable is available, this can speed up the process\n",
    "    environment_id=\"64c964448dd3f0c07f47d040\",  # [DataRobot] Python 3.9 GenAI\n",
    ")"
   ],
   "metadata": {
    "name": "Create Deployment",
    "collapsed": false,
    "scrolled": false,
    "datarobot": {
     "language": "python"
    },
    "hide_code": false,
    "hide_results": false,
    "disable_run": false,
    "chart_settings": null,
    "custom_metric_settings": null,
    "dataframe_view_options": null
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 8,
     "data": {
      "text/plain": "\u001b[1m\u001b[34m#\u001b[0m\u001b[1m Deploying custom model\u001b[0m\n\u001b[1m  - \u001b[0mUnable to auto-detect model type; any provided paths and files will be\n    exported - dependencies should be explicitly specified using\n    `extra_requirements` or `environment_id`\n\u001b[1m  - \u001b[0mPreparing model and environment...\n\u001b[1m  - \u001b[0mUsing environment [[DataRobot] Python 3.9 GenAI\n    v7](https://app.datarobot.com/model-registry/custom-environments/64c964448dd3f0c07f47d040)\n    for deployment\n\u001b[1m  - \u001b[0mConfiguring and uploading custom model...\n\r    100%|█████████████████████████████████████| 225M/225M [00:01<00:00, 134MB/s]\n"
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "execution_count": 8,
     "data": {
      "text/plain": "\u001b[1m  - \u001b[0mRegistered custom model [Whisper Speech\n    Recognition](https://app.datarobot.com/model-registry/custom-models/65a8e64e25149018f7c1d4c3/info)\n    with target type: Unstructured\n\u001b[1m  - \u001b[0mInstalling additional dependencies...\n"
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "execution_count": 8,
     "data": {
      "text/plain": "\u001b[1m  - \u001b[0mCreating and deploying model package...\n"
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "execution_count": 8,
     "data": {
      "text/plain": "\u001b[1m  - \u001b[0mCreated deployment [Whisper Speech\n    Recognition](https://app.datarobot.com/deployments/65a8e775d3c751468792502c/overview)\n\u001b[1m\u001b[34m#\u001b[0m\u001b[1m Custom model deployment complete\u001b[0m\n"
     },
     "metadata": {}
    }
   ],
   "execution_count": 8
  },
  {
   "id": "65a78e7cb7e1adf036c8cb41",
   "cell_type": "markdown",
   "source": "# Test by calling the deployment\n\nWe can test by downloading a file locally and submitting it directly, and also by providing the URL to a publically available audio file\n\nSample files source: https://github.com/microsoft/MS-SNSD/tree/master",
   "metadata": {
    "collapsed": false,
    "scrolled": false,
    "datarobot": {
     "language": "markdown"
    },
    "hide_code": false,
    "hide_results": false,
    "disable_run": false,
    "chart_settings": null,
    "custom_metric_settings": null,
    "dataframe_view_options": null
   }
  },
  {
   "id": "65a6feb2b7e1adf036c89d5b",
   "cell_type": "code",
   "source": [
    "import datarobotx as drx\n",
    "\n",
    "# if using an existing deployment copy your deployment_id here\n",
    "# deployment = drx.Deployment(\"653995d19da96f2431c90516\")"
   ],
   "metadata": {
    "collapsed": false,
    "scrolled": false,
    "datarobot": {
     "language": "python"
    },
    "hide_code": false,
    "hide_results": false,
    "disable_run": false,
    "chart_settings": null,
    "custom_metric_settings": null,
    "dataframe_view_options": null
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "65a6fa4c5ed179051938812d",
   "cell_type": "code",
   "source": [
    "import requests\n",
    "\n",
    "# Download the file first\n",
    "url = \"https://github.com/microsoft/MS-SNSD/raw/master/clean_test/clnsp0.wav\"\n",
    "data_file_name = \"./storage/sample_audio\"\n",
    "resp = requests.get(url)\n",
    "with open(data_file_name, \"wb\") as f:\n",
    "    f.write(resp.content)\n",
    "f.close()\n",
    "\n",
    "# Open the file and encode it\n",
    "data_file = open(data_file_name, \"rb\")\n",
    "data_file_bytes = data_file.read()\n",
    "encoding = base64.b64encode(data_file_bytes)\n",
    "\n",
    "# Test the hooks locally\n",
    "result = deployment.predict_unstructured(\n",
    "    {\n",
    "        \"file\": encoding.decode(),\n",
    "    }\n",
    ")\n",
    "result[\"text\"]"
   ],
   "metadata": {
    "name": "Test using a downloaded file",
    "collapsed": false,
    "scrolled": false,
    "datarobot": {
     "language": "python"
    },
    "hide_code": false,
    "hide_results": false,
    "disable_run": false,
    "chart_settings": null,
    "custom_metric_settings": null,
    "dataframe_view_options": null
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 10,
     "data": {
      "text/plain": "\u001b[1m\u001b[34m#\u001b[0m\u001b[1m Making predictions\u001b[0m\n\u001b[1m  - \u001b[0mMaking predictions with deployment [Whisper Speech\n    Recognition](https://app.datarobot.com/deployments/65a8e775d3c751468792502c/overview)\n"
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "execution_count": 10,
     "data": {
      "text/plain": "\u001b[1m\u001b[34m#\u001b[0m\u001b[1m Predictions complete\u001b[0m\n\" She seemed irritated. You've got no business up here. You took me by surprise. There would still be plenty of moments of regret and sadness and guilty relief. A warm breeze played across it, moving it like waves.\""
     },
     "metadata": {}
    }
   ],
   "execution_count": 10
  },
  {
   "id": "65a6fb015ed1790519388164",
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "import requests\n",
    "\n",
    "# ------------- Test using a URL -------------\n",
    "\n",
    "# Test the hooks locally\n",
    "result = deployment.predict_unstructured(\n",
    "    {\"url\": \"https://github.com/microsoft/MS-SNSD/raw/master/clean_test/clnsp1.wav\"}\n",
    ")\n",
    "result[\"text\"]"
   ],
   "metadata": {
    "collapsed": false,
    "scrolled": false,
    "datarobot": {
     "language": "python"
    },
    "hide_code": false,
    "hide_results": false,
    "disable_run": false,
    "chart_settings": null,
    "custom_metric_settings": null,
    "dataframe_view_options": null
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 11,
     "data": {
      "text/plain": "\u001b[1m\u001b[34m#\u001b[0m\u001b[1m Making predictions\u001b[0m\n\u001b[1m  - \u001b[0mMaking predictions with deployment [Whisper Speech\n    Recognition](https://app.datarobot.com/deployments/65a8e775d3c751468792502c/overview)\n"
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "execution_count": 11,
     "data": {
      "text/plain": "\u001b[1m\u001b[34m#\u001b[0m\u001b[1m Predictions complete\u001b[0m\n' In some measure, they depend upon the structure of individual personality. Many selections are themselves convincing contributions to this appraisal. What shall these effects be?'"
     },
     "metadata": {}
    }
   ],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python",
   "language": "python",
   "display_name": "Python 3.9.18"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}